---
title: "Exposure Ethovision Analysis - Data Cleaning"
author: "Anna Steel"
date: "2/24/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(lme4)
library(circular)
library(patchwork)
library(MuMIn)

#library(rprojroot) # only used for find_rstudio_root_file() to set project wd as root
#knitr::opts_knit$set(root.dir = find_rstudio_root_file()) # sets root directory to match project directory, not rmd file location
```

This code segment reads in the measurements of inter-laser distance taken from the tunnel (taken immediately before or after trials) and entered in the same format as Ken used in his initial tests in 2019 and 2020 ('tunnel_specsXX').   
  
It then manipulates these dataframes/tibbles to use merge with the burst files for each fish and calculate velocities.   
```{r read tunnel data}
# if running from the SturgContam project in AES, go to documents -> git folder, then the base wd is "/Users/Anna/Documents/ResearchGit/SturgContam"

## Build Segment Dataset (all possible combs of inter-gate distances)----
tunnel_specs20 <- read_csv("../rawData/Small_Burst_Tunnel_Specs_Spring_2020_KZ.csv")
tunnel_specs21 <- read_csv("../rawData/Sturg_Burst_Tunnel_Specs_Spring_2021_AES.csv")

tunnel_specs = tunnel_specs21[,c("GATE_ID_L", "INTERGATE_DISTANCES_CM","GATE_DISTANCES_CM_L")]
names(tunnel_specs) = c("GATE_ID","INTERGATE_DISTANCES","GATE_DISTANCES")

segment_dat <- tribble(  ~GATE_A, ~GATE_B, ~START, ~END  ) # empty tibble for use in next step
seg_length = nrow(tunnel_specs) # number for use in next step

   # Create a large tibble with all possible permutations of gates 
    for (p in 1:seg_length){
      for (q in 1:seg_length){
        segment_dat <- segment_dat %>% 
          add_row(GATE_A = tunnel_specs$GATE_ID[p], GATE_B = tunnel_specs$GATE_ID[q], 
                  START = tunnel_specs$GATE_DISTANCES[p], 
                  END = tunnel_specs$GATE_DISTANCES[q])
      }
    }
    remove(p,q)

    #  Clean the segment dataframe to add intergate distances and a midpoint for each segment
    segment_dat_1 <- segment_dat %>% 
      mutate(DIFF = END-START) %>% # calculates the difference between two gates
      mutate(MIDPOINT = (START+END)/2) %>% # calculates the midpoint between two gates
      filter(DIFF > 0)  # get rid of combos of the same gate or reverse combinations
 
    # convert the gate categorical name to a number for use later 
    segment_dat_2 = segment_dat_1
      segment_dat_2$GATE_A <- as.numeric(gsub('Gate', '', segment_dat_2$GATE_A) )
      segment_dat_2$GATE_B <- as.numeric(gsub('Gate', '', segment_dat_2$GATE_B) )    
```      
    
```{r read trial metadata}

# pull metadata for index to all trials and metadata
trial_specs20ws <- read.csv("../rawData/Burst_Metadata_WS2020.csv")
trial_specs21ws <- read.csv("../rawData/Burst_Metadata_Complete_WS2021.csv")
trial_specs21gs <- read.csv("../rawData/Burst_Metadata_Complete_GS2021.csv")
trial_specs22ws <- read.csv("../rawData/Burst_MetaTrialdata_WS2022.csv")
trial_specs22ws_v2 <- read.csv("../rawData/Burst_MetaTrialdata_WS2022_noearlygates.csv")

# pull in chem analysis results for contaminant exposures
chem_dat = read.csv("../rawData/ChemAnalysisResults_CompiledforR.csv")
  ws20_chemdat = filter(chem_dat, Contaminant=="Bifenthrin", year==2020, spp=="WS", Sample=="spike")
  ws21_chemdat = filter(chem_dat, Contaminant=="Fipronil", year==2021, spp=="WS", Sample=="spike")
  gs21_chemdat = filter(chem_dat, Contaminant=="Fipronil", year==2021, spp=="GS", Sample=="spike")
  ws22_chemdat = filter(chem_dat, Contaminant=="Bifenthrin", year==2022, spp=="WS", Sample=="spike")
######*******########********#########**********#########***********#########
  ### ***** something is off with T30 from 2022; check the output file, the =raw data sheet, and the metadata csv to see what isn't aligning. Note from AES 3/23/2023 **** ###
######*******########********#########**********#########***********#########

# set one of these datasets for use in the subsequent analysis (may re-arrange this later to make it easier to re-run after troubleshooting is complete) 
trial_specs = merge(trial_specs22ws_v2, ws22_chemdat[,c("nomconc","CalcConc")], 
                    all.x=T, by.x=c("nomconc_ngL"), by.y=c("nomconc"))
 trial_specs$color = factor(gsub(" ","",trial_specs$color),
                            levels=c("white","green","yellow","red"))
 trial_specs$burstQual = gsub(" ","", trial_specs$burstQual) # remove spaces from extra trailing spaces entered in excel
 
 
# vector of all the file names to be considered in the analysis
filestart <- unique(trial_specs$raspPI_filestart)

 # remove trials without burst trial data file or terrible terrible results that break the code
 filestart = filestart[!(filestart %in% c("WSContam2022_Whit_R02_07_26_2022"))]


```


There are endless ways to use the burst events from one individual to estimate a 'burst speed' for that fish. See Ken's paper to understand what he considered and selected, and then look at if/how much those align with the methods considered here (AES note on 10/9/2023)

```{r create empty df for collection}

# create empty dataframe to record mean of top 3 burst velocities, after removing top 2; for each burst of each fish
burst.topvels = data.frame(treatmentrep = "EMPTY", burstID = NA, burstQual = as.factor(NA),
                          n_vels = NA, n_avg = NA, n_dropped = NA, start_side = NA,
                          mn.topburstvels = NA, sd.topburstvels = NA, CV.topburstvels.perc = NA)

# create empty dataframe to record above burst velocity averaged across the the pre-filtered 'good' trials for each fish, as well as sd of bursts and and N good bursts considered
mean.topvels = data.frame(treatmentrep = filestart, 
                          mn.top3burstvelGood = NA, sd.top3burstvelGood = NA, nburstGood = NA,
                          mn.top3burstvelGoodFair = NA, sd.top3burstvelGoodFair = NA, nburstGoodFair = NA)


# create empty data frame to record gates with top 25% of inter-gate speeds within a single burst event
fastPos.comp = data.frame(treatmentrep = "EMPTY", burstID = as.factor(NA), burstQual = NA, 
                          fastVel = NA, fastGate = as.factor(NA), fastPos = NA)
                          #, nGatesMissed = NA)

# create empty data frame to collect the burst events that were recorded but not used in analysis (usually false-triggers); need to check and confirm the filtering critera are working well
check_events = data.frame(burstQual = "EMTPY", stalledAt = "EMPTY", BURST_NUMBER=NA, ORIENTATION=NA, START_TIME=NA,  
Gate00 = NA, Gate01=NA, Gate02=NA, Gate03=NA, Gate04=NA, Gate05=NA, Gate06=NA, Gate07=NA, Gate08=NA, Gate09 = NA, Gate10=NA, Gate11=NA, Gate12=NA, Gate13=NA, Gate14=NA, n.missed=NA)
```
  
    
Loop through all burst trials and fill in above dfs, and write out a pdf of burst speeds over multiple tunnel segments for manual/subjective evaluation of methods. This. Will. Be. Epic. 
```{r loop through trials and collect data}

# first define segment lengths to use in summarizing data
min_distance = 1.5       # only consider inter-gate distances greater than 1.5cm 
max_distance = 15        # only consider inter-gate distances less than 15cm 
write.file = "Yes"        # don't write out a file (will take time and add clutter; only write out for final run)

spp.yr.rawfilepath = "BurstTrialRaw2022WS" # match this to the dataset chosen above; used in setting filepath for write-out
spp.yr.figfolder = "Bursts_Outputfigures_2022WS"
spp.yr.dataoutputfolder = "Bursts_Outputdata_2022WS"


# loop that will set up file structure for reading and writing each burst event, then run through code to pull information from the burst datafiles
# for learning or troubleshooting, assign f to 1 (or 2 or 3 etc) then run each line within the loop directly and see what it does/where it's broken
for(f in 1:length(filestart)) {
  print(f) # useful for troubleshooting when things break
     filename = as.character(dir(paste0("../rawData/",spp.yr.rawfilepath), 
                                 pattern=filestart[f]))
     
     # create a folder within existing structure for each burst trial (if not already there)
     figureoutputfolder = paste0("../figures/",spp.yr.figfolder,"/",filestart[f])
         if (file.exists(figureoutputfolder) == FALSE) { dir.create(figureoutputfolder)}
      dataoutputfolder = paste0("../outputData/",spp.yr.dataoutputfolder,"/",filestart[f])
          if (file.exists(dataoutputfolder) == FALSE) { dir.create(dataoutputfolder)}
    
     ## read in all bursts for a fish
     dat = read.csv(paste0("../rawData/",spp.yr.rawfilepath,"/",filename)  )
      dat = dat[1:(nrow(dat)-3),]  
       # remove last three rows of df that have only start/end/total time stamps
      dat$X <- NULL
       # if there is an extra empty column at the end, remove it here
    
     ## add the leading zero inside the gate names (column names) for later organization
      shortnames = names(dat)[names(dat) %in% paste0("Gate",0:9)] 
      longnames = paste0(str_sub(shortnames,end=4),"0",str_sub(shortnames,start=5, end=5))
      names(dat)[names(dat) %in% shortnames] <- longnames
      
     gate_names <- names(dat)[grep("Gate",names(dat))] # pulls all the gate names
      # check point during loop
     if(sum(nchar(gate_names)!=6) >0) print(paste("filestart, element#",f,filestart[f],"with error in Gate Names. Check loop around line 150"))
  
     ## read in metadata for trial
     metadat = trial_specs[trial_specs$raspPI_filestart==filestart[f],]
      # fix entering error that typed "N/A" 
      metadat[metadat=="N/A"] <- NA
      # ensure metadat is ordered by burst number
      metadat = metadat[order(metadat$burst),]
     
       
        ##### Unnecessary code from Ken; replaced with single line above #####
        # num_gates <- length(names(dat)[grep("Gate",names(dat))])  
        ## figure out number of gates from the tunnel specs.
        # first_gate_L <- which(names(dat)=="Gate0")  
        ## finds the first gate in the dataframe
        # first_gate_R <- which(names(dat)==paste0("Gate",(num_gates-1))) 
        ## finds the index of the rightmost gate
         ## MAYBE CHANGE THIS DEPENDING ON HOW THE RASPBERRY PI HANDLES LEFT AND RIGHT
        # gate_names <- names(dat[first_gate_L:first_gate_R]) 
        ## subsets all the gate names
        #####

     
 ## filter out gate trips not made by fish, using metadata ('stalledAt'); will remove 'poor' bursts later in code
     dat2 = data.frame(burstQual=as.character(NA), stalledAt= as.character(NA), dat) # df to be filled in with the following loop
    
     for(b in 1:nrow(dat2)) {                       #  for each row in dat
     #print(b)                                     #  use this line to troubleshoot if the loop is breaking; can see where in the loop something happens, and review that specific iteration
      dat2$burstQual[b] <- metadat[b,"burstQual"]   #   pull metadat for corresponding burst 
      finalgate = as.numeric(metadat[b,"stalledAt"])#   translate 'stalledAt' number to GateXX name
      dat2$stalledAt[b] <-as.numeric(metadat[b,"stalledAt"])#   translate 'stalledAt' number to GateXX name
      if(is.na(finalgate)) next                     #   if fish never stalled, move to next burst
      if(finalgate==14) next                        #   if fish stalled at final gate (14 in 2022), next 
      badcol_index = finalgate+6                    #  save column number where 'bad data' start so you can replace data from columns GateXX and after in next line
      dat2[b,badcol_index:ncol(dat2)] <- -99        # replace any timestamps with -99, to be removed in next stage 
     }
     
    ## quantify how many gates were missed 
     for(m in 1:nrow(dat2)) {
       dat2$n.missed[m] = sum(is.na(dat2[m,c(5:ncol(dat2))]) )
      }
     
     
     # switch -99 to NA for rest of code
      dat2[is.na(dat2)] <- -99
    
     # remove burst events that didn't collect quality data (ie: gates triggered incorrectly), but first print the gates that meet my tentative criteria for removal, along with the label so I can see what happens as the loop runs. I can take more time and vectorize this and create a dataframe with this information, but for now I'll just watch and troubleshoot in real time
    check_events_i = dat2[dat2$n.missed>6,]
    
    check_events <<- rbind(check_events, check_events_i) 
       # double arrow saves object to the global environment for reference after loop is completed
    
     dat3 = dat2[dat2$burstQual != -99 & dat2$n.missed<7,]
      # maybe remove more; review again later
      
    
  ### Create an empty list of datafames for each burst in the target trial
     num_burst<-nrow(dat3)
     burst.df.list <- replicate(num_burst, data.frame()) 
    
    # adjust tunnel_specs to have fewer columns and different names for the merge in the next step
    tunnel_position = tunnel_specs[,c("GATE_ID","GATE_DISTANCES")]
     names(tunnel_position) = c("GATE_ID","POSITION")
     
    # Calulate Metrics for each burst attempt in target trial
    for (i in 1:num_burst){
      assign("temp.dat", dat3[i,],.GlobalEnv)
      temp.dat.gathered <- gather(temp.dat, all_of(gate_names), 
                                  key = "GATE_ID",value = "TIMING") 
      # convert from wide to long format, with one line per gate rather than one line per burst event
      temp.dat.gathered = merge(temp.dat.gathered, tunnel_position, all.x=T) 
       # add the location in the tunnel (from tunnel_specs) to the times at that gate 
      
      temp.dat.gathered = filter(temp.dat.gathered, TIMING!=-99)
      
      ## Use a pipe to calculate more metrics from the positions and times
      temp.dat.gathered = temp.dat.gathered %>%
        filter(TIMING!=-99) %>%
           # removes gates that were missed (no times); do this first for better calcs of spd
        filter(TIMING==0 | TIMING - lag(TIMING,1) >= 0) %>%
           # removes row if the time recorded was before the previous, unless the row was the first detection of the fish in the tunnel ; do before spd calcs 
        mutate("POSITION_DIFF" = POSITION - lag(POSITION,1)) %>% 
          # Calulates the difference in position between gates
        mutate("TIMING_DIFF" = TIMING - lag(TIMING,1)) %>% 
           # Creates a column which calculates teh differences between two sequential timings
        mutate("VELOCITY" = POSITION_DIFF/TIMING_DIFF) %>% 
           # calculates velocity
        mutate("VELOCITY_DIFF" = VELOCITY - lag(VELOCITY,1)) %>%  
           # creates column which calculates teh differnce between two sequential speeds
        mutate("ACCEL" = VELOCITY_DIFF/TIMING_DIFF) 
           # calculates accleration
      
     burst.df.list[[i]]<-temp.dat.gathered #
           # stores them all as dataframes in a list
    }
    
   # filter to remove all elements within the list that have no data; they cause problems later
   #  they should have been filtered out already with above filters, but this is a final check
   burst.df.list = Filter(function(n) {sum(!is.na(n$TIMING_DIFF)) > 0}, burst.df.list)

    
   
     
  ## Write out to previously defined output folder  
    if(write.file=="Yes") {
     rbind_burst.df.list = do.call(rbind, burst.df.list) # convert from list to dataframe
     write.csv(rbind_burst.df.list,
                paste0(dataoutputfolder,"/Gate_by_Gate_metrics_",filestart[f],".csv"),
                row.names=F) }
   
   
   ## write pdf plots of inter-gate speeds for each burst event for the fish in the current loop
    if(write.file=="Yes") {

        pdf(paste0(figureoutputfolder,"/filtered_segmentBursts_",filestart[f],".pdf"),
            onefile=TRUE)
        for(i in 1:length(burst.df.list)) {
          if(nrow(burst.df.list[[i]]) == 0) {next} else {
            burst.df.list[[i]]$GATE_ID = factor(burst.df.list[[i]]$GATE_ID,
                                                levels=c(paste0("Gate0",0:9), paste0("Gate",10:14)) )
            print ( ggplot(data = burst.df.list[[i]]) +
              geom_errorbarh(aes(xmax = as.numeric(GATE_ID), 
                                 xmin = as.numeric(lag(GATE_ID)), 
                                 y = VELOCITY, height = 0))+
              coord_cartesian(xlim=c(1,15))+
              scale_x_continuous(breaks=1:15,labels=levels(burst.df.list[[i]]$GATE_ID))+  
              ggtitle(paste("Inter-gate Velocities: Burst",i," (max segment length =",max_distance,")")) +
              ylab("Velocity (cm/s)")+
              xlab("Gate Number")+
              theme(axis.text.x = element_text(angle=90)) ) }
                   }
        dev.off()
      }
   
   
 # Now this function will be fed each burst event stored in the burst.df.list object above:
    veldat_maxXcm = function(burst) {
      
          # deals with missing bursts from raspPi so they don't break code
        if(nrow(data.frame(burst))<1) {burst[1,"burstQual"] <- "none"} 
      
          # add more information to tunnel metadat (all gate combos) from focal burst data
        vel_dat_2 <- segment_dat_1 %>%  # segment_dat_1 is tunnel metadata. from ln 49 above
        mutate(burstQual = unique(burst$burstQual)) %>% 
        mutate(BURST_NUMBER = unique(burst$BURST_NUMBER)) %>%
        mutate(ORIENTATION = unique(burst$ORIENTATION)) 
        
        vel_dat_2b = merge(vel_dat_2, burst[,c("GATE_ID","TIMING")], 
                           by.x="GATE_B", by.y="GATE_ID", all.x = T)
          names(vel_dat_2b)[ncol(vel_dat_2b)] <- "TIMING_B"
        vel_dat_2a = merge(vel_dat_2b, burst[,c("GATE_ID","TIMING")], 
                           by.x="GATE_A", by.y="GATE_ID", all.x = T)
          names(vel_dat_2a)[ncol(vel_dat_2a)] <- "TIMING_A"
          
        # same goal, but from previous code where the gates were numeric not characters
          # mutate(TIMING_A = (burst$TIMING[GATE_A+1])) %>%
         # mutate(TIMING_B = (burst$TIMING[GATE_B+1])) %>% 
          
        vel_dat_3 <- vel_dat_2a %>%
          mutate(TIME_DIFF = TIMING_B - TIMING_A) %>%
          mutate(VELOCITY = DIFF/TIME_DIFF) %>%
          filter(DIFF >= min_distance & DIFF <= max_distance) %>% # dist defined prior to loop
          filter(TIME_DIFF <= 2) %>% # removes erroneous values generated by comparing gates which were triggered way too far apart; also appears to remove all rows with NA here
          filter(VELOCITY >= 0) # this may be redundant, but no harm in keeping it
      return(vel_dat_3)
    }

    clean_vel_data = lapply(burst.df.list,  veldat_maxXcm)

    # ## Plot data for each burst ####
    # if(write.file=="Yes") {
    # 
    #     pdf(paste0(figureoutputfolder,"/filtered_segmentBursts_",filestart[f],".pdf"),
    #         onefile=TRUE, )
    #     for(i in 1:15) {
    #       if(nrow(clean_vel_data[[i]]) == 0) {next} else {
    #       print ( ggplot(data = clean_vel_data[[i]]) +
    #         geom_errorbarh(aes(xmax = END, xmin = START, y = VELOCITY, height = 0))+
    #       geom_point(aes(x=MIDPOINT, y = VELOCITY), color = "orangered2") +
    #         coord_cartesian(xlim=c(0,100), ylim=c(0,70))+
    #         ggtitle(paste("Velocity: Burst",i," (max segment length =",max_distance,")")) +
    #       ylab("Velocity (cm/s)")+
    #         xlab("Tunnel Position (cm)")+
    #         theme(axis.text.x = element_text(angle=90)) ) }
    #                }
    #     dev.off()
    #   }

    # ### other exploratory plots from Ken's code ##
    #  Timeseries_pos_plot <- ggplot(data = burst.df.list[[i]],
    #                            aes(x=TIMING, y = POSITION)) +
    #     geom_line(color = "#0273e9")+
    #     geom_point() + 
    #     ggtitle(paste("Time Series of Position: Burst",i)) +
    #     ylab("Tunnel Position (cm)")+
    #     xlab("Time (s)")+
    #     theme(axis.text.x = element_text(angle=90))
    #  
    #  
    #  Timeseries_vel_plot <- ggplot(data = burst.df.list[[i]],
    #                                aes(x=TIMING, y = VELOCITY)) +
    #     geom_point() + 
    #     geom_line(color = "#3c5c00")+
    #     ggtitle(paste("Time Series of Velocities: Burst",i)) +
    #     coord_cartesian(ylim = c(0,100)) +
    #     ylab("Segment Velocity (cm/s)")+
    #     xlab("Time (s)")
    #  
    #  
    #   Timeseries_acc_plot <- ggplot(data = burst.df.list[[i]],
    #                                aes(x=TIMING, y = ACCEL)) +
    #     geom_point() + 
    #     geom_line(color = "#3c5c00")+
    #     ggtitle(paste("Time Series of Acceleration: Burst",i)) +
    #     #coord_cartesian(ylim = c(0,100)) +
    #     ylab("Segment Acceleration (cm/s)")+
    #     xlab("Time (s)")
    #####
      
      
  ### pull velocity metrics
    #  mean of fastest 3 velocities per burst, after dropping fastest one (object dd below notes how many fastest metrics to drop)
    
    topvel_func= function(x,n,d) { ## runs with x = either burst.df.list (sequential gates) or clean_vel_data (all pairs of gates)
      vel.list = sort(x$VELOCITY, decreasing=TRUE) 
      n_vels <- length(vel.list)
      n_avg <- n
      n_dropped <- d
      if(length(vel.list)<(n+d)) {mnvel=NA; sdvel=NA; n_avg<-0} else {
         mnvel = mean(vel.list[(d+1):(d+n)]) 
         sdvel = sd(vel.list[(d+1):(d+n)]) }
      return(data.frame(treatmentrep = filestart[f],
                        burstID = unique(x$BURST_NUMBER), 
                        burstQual = factor(unique(x$burstQual), levels=c("poor","fair","good")),
                        n_vels = n_vels,
                        n_avg = n_avg,
                        n_dropped = n_dropped,
                        start_side = unique(x$ORIENTATION),
                        mn.topburstvels = mnvel, 
                        sd.topburstvels = sdvel,
                        CV.topburstvels.perc = round(sdvel/mnvel*100,1) ) ) 
     }
     
  ## this summarizes results for each burst event (ie: estimates burst speed for one burst)
  ### drop fastest (sometimes erroneous) and take mean of next N sequential segment velocities
    dd = 1 # drop fastest dd
    nn = 3 # average remaining nn
    burst.mntopvels = do.call(rbind, lapply(burst.df.list, topvel_func, n=nn, d=dd)) # seems to give similar answers to results from all (overlapping) gate combinations created in clean_vel_data; not exhaustively or formally evaluated. Using this avoids pseudoreplication, but may be less ideal if there are gaps in data where lasers are frequently missed. 
     # returns NA vel if there are =< n velocity values measured
      burst.mntopvels$burstID = factor(burst.mntopvels$burstID, levels=c(1:14))
 
        
    if(write.file=="Yes") {
      write.csv(burst.mntopvels, paste0(dataoutputfolder,
                  "/Subjective_Rank_Mn_dropTop2_avgNext",nn,"_", filestart[f],".csv"),
                  row.names=F)
       
       pdf(paste0(figureoutputfolder,"/velTrends_within_trial_",filestart[f],".pdf"))
          print ( ggplot(data = burst.mntopvels, aes(x=burstID, y=mn.topburstvels)) +
              geom_errorbar(aes(ymax = mn.topburstvels+sd.topburstvels, 
                                 ymin = mn.topburstvels-sd.topburstvels), width=0.25)+
              geom_point(size=2.5)+  
              coord_cartesian(xlim=c(1,8), ylim=c(0,100))+
              ylab("Est. Max Velocity (cm/s)")+
              xlab("Burst Event")+
              theme_bw() )
        dev.off()
      
      }
  
    
      ## append to empty dataframe so we can collect all of the bursts in one place for later analysis  
    burst.topvels = rbind(burst.topvels, burst.mntopvels)

  
    
    
    ### function to pull the top 25% of speeds (measured at each sequential gate) 
      #for each burst and identify where along the burst tunnel they are happening
     ## This was mostly for designing the burst tunnel before we built the smallest one, 
      # as we wanted to confirm that a 70cm tunnel was long enough for sturgeon 
      # (ie: fastest speeds were <70cm)
      fastPos_func = function(x) { 
        fast.pos = which(x$VELOCITY > quantile(x$VELOCITY,.75, na.rm=T)) 
            # returns true/false vector of inter-gate speeds in the top 25% percentile
         if(length(fast.pos)==0) {return(NULL)} else {  
        fastVel = x$VELOCITY[fast.pos]   
            # new vector that includes the top 25% of measured spds
        fastGate = x$GATE_ID[fast.pos]   
            # gate ID that corresponds to fastest measures
        fastPos = x$POSITION[fast.pos]   
            # cm along tunnel that corresponds to fastest measures
        return(cbind(data.frame(treatmentrep = filestart[f],
                                burstID = unique(x$BURST_NUMBER), 
                                burstQual = unique(x$burstQual)),
                     fastVel, fastGate, fastPos) ) } # make a new df for each burst event
        }
      
      fastPos = do.call(rbind, lapply(burst.df.list, fastPos_func)) 
           # rbind all df created with the function above for the burst trial being 
           #  targetted in the current iteration of this giant loop
      fastPos$burstID = factor(fastPos$burstID, levels=c(1:15))
      fastPos$fastGate = factor(fastPos$fastGate, levels=c(paste0("Gate0",1:9), paste0("Gate",10:14)))
      
               
        # append burst from current loop to an existing object that will accumulate ALL data
              fastPos.comp = rbind(fastPos.comp, fastPos)
              
              
              # boxplots of mean and sd top speeds within each subjective rank category
              burst.mntop.nona = burst.mntopvels[!is.na(burst.mntopvels$mn.topburstvels),]
              subjective_rank_spds = ggplot( data = burst.mntop.nona,
                      aes(x=burstQual, y=mn.topburstvels)) +
                      geom_boxplot() +
                        geom_point()+
                      theme_bw()
            
              subjective_rank_varspds = ggplot( data = burst.mntop.nona,
                      aes(x=burstQual, y=sd.topburstvels)) +
                      geom_boxplot() +
                        geom_point()+
                      theme_bw()
              
              
              if(write.file=="Yes") {
                pdf(paste0(figureoutputfolder,"/Subjective_Rank_Mn_dropTop",dd,"_avgNext",nn,"_",filestart[f],".pdf"), onefile=TRUE)
                
                  subjective_rank_spds + subjective_rank_varspds + plot_layout(ncol=1)
                  
                dev.off() }
              
              
    
    
    
   # calculate metrics to output
    GoodBurstdf = burst.mntopvels[burst.mntopvels$burstQual=="good",]      
      top3burstGood     = GoodBurstdf[rev(order(GoodBurstdf$mn.topburstvels)),][1:3,]
       
   GoodFairBurstdf = burst.mntopvels[burst.mntopvels$burstQual%in% c("good","fair"),]      
      top3burstGoodFair = GoodFairBurstdf[rev(order(GoodFairBurstdf$mn.topburstvels)),][1:3,]     
    
    n.burstvel.Good      = length(    GoodBurstdf$mn.topburstvels)
    n.burstvel.GoodFair  = length(GoodFairBurstdf$mn.topburstvels)

    mn.top3burstvel      = mean(    top3burstGood$mn.topburstvels, na.rm=T)
    mn.top3burstvel.gf   = mean(top3burstGoodFair$mn.topburstvels, na.rm=T)
    
    sd.top3burstvel      = sd(    top3burstGood$mn.topburstvels, na.rm=T)
    sd.top3burstvel.gf   = sd(top3burstGoodFair$mn.topburstvels, na.rm=T)
   
    
    # add them to the appropriate row in empty dataframe
    mean.topvels[mean.topvels$treatmentrep == filestart[f], "nburstGood"] <- n.burstvel.Good
    mean.topvels[mean.topvels$treatmentrep == filestart[f], "nburstGoodFair"] <- n.burstvel.GoodFair
    
    mean.topvels[mean.topvels$treatmentrep == filestart[f], "mn.top3burstvelGood"] <- mn.top3burstvel
    mean.topvels[mean.topvels$treatmentrep == filestart[f], "mn.top3burstvelGoodFair"] <- mn.top3burstvel.gf
    
    mean.topvels[mean.topvels$treatmentrep == filestart[f], "sd.top3burstvelGood"] <- sd.top3burstvel
    mean.topvels[mean.topvels$treatmentrep == filestart[f], "sd.top3burstvelGoodFair"] <- sd.top3burstvel.gf
     

}
```
PHEW! That was an epic loop. 


```{r clean up compilation df}
# remove one line used to start the df
burst.topvels2 = burst.topvels[burst.topvels$treatmentrep!="EMPTY",]
fastPos.comp2 = fastPos.comp[fastPos.comp$treatmentrep!="EMPTY",] 

# 
# # set fastPos gate order for factor
# fastPos.comp2$fastGate = factor(fastPos.comp2$fastGate, 
#                                 levels=c("Gate00","Gate01","Gate02","Gate03",
#                                          "Gate04","Gate05","Gate06","Gate07",
#                                          "Gate08","Gate09","Gate10","Gate11",
#                                          "Gate12","Gate13","Gate14"))



# add metadata and fix formatting
trial_specs_unique = unique(trial_specs[,c("raspPI_filestart","tempRampGroup","trialID", "spp","dph","treattemp","triallength","tankrep","color","CalcConc","tunneltemp","tl_mm","mass_g", "badfish")])

mean.topvels2 = merge(mean.topvels, trial_specs_unique, all.x=T, by.x="treatmentrep", by.y="raspPI_filestart") 

mean.topvels2$color = factor(mean.topvels2$color,
                             levels=c("white","green","yellow","red"))
mean.topvels2$rep = substring(mean.topvels2$treatmentrep, 19,21)

# remove NA burst estimates (or estiamted with only one good burst
mean.topvels2 = mean.topvels2[!is.na(mean.topvels2$sd.top3burstvelGood),] # removed 7

# convert CalcConc to numeric
mean.topvels2$CalcConc= as.numeric(mean.topvels2$CalcConc)
mean.topvels2$mass_g = as.numeric(mean.topvels2$mass_g)

# add BL/s column
mean.topvels2$mnburstGood_bls = mean.topvels2$mn.top3burstvelGood/(mean.topvels2$tl_mm) 
mean.topvels2$mnburstGoodFair_bls = 
  mean.topvels2$mn.top3burstvelGoodFair/(mean.topvels2$tl_mm)

mean.topvels2$sdburstGood_bls = mean.topvels2$sd.top3burstvelGood/(mean.topvels2$tl_mm) 
```


```{r review possibly erronious bursts}
  # look at potentially erronious bursts
  hist(burst.topvels2$mn.topburstvels)
  toofast = burst.topvels2[burst.topvels2$mn.topburstvels>110 & 
                             !is.na(burst.topvels2$mn.topburstvels),]
     # examine raw data (outside of R) for:
        # GWSContam2022_Redd_R12_07_28_2022 ---> just a super fast fish! 
  hist(burst.topvels2$CV.topburstvels.perc)
  toovar = burst.topvels2[burst.topvels2$CV.topburstvels.perc>50 & 
                             !is.na(burst.topvels2$CV.topburstvels.perc),]
       # WSContam2022_Whit_R16_08_09_2022 ---> looks fine
       # WSContam2022_Gree_R12_08_08_2022 ---> burst 2 with a bad triggers at gate 13;  removed timestamp and CV dropped from >100% to 8%
       # WSContam2022_Gree_R09_08_08_2022 ---> looks fine; highly variable fish
       # WSContam2022_Gree_R16_08_09_2022 ---> burst 4 with two maybe erronious times; 
       # WSContam2022_Yell_R16_08_09_2022 ---> burst 2 looks like last 6 gates were wrong, perhaps forgot to add 'stalledAt'; changed stalled at to 9 to adjust for this
       # WSContam2022_Yell_R15_07_29_2022 ---> fine
       # WSContam2022_Yell_R04_07_27_2022 ---> fine, just a very slow fish
       # WSContam2022_Yell_R06_07_27_2022 ---> burst 7 with two very high measures (>100) and rest of velocities suggest it's a very slow fish. notes say gate tripped early
       # WSContam2022_Redd_R14_07_28_2022 ---> burst 3, first two gates fast; tripped early?
       # WSContam2022_Redd_R16_08_09_2022 ---> fine
```


```{r plots to evaluate study design incl tank effects}
### review study design and analysis approach first:  

  # look at where the fastest burst segment were (for next tunnel design)
  ggplot(fastPos.comp2, aes(y=fastVel,x=burstID, color=burstQual)) + 
      geom_point() + 
      theme_bw() 
    
  ggplot(fastPos.comp2, aes(x=fastGate, fill=burstQual)) + 
      geom_histogram(stat="count", position="dodge", color="black") + 
      facet_grid(.~burstQual)+
      scale_x_discrete(guide=guide_axis(angle = 45), name="") + 
      theme_bw()
  
  ggplot(filter(fastPos.comp2, fastVel>20) , aes(x=fastGate, fill=burstQual)) + 
      geom_histogram(stat="count", position="dodge", color="black") + 
      facet_grid(.~burstQual)+
      scale_x_discrete(guide=guide_axis(angle = 45), name="") + 
      theme_bw()

  # look at speed and trial order
  ggplot(mean.topvels2, aes(x=as.numeric(str_sub(trialID,2,3)), y=mn.top3burstvelGood)) + 
    geom_point() + 
    geom_smooth(method="lm") +
    theme_bw()   
  
  # look at speed and participation by early vs late transition to 18C
  ggplot(mean.topvels2, aes(x=color, y=mn.top3burstvelGood, fill=factor(tempRampGroup))) + 
      geom_boxplot() + 
      scale_fill_manual(values=c("pink1","steelblue3")) + 
     theme_bw()
  ggplot(mean.topvels2, aes(x=color, y=nburstGood, fill=factor(tempRampGroup))) + 
      geom_boxplot() + 
      scale_fill_manual(values=c("pink1","steelblue3")) + 
     theme_bw()

  
  # look at trial length within a concentration, and look at participation and burst speed
  ggplot(mean.topvels2, aes(y=triallength, x=color, fill=color)) + 
      geom_boxplot() + 
      scale_fill_manual(values=c("grey70","green3","gold1","brown3")) + 
      theme_bw()
        ggplot(mean.topvels2, aes(x=triallength, y=nburstGood, fill=color)) + 
            geom_point(pch=21, size=4) + geom_smooth(aes(color=color), n=4) + 
            scale_color_manual(values=c("black","green3","gold1","brown3")) + 
            scale_fill_manual(values=c("grey70","green3","gold1","brown3")) + 
            facet_wrap(~color) + theme_bw()
        ggplot(mean.topvels2, aes(x=triallength, y=mnburstGood_bls, fill=color)) + 
            geom_point(pch=21, size=4) + geom_smooth(aes(color=color), n=4) + 
            scale_color_manual(values=c("black","green3","gold1","brown3")) + 
            scale_fill_manual(values=c("grey70","green3","gold1","brown3")) + 
            facet_wrap(~color) + theme_bw()

  # look at tank effects on growth, then on participation and burst speeds
  mean.topvels2$rep <- gsub(" ","",mean.topvels2$rep)

  ggplot(mean.topvels2, aes(x=color, y=tl_mm, fill=rep)) + 
    geom_boxplot() +
    scale_fill_manual(values=c("pink","steelblue3")) + 
    theme_bw()
  ggplot(mean.topvels2, aes(x=color,  y=mass_g, fill=rep)) + 
    geom_boxplot() +
    scale_fill_manual(values=c("pink","steelblue3")) + 
    theme_bw()
        
  ggplot(mean.topvels2, aes(x=color, y=nburstGood, fill=factor(rep))) + 
      geom_boxplot() + 
      scale_fill_manual(values=c("pink1","steelblue3")) + 
     theme_bw()
  ggplot(mean.topvels2, aes(x=color, y=mnburstGood_bls, fill=factor(rep))) + 
      geom_boxplot() + 
      scale_fill_manual(values=c("pink1","steelblue3")) + 
     theme_bw()
  
  summary(aov(lm(mass_g ~ color + tankrep, data= mean.topvels2)))     
  summary(aov(lm(tl_mm ~ color + tankrep, data= mean.topvels2)))  
  summary(aov(lm(nburstGood ~ color + tankrep, data= mean.topvels2)))  
  summary(aov(lm(mnburstGood_bls ~ color + tankrep, data= mean.topvels2)))  
  # phew! Tank effects doesn't seem to be causing difference in growth or nburstGood 
```
  
  
```{r plot effects on Good burst number}
 
  # look at relationship between number of bursts and sd in bursts within a fish
  ggplot(mean.topvels2, aes(x=nburstGood, y=mn.top3burstvelGood)) + 
    geom_point(aes(color=nburstGood), size=3) + geom_smooth()

  # look at relationship between number of bursts and sd in bursts within a fish
  ggplot(mean.topvels2, aes(x=nburstGood, y=sd.top3burstvelGood)) + 
    geom_point(aes(color=nburstGood), size=3) + geom_smooth()

    # look at sample size for all fish with burst data:
    table(mean.topvels2$color)   
   # White  Green Yellow    Red   
   #  30     30     30     30    
    
    # reduce this to only fish that gave >2 good bursts
    table(mean.topvels2[mean.topvels2$nburstGood>2,]$color)   
   # White  Green Yellow    Red   
   #    30     29     30     30   
    
    # reduce this to only fish that gave >3 good bursts
    table(mean.topvels2[mean.topvels2$nburstGood>3,]$color)   
   # White  Green Yellow    Red   
   #    30     25     28     30   
  
    # reduce this to only fish that gave >4 good bursts
    table(mean.topvels2[mean.topvels2$nburstGood>4,]$color)
    # White  Green Yellow    Red   
    #    29     24     26     29   
    
    # reduce this to only fish that gave >4 good bursts
    table(mean.topvels2[mean.topvels2$nburstGood>5,]$color)
    # White  Green Yellow    Red   
    #    27     23     26     28   
  
  # look at effect of filtering on this relationship
  ggplot(filter(mean.topvels2, nburstGood>5), aes(x=nburstGood, y=mn.top3burstvelGood)) + 
    geom_point(aes(color=nburstGood), size=3) + geom_smooth()
  
  # look at effect of filtering on this relationship
  ggplot(filter(mean.topvels2, nburstGood>5), aes(x=nburstGood, y=sd.top3burstvelGood)) + 
    geom_point(aes(color=nburstGood), size=3) + geom_smooth()  
  
  # chose 5 because there were many individuals in this dataset, and 5 reduced the effect of participation on burst estimate, as well as evening the treatment groups (sd=2.16)  better than a threshold at 3 (2.36) or at 4 (2.45)
      
```


```{r plots relating burst participation with speed}
  # look at relationship between estimated burst speeds and number of good bursts
     ggplot(mean.topvels2, 
           aes(x=nburstGood, y=mnburstGood_bls ,color=color, group=color)) + 
      geom_point(size=4) + geom_smooth(n=4) + 
      scale_color_manual(values=c("black","green3","gold1","brown3")) + 
      facet_wrap(~color) + theme_bw()

    # reduce this to only fish that gave >5 good bursts  (see above)
    ggplot(filter(mean.topvels2, nburstGood>5), 
           aes(x=nburstGood, y=mnburstGood_bls ,color=color, group=color)) + 
      geom_point(size=4) + geom_smooth(n=4) + 
      scale_color_manual(values=c("black","green3","gold1","brown3")) + 
      facet_wrap(~color) + theme_bw()

   
    # look at relationship between burst quality and treatment
    ggplot(filter(mean.topvels2, nburstGood>5), aes(x=color, y=nburstGood, fill=color)) + 
     #geom_boxplot() +
     geom_violin() +
     scale_fill_manual(values=c("grey95","green3","gold1","brown3")) + 
     ylab("n 'Good' bursts") + xlab("Bifenthrin Treatment") + ylim(c(0,14))+
   theme_bw()

  # # test this statistically
  # participant.model.all = lm(nburstGood~log(CalcConc+1), data = mean.topvels2)
  #   plot(participant.model.all) # meets assumptions okay, normal plot ends are skewed
  #   summary((participant.model.all)) # no effect of treatment; effect size shows linear increase in number of good bursts with increasing conc. 
  # participant.model.5 = lm(nburstGood~log(CalcConc+1), 
  #                          data = filter(mean.topvels2, nburstGood>5))
  #   plot(participant.model.5) # meets assumptions okay, better ends for normal plot
  #   summary((participant.model.5)) # sig effect of conc now, p=0.036; slightly stronger effect size and lower se; still linear increase in number of good bursts with increasing conc. 
  #   
    
    
         # look at relationship between burst quality and treatment including 'fair' bursts
      ggplot(mean.topvels2, aes(x=color, y=nburstGoodFair, fill=color)) + 
         #geom_boxplot() +
         geom_violin() +
         scale_fill_manual(values=c("grey95","green3","gold1","brown3")) + 
         ylab("n 'Good' & 'Fair' bursts") + xlab("Bifenthrin Treatment") + ylim(c(0,14))+
       theme_bw()
    
      ggplot(filter(mean.topvels2, nburstGood>5), aes(x=color, y=nburstGoodFair, fill=color))+ 
         #geom_boxplot() +
         geom_violin() +
         scale_fill_manual(values=c("grey95","green3","gold1","brown3")) + 
         ylab("n 'Good' & 'Fair' bursts") + xlab("Bifenthrin Treatment") + ylim(c(0,14))+
       theme_bw()
      # 
      # # test this statistically
      # participant.model.allfair = lm(nburstGoodFair~log(CalcConc+1), data = mean.topvels2)
      #   plot(participant.model.allfair) # meets assumptions okay, normal plot ends skew down
      #   summary((participant.model.allfair)) # no effect of treatment; effect size shows linear increase in number of good bursts with increasing conc. 
      # participant.model.5fair = lm(nburstGoodFair~log(CalcConc+1), 
      #                          data = filter(mean.topvels2, nburstGood>5))
      #   plot(participant.model.5fair) # meets assumptions okay, better ends for normal plot
      #   summary((participant.model.5fair)) # sig effect of conc now, p=0.038 slightly stronger effect size and lower se; still linear increase in number of good bursts with increasing conc. 
```
        
        
```{r plot effect of size on outcomes}         

# look at relationship between participation and fish length
    ggplot(filter(mean.topvels2, nburstGood>5), aes(x=tl_mm, y=nburstGood)) + 
      geom_point() + geom_smooth(method="lm")+
      ylab("n 'Good' bursts") + xlab("fish length cm") + ylim(c(0,14))+
    theme_bw()
    
  # look at effect of fish size or mass on burst speeds
  ggplot(mean.topvels2, aes(x=tl_mm, y=mass_g)) + geom_point() + geom_smooth() + theme_bw()
  
  ggplot(mean.topvels2, aes(x=tl_mm, y=mn.top3burstvelGood)) + 
    geom_point() + geom_smooth() + theme_bw()

  ggplot(filter(mean.topvels2, tl_mm<100), aes(x=tl_mm, y=mn.top3burstvelGood)) + 
    geom_point() + geom_smooth() + theme_bw()
  
  ggplot(filter(mean.topvels2, mass_g<6), aes(x=mass_g, y=mn.top3burstvelGood)) + 
    geom_point() + geom_smooth() + theme_bw()

# look at relationship between burst speed in cm/s and bl/s and fish length
    ggplot(filter(mean.topvels2, nburstGood>5), aes(x=tl_mm, y=mn.top3burstvelGood)) + 
      geom_point() + geom_smooth(method="lm")+
      ylab("Burst Velocity in cm/s") + xlab("fish length cm") + 
    theme_bw()
    
    ggplot(filter(mean.topvels2, nburstGood>5), aes(x=tl_mm, y=mnburstGood_bls)) + 
      geom_point() + geom_smooth(method="lm")+
      ylab("Burst Velocity in bl/s") + xlab("fish length cm") + ylim(c(0,14))+
    theme_bw()

# look at relationship between burst speed in cm/s and bl/s and fish mass
    ggplot(filter(mean.topvels2, nburstGood>5), aes(x=mass_g, y=mn.top3burstvelGood)) + 
      geom_point() + geom_smooth(method="lm")+
      ylab("Burst Velocity in cm/s") + xlab("fish mass(g)") + 
    theme_bw()
    
    ggplot(filter(mean.topvels2, nburstGood>5), aes(x=mass_g, y=mnburstGood_bls)) + 
      geom_point() + geom_smooth(method="lm")+
      ylab("Burst Velocity in bl/s") + xlab("fish mass(g)") + ylim(c(0,14))+
    theme_bw()
    
    # no evidence that filtering will change the relationship; do not filter by size but normalize by length into bl/s
    
    
      # look at length-adjusted burst speeds (ie: bl/s)
       library(ggpubr)
       gghistogram(mean.topvels2, x="mnburstGood_bls", y="..density..",
                   add="mean", add_density=TRUE, fill="grey50")
dens.estburstvel =  ggplot(mean.topvels2, 
                           aes(x=mnburstGood_bls, 
                           color=factor(color), fill=factor(color))) + 
         geom_density(alpha=0.2, bw=.75) + 
         scale_color_manual(values=c("black","green3","gold1","brown3"),                      
                           labels=c("0","10","100","500"),
                           name="Bifenthrin\nConcentration (ng/L)") + 

         scale_fill_manual(values=c("black","green3","gold1", "brown3"),
                           labels=c("0","10","100","500"),
                           name="Bifenthrin\nConcentration (ng/L)") + 
         ylab("Density") + 
         xlab("Estimated Burst Velocities (bl/s)\nof White Sturgeon") + 
        theme_bw()

       
  if(write.file=="Yes") {
      tiff(file = "...figures/Burst_WS2022_Density.tiff",
           width = 150, height = 80, units = "mm", pointsize = 12,
           compression = c("lzw"), bg = "white", res=300)
      dens.estburstvel
      dev.off()
      }
    
```


```{r plots of effect of treatment on velocity & participation} 

# Look at relationship between treatment and burst speeds, boxplot
ggplot(mean.topvels2, aes(x=color, y=mnburstGood_bls, fill=color)) + 
     geom_boxplot() +
     scale_fill_manual(values=c("grey90","green3","gold1","brown3")) + 
    theme_bw()
     
# Look at relationship between treatment and burst speeds, points for each fish;
#   with points jittered around the log of the exposure concentration
#   this is the plot used for Ken's bay delta poster
set.seed(38)
mean.topvels2$random.offset = runif(n=nrow(mean.topvels2), min = -0.25, max=0.25)
mainplot.cms = ggplot(mean.topvels2, aes(y=mn.top3burstvelGood, 
                                     x=log(CalcConc+1)+random.offset)) + 
         geom_errorbar(aes(ymin=mn.top3burstvelGood-sd.top3burstvelGood,
                           ymax=mn.top3burstvelGood+sd.top3burstvelGood), width=0) + 
         geom_point(aes(size=nburstGood, fill=factor(color)), pch=21, alpha=0.8) + 
         theme_bw() + 
         ylab("Mean Burst Swim Speed (cm/s)") +
         scale_x_continuous(breaks=log(c(1,11,101, 501)), 
                            labels=c(1,11,101, 501)-1, 
                            name="Measured Bifenthrin Concentration")  +
         scale_size_continuous(breaks=seq(3,15,2), name = "Number of\n'Good' Bursts") + 
         scale_fill_manual(values=c("grey90","green3","gold1","brown3"), 
                           labels=c("0 ng/l","10 ng/l","100 ng/l","500 ng/l"),
                           name="Nominal Bifenthrin\nConcentration") +
         theme_bw()


mainplot.bls = ggplot(mean.topvels2, aes(y=mnburstGood_bls, 
                                     x=log(CalcConc+1)+random.offset)) + 
         geom_errorbar(aes(ymin=mnburstGood_bls-sdburstGood_bls,
                           ymax=mnburstGood_bls+sdburstGood_bls, 
                           width=0) ) + 
         geom_point(aes(size=nburstGood, fill=factor(color)), pch=21, alpha=0.8) + 
         theme_bw() + 
         ylab("Mean Burst Swim Speed (bl/s)") +
         scale_x_continuous(breaks=log(c(1,11,101, 501)), 
                            labels=c(1,11,101, 501)-1, 
                            name="Measured Bifenthrin Concentration (ng/L)")  +
         scale_size_continuous(breaks=seq(3,15,2), name = "Number of\n'Good' Bursts") + 
         scale_fill_manual(guide="none",
                           values=c("grey90","green3","gold1","brown3"), 
                           labels=c("0 ng/L","10 ng/L","100 ng/L","500 ng/L"),
                           name="Nominal Bifenthrin\nConcentration") +
         theme_bw()


mainplot.cms
mainplot.bls




 # Look at relationship between burst quality and treatment, as boxplot
  ggplot(mean.topvels2, aes(x=color, y=nburstGood, fill=color)) + 
    geom_boxplot() +
     scale_fill_manual(values=c("grey90","green3","gold1","brown3")) + 
    theme_bw()
    
  # Look at relationship between treatment and participation, points for each fish;
  #   with points jittered around the log of the exposure concentration
  #   this is the plot used for Ken's bay delta poster  
  participation.means= summarize(group_by(mean.topvels2, CalcConc),
                                 mean.goodburst=mean(nburstGood),
                                 sd.goodburst=sd(nburstGood),
                                 se.goodburst=sd(nburstGood)/n())
  mainplot.participate = ggplot() + 
         geom_dotplot(data=mean.topvels2, aes(y=as.numeric(nburstGood), 
                                       x=factor(log(CalcConc+1)),
                                       fill=factor(color)),
                      binaxis="y", stackdir="center", stackratio=0.7, alpha=0.8)+
         ylab("Number of 'Good' Bursts") +
         scale_x_discrete(labels=c(1,11,101, 501)-1, 
                            name="Measured Bifenthrin Concentration (ng/L)")  +
         scale_fill_manual(guide="none",
                    values=c("grey90","green3","gold1","brown3"), 
                           labels=c("0 ng/l","10 ng/l","100 ng/l","500 ng/l"),
                           name="Nominal Bifenthrin\nConcentration") +
         theme_bw()
  
  mainplot.participate
  
  mainplot.participate + 
    geom_point(data=participation.means,
                      aes(x=factor(log(CalcConc+1)), y=mean.goodburst), 
                      pch=17, size=2)+
          geom_errorbar(data=participation.means, 
                       aes(x=factor(log(CalcConc+1)), y=mean.goodburst, 
                       ymin=mean.goodburst-se.goodburst, 
                       ymax=mean.goodburst+se.goodburst), 
                           width=.1, size=.5) 

  
```




```{r lm relating experimental design with treatment}

filtered.moddat = filter(mean.topvels2, nburstGood>5)

# experimental design
summary(aov(tl_mm ~color, data = filtered.moddat)) # significant
 TukeyHSD(aov(tl_mm ~color, data = filtered.moddat))
  # 2 of 6 with sig differences 
  #  red and green (diff=0.998cm, p adj = 0.015)
  #  white and green (diff= -0.917cm, p adj = 0.032)
 
summary(aov(mass_g ~ color, data = filtered.moddat)) # significant
 TukeyHSD(aov(mass_g ~color, data = filtered.moddat)) 
  # 2 of 6 with sig differences 
  #  red and green (diff=1.21g, p adj = 0.018)
  #  white and green (diff= -1.12g, p adj = 0.033)
 
summary(aov(dph ~ color, data = filtered.moddat)) # no significance
summary(aov(tunneltemp ~ color, data = filtered.moddat)) # no significance
  # largest pairwise mean dif was 0.1C


```


```{r lm relating burst vel with treatment}

filtered.moddat = filter(mean.topvels2, nburstGood>5)

# basic hypothesis test (effect of bif on spd)
testmod.continuous = lm(mnburstGood_bls~log(CalcConc+1), data = filtered.moddat)
  plot(testmod.continuous) # fits assumptions very well
  summary((testmod.continuous)) # not significant p=0.233, effect size 0.059 for log(calcconc+1)
  
testmod.factor = lm(mnburstGood_bls~factor(CalcConc), data = filtered.moddat)
  plot(testmod.factor) # fits assumptions fine
  summary(aov(testmod.factor)) # still no sig diff p=0.513


# kitchen sink model for dredging (explore effects of study design/constraints)
  
fullmod.speed2 = lm(mnburstGood_bls ~ log(CalcConc+1) + nburstGood + dph + tunneltemp + tl_mm + tankrep, data = filtered.moddat, na.action="na.fail" )
 plot(fullmod.speed2) # looks okay with one outlier
 summary((fullmod.speed2)) # nburstGood, tl_mm, and tunnel temp significant
 dredge(fullmod.speed2)
   # best model without CalcConc, dph, or tank rep; WITH nburstGood, tunneltemp, tl_mm
   # 2nd best (dAIC = 1.55) adds calcConc
 
  # this is most parsimonious 
   fullmod.speed2.best = lm(mnburstGood_bls ~ nburstGood + tl_mm + tunneltemp, data = filtered.moddat, na.action="na.fail" )
 
 
fullmod.speed2.fac = lm(mnburstGood_bls ~ factor(color) + nburstGood + dph + tunneltemp + tl_mm + tankrep, data = filtered.moddat, na.action="na.fail" )
 plot(fullmod.speed2.fac) # looks okay with same odd outliers as continuous model
 summary(aov(fullmod.speed2.fac)) # nburstGood, and tl_mm both significant 
 dredge(fullmod.speed2.fac)
   # best model with only nburstGood, tunnel temp, and tl
   # 2nd best (dAIC = 2.11) adds dph

# this is most parsimonious with variable of interest included for plotting
  fullmod.speed2.facbest = lm(mnburstGood_bls ~ factor(CalcConc) + nburstGood +  tl_mm + tunneltemp, data = filtered.moddat, na.action="na.fail" )
  
  
summarize(group_by(filtered.moddat, color), 
           n.reps = n(),
           mean.vel = mean(mnburstGood_bls, na.rm=T), 
           sd.vel = sd(mnburstGood_bls, na.rm=T),
           mean.nburstGood = mean(nburstGood, na.rm=T),
           mean.dph = mean(dph, na.rm=T),
           mean.temp = mean(tunneltemp, na.rm=T),
           mean.tl_mm = mean(tl_mm, na.rm=T))
    # color  n.reps  mean.vel  sd.vel  mean.nburstGood mean.dph  mean.temp  mean.TL
    # white      27     4.96  1.09             8.63     68.0      18.1       9.83
    # green      23     5.39  0.864            9.17     68.2      18.1       8.92
    # yellow     26     5.33  0.927            9.58     67.8      18.0       9.38
    # red        28     5.28  1.46             9.57     67.4      18.0       9.91

``` 


```{r final lm models of participation} 
fullmod.participant2 = lm(nburstGood ~ log(CalcConc+1) + dph + tunneltemp + tl_mm + tankrep, data = filtered.moddat, na.action="na.fail")
 plot(fullmod.participant2) # fine
 summary((fullmod.participant2)) # CalcConc and tl_mm are signficant
 car::vif((fullmod.participant2)) # no issues here
 dredge(fullmod.participant2)  
 # best model CalcConc and tl (most parsimonious)
 # 2nd best (dAIC = 0.52), adds tunneltemp
 # 3rd best (dAIC = 0.78), adds dph
 # 4th best (dAIC = 0.92), adds tunneltemp and dph
 
fullmod.participant2.best = lm(nburstGood ~ log(CalcConc+1) + tl_mm, data = filtered.moddat, na.action="na.fail") 



 
fullmod.participant2.fac = lm(nburstGood ~ factor(color) + dph + tunneltemp + tl_mm + tankrep, data = filtered.moddat, na.action="na.fail")
 plot(fullmod.participant2.fac) 
 summary(aov(fullmod.participant2.fac)) # tl only significant one
 dredge(fullmod.participant2.fac)  
 # best model tl and tunnel temp 
 # 2nd best (dAIC = 0.20), adds CalcConc
 # 3rd best (dAIC = 0.40), adds CalcConc and drops tunneltemp
 # 4th best (dAIC = 0.43), drops tunneltemp  **most parsimonious
 # 5th best (dAIC = 0.52), adds dph
 # 6th best (dAIC = 0.72), adds CalcConc and dph
 # 7th best (dAIC = 1.37), adds CalcConc and dph and drops tunneltemp
 # 8th best (dAIC = 1.43), adds dph and drops tunneltemp
 
fullmod.participant2.facbest = lm(nburstGood ~ factor(color) + tl_mm, data = filtered.moddat, na.action="na.fail") 


 
 
       
```
### SO. For GS and fipronil exposure, fip did not affect the participation rate but DID affect burst speed if we modeled each concentration independently (ie don't force a linaer relationship on it). And there was not an unintentional tank-effect on growth or burst metrics.

```{r add final model preds to plots}
## plot predicted values on top of the previous data-only plots
newdat.vel = expand.grid(CalcConc = unique(filtered.moddat$CalcConc), #seq(0,1600, 20),
                         nburstGood = mean(filtered.moddat$nburstGood), #seq(3,11,1),
                         dph = mean(filtered.moddat$dph), #seq(61,69,1),
                         tl_mm = mean(filtered.moddat$tl_mm),
                         tunneltemp =mean(filtered.moddat$tunneltemp),
                         random.offset = 0) #seq(60,110, 5))
modeloutput = predict(fullmod.speed2.best, newdat.vel, se.fit=TRUE,
                      interval="confidence")#, type="response")

newdat.vel$predictVel = modeloutput[[1]][,"fit"]
newdat.vel$predictVel.se = modeloutput[[2]]
newdat.vel$predictVel.u96ci = modeloutput[[1]][,"upr"]
newdat.vel$predictVel.l95ci = modeloutput[[1]][,"lwr"]


mainplot.bls.predsLM = mainplot.bls + 
         #geom_smooth(data=newdat.vel, aes(x=log(CalcConc+1), y=predictVel)) + 
         geom_errorbar(data=newdat.vel, aes(x=log(CalcConc+1), y=predictVel, 
                       ymin=predictVel.l95ci, ymax=predictVel.u96ci), 
                           width=.25, size=1)   +
         geom_point(data=newdat.vel, aes(x=log(CalcConc+1), y=predictVel), 
                    size=3, pch=17)#, pch=24, fill="grey70", color="black") 
mainplot.bls.predsLM




## plot predicted values on top of the previous data-only plots

modeloutput.fac = predict(fullmod.speed2.facbest, newdat.vel, se.fit=TRUE,
                      interval="confidence")#, type="response")

newdat.vel.fac = newdat.vel

newdat.vel.fac$predictVel = modeloutput.fac[[1]][,"fit"]
newdat.vel.fac$predictVel.se = modeloutput.fac[[2]]
newdat.vel.fac$predictVel.u96ci = modeloutput.fac[[1]][,"upr"]
newdat.vel.fac$predictVel.l95ci = modeloutput.fac[[1]][,"lwr"]


mainplot.bls.preds_FAC = mainplot.bls + 
         #geom_smooth(data=newdat.vel, aes(x=log(CalcConc+1), y=predictVel)) + 
         geom_errorbar(data=newdat.vel.fac, aes(x=log(CalcConc+1), y=predictVel, 
                       ymin=predictVel.l95ci, ymax=predictVel.u96ci), 
                           width=.25, size=1)   +
         geom_point(data=newdat.vel.fac, aes(x=log(CalcConc+1), y=predictVel), 
                    size=3, pch=17)#, pch=24, fill="grey70", color="black") 

mainplot.bls.preds_FAC


# plot for nbursts

newdat.part =  expand.grid(CalcConc = unique(filtered.moddat$CalcConc), #seq(0,1600, 20),
                         tl_mm = mean(filtered.moddat$tl_mm))
modeloutput.part = predict(fullmod.participant2.best, newdat.part, se.fit=TRUE,
                      interval="confidence")#, type="response")

newdat.part$predictnBurst = modeloutput.part[[1]][,"fit"]
newdat.part$predictnBurst.se = modeloutput.part[[2]]
newdat.part$predictnBurst.u96ci = modeloutput.part[[1]][,"upr"]
newdat.part$predictnBurst.l95ci = modeloutput.part[[1]][,"lwr"]


mainplot.participate.lmCC = mainplot.participate + 
          geom_errorbar(data=newdat.part, 
                        aes(x=factor(log(CalcConc+1)), y=predictnBurst, 
                        ymin=predictnBurst.l95ci, ymax=predictnBurst.u96ci), 
                           width=.25, size=1)   +
         geom_point(data=newdat.part, 
                    aes(x=factor(log(CalcConc+1)), y=predictnBurst), 
                    size=3, pch=17)#, pch=24, fill="grey70", color="black") 

# from the 'best' participation model that also included calc conc
  
mainplot.participate.lmCC
  
  


```


```{r write final output figures}

if(write.file=="Yes") {
    # Velocities with lm predictions, holding dph, tl_mm, and nburstGood at mean: 
    tiff(filename = "../figures/Burst_WS2022_velWith_LM_predict.tiff",
     width = 150, height = 80, units = "mm", pointsize = 12,
     compression = c("lzw"), bg = "white", res=300)

      mainplot.bls.predsLM
    
     dev.off()
      
     
    # Velocities with lm predictions using CalcConc as factor, 
    #   while holding dph, tl_mm, and nburstGood at mean:     
     tiff(filename = "../figures/Burst_WS2022_velocityWith_FAC_predict.tiff",
     width = 150, height = 80, units = "mm", pointsize = 12,
     compression = c("lzw"), bg = "white", res=300)

      mainplot.bls.preds_FAC
    
     dev.off()
     
     
     
     
   # Participation with lm predictions, holding dph, tl_mm, and nburstGood at mean: 
     tiff(filename = "../figures/Burst_WS2022_participatWith_LM_predict.tiff",
     width = 135, height = 80, units = "mm", pointsize = 12,
     compression = c("lzw"), bg = "white", res=300)

      mainplot.participate.lmCC
    
     dev.off()
     
}
  

```


### SO. For WS and bifentrhin exposure, bifenthrin positively affected the participation rate (high concentrations of past exposure were correlated with more 'good' bursts in the trial). However, the speed of the burst was correlated with the number of good bursts (those that participated more willingly also went faster) and positively correlated with tunnel temperature (although the range of temps was 17.3-18.4, so perhaps not as biologically significant) and fish length where smaller fish went faster. And there was not an unintentional tank-effect on growth or burst metrics.

### fix length- reads tl_mm but entered as TL-cm

