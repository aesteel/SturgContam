---
title: "Exposure Ethovision Analysis - Data Cleaning"
author: "Anna Steel"
date: "2/24/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(readtext) # need this because the ethovision output .txt files have unusual encoding as UTF-16
library(lme4)
library(circular)
library(rprojroot) # only used for find_rstudio_root_file() to set project wd as root
library(rstatix)
library(chron)

knitr::opts_knit$set(root.dir = find_rstudio_root_file()) # sets root directory to match project directory, not rmd file location
```

```{r utility functions}
# calculate hypotenuse of triangle created by two xy locations

distmov = function(x1,x2,y1,y2) { dm = sqrt((x1-x2)^2 + (y1-y2)^2); return(dm)}

# calculate number steps between detections; use summarized dataset (5 pos/sec)
nstep = function(t2,t1, interv=0.2) {
  if (t2-t1 < 0) stop('time steps backwards?')
  nstep <- ( (t2-t1) / interv)
  return(nstep)
  }

circ.mean.na = function(x) {
  x2 = x[!is.na(x)]
  sinr <- sum(sin(x2))
  cosr <- sum(cos(x2))
  circmean <- atan2(sinr, cosr)
  return(circmean)
}


circ.disp.na = function(x) {
  x2 = x[!is.na(x)]
    n <- length(x2)
    c <- sum(cos(x2))
    s <- sum(sin(x2))
    r <- sqrt(c^2 + s^2)
    rbar <- r/n
    var <- 1 - rbar
    data.frame(n, r, rbar, var)
}

```


## Prep Data for 2021 WS and GS Foraging (Fipronil)
  
The data used here were tracked in Ethovision XT17; settings TBD
  
  
#### Read in metadata 
```{r read directories and file names}
# set directory where .txt files are for each species
GSdatadir = "rawData/Foraging_EthoExport_Complete_GS2021/GSFip_settingsTBD/"
  
# read in file names 
GSfilelist = list.files(path=GSdatadir, pattern="Track-Foraging_GSFip") 
  ## for now I've pulled out everything from Camera 4; issues with tracks and needs editing


# set directory where .txt files are for each species
WSdatadir = "rawData/Foraging_EthoExport_Complete_WS2021/WSFip_Foraging_settingsTBD/"
  
# read in file names 
WSfilelist = list.files(path=WSdatadir, pattern="Track-Foraging_WSFip") 
  ## for now I've pulled out everything from Camera 4; issues with tracks and needs editing



# read in metadata
fdataGS = read.csv("rawData/Foraging_Metadata_GS2021.csv")

fdataWS = read.csv("rawData/Foraging_Metadata_WS2021.csv")

```

#### Read in data
```{r read data}


# prep new column names for datafiles (current ones buried in .txt header)
    datcolNamesWS = c("TrialTime_s","RecTime_s",
                      "Xcent_mm","Ycent_mm",
                      "Area_mm2","AreaChange_mm2","Elong",
                      "DistMoved_mm","Vel",
                      "InZone_FZ1","InZone_FZ2","InZone_FZ3","InZone_FZ4",
                      "InZone_Any",  
                      "MeanderAbs_degMM","TurnAngleAbs_deg",
                      "MeanderRel_degMM","TurnAngleRel_deg",
                      "X1")

    datcolNamesGS = c("TrialTime_s","RecTime_s",
                      "Xcent_mm","Ycent_mm",
                      "Area_mm2","AreaChange_mm2","Elong",
                      "DistMoved_mm","Vel",
                      "InZone_FZ1","InZone_FZ2","InZone_FZ3","InZone_FZ4",
                      "MeanderRel_degMM","TurnAngleRel_deg",
                      "InZone_Any",  
                      "MeanderAbs_degMM","TurnAngleAbs_deg",
                      "X1")

 
# function to read and ammend ethovision files to compile later     
 readTrialDat.func =function(datadir, datcolNames, x) {
      trialidat = read.csv(paste0(datadir, x), sep=",", 
                           skip=40, header=F, fileEncoding="UTF-16")
      trialheader = read.csv(paste0(datadir, x), sep=",",
                             header=F, fileEncoding="UTF-16")[1:40,]
      names(trialidat) = datcolNames
      trialidat$X1 <-NULL
      
      trialidat$EthoTrialName<- trialheader[4,2]
      trialidat$TrackLength <- trialheader[16,2]
      trialidat$TrialDateTime <- trialheader[20,2]
      trialidat$SubjectNotFound <- trialheader[30,2]
      trialidat$color <- trialheader[33,2]
      trialidat$rep <- trialheader[34,2]
      trialidat$barrel <- trialheader[35,2]
      trialidat$exptTrialID <- trialheader[36,2]
      trialidat$prepost <- trialheader[37,2]

      
    Treatment = paste0(trialidat$color[1], "-", trialidat$prepost[1])
    print(Treatment) 
      # check point to make sure it's working correctly; can comment out if it is
      
      return(trialidat) 
    }
    
    
# do.call function to use above function to read and then rbind all the trial datafiles into one df per species    

  WSdata = do.call(rbind, lapply(WSfilelist, readTrialDat.func, datadir = WSdatadir,  datcolNames = datcolNamesWS) )
  
  
  GSdata = do.call(rbind, lapply(GSfilelist, readTrialDat.func, datadir = GSdatadir,  datcolNames = datcolNamesGS) )

```

```{r corrections}

WSdatasub = WSdata
GSdatasub = GSdata

```

#### summarize the data into larger time-chunks to facilitate analysis and visualization (the large dataset doesn't move particularly fast...). Recorded with 30 positions per second, summarized those to 5 positions per second (each trial thus created 6000 positions over 13.5 minutes, if all data were collected).    

#### Also add datacolumn for distanced moved where NA is replaced with 0 

```{r cut WS data}

WSdatasub = WSdatasub[,c("color","prepost","rep","barrel", 
                         "EthoTrialName","TrackLength","TrialDateTime","exptTrialID",
                      "SubjectNotFound","TrialTime_s","RecTime_s",
                      "Xcent_mm","Ycent_mm",
                      "DistMoved_mm","Vel","TurnAngleRel_deg",
                      "InZone_FZ1","InZone_FZ2","InZone_FZ3","InZone_FZ4","InZone_Any")]

WSdatasub$cut = cut_width(WSdatasub$RecTime_s, 0.2, boundary=0, labels=F)

WSdatasum = WSdatasub %>%
  group_by(color, prepost, rep, barrel, TrackLength, SubjectNotFound,
           EthoTrialName, TrialDateTime, exptTrialID, cut) %>%
  summarize(TrialTime = round(mean(RecTime_s),1),
            Xcent = mean(Xcent_mm, na.rm=T),
            Ycent = mean(Ycent_mm, na.rm=T),
            MnDistMoved = mean(DistMoved_mm, na.rm=T),
            SumDistMoved = sum(DistMoved_mm, na.rm=T),
            #Meander = mean(Meander_degmm, na.rm=T),
            #CircMnTurnAngleAbs = deg(circ.mean.na(rad(TurnAngleAbs_deg))),
            SumTurnAngleRel = sum(TurnAngleRel_deg, na.rm=T),
            InZone_FZ1 = max(InZone_FZ1),
            InZone_FZ2 = max(InZone_FZ2),
            InZone_FZ3 = max(InZone_FZ3),
            InZone_FZ4 = max(InZone_FZ4),
            InZone_Any = max(InZone_Any)) %>%
  ungroup() %>%
  data.frame()

# rather than summarize the meander at each step, recalculate it at these summarized steps by taking the mean heading (turn angle over the 0.2 secs) and divide it by the total distance moved in that same period, following the calculations made by Ethovision to calculate meander. 
WSdatasum$Meander = WSdatasum$SumTurnAngleRel/WSdatasum$SumDistMoved
WSdatasum$spp<-"WS"

```
```{r add calc conc}
chemcsv.raw = read.csv("/Users/Anna/Documents/ResearchGit/SturgContam/rawData/ChemAnalysis_Fipronil_2021_Summary.csv")

chemcsv = chemcsv.raw %>%
  filter(sample=="spike" & chemical=="fipronil") %>%
  select(chemical, spp, nomconc, calcConc) %>%
  mutate(color = rep(c("White","Green","Yellow","Red","Pink","Blue"), 2))
  
chemcsvWS = filter(chemcsv, spp=="WS")
WSdatasum1 <- merge(WSdatasum, chemcsvWS[,c("nomconc","calcConc","color")], by="color", all.x=T)

```

## add metadata
```{r add metadata to WS}

WSdatasum2 = merge(WSdatasum1,
                   fdataWS[,c("spp","nomconc","trialIID","barrel",
                              "hatchdate","dph","treattemp","colorRep","ExposeRep",
                              "accstart","foodstart","testtemp","tlmm","massg")],
                   by.x=c("spp","nomconc","exptTrialID","barrel"),
                   by.y=c("spp","nomconc","trialIID","barrel"), 
                   all.x=T)

```


```{r cut GS data}

GSdatasub = GSdatasub[,c("color","prepost","rep","barrel", 
                         "EthoTrialName","TrackLength","TrialDateTime","exptTrialID",
                      "SubjectNotFound","TrialTime_s","RecTime_s",
                      "Xcent_mm","Ycent_mm",
                      "DistMoved_mm","Vel","TurnAngleRel_deg",
                      "InZone_FZ1","InZone_FZ2","InZone_FZ3","InZone_FZ4","InZone_Any")]

GSdatasub$cut = cut_width(GSdatasub$RecTime_s, 0.2, boundary=0, labels=F)

GSdatasum = GSdatasub %>%
  group_by(color, prepost, rep, barrel, TrackLength, SubjectNotFound,
           EthoTrialName, TrialDateTime, exptTrialID, cut) %>%
  summarize(TrialTime = round(mean(RecTime_s),1),
            Xcent = mean(Xcent_mm, na.rm=T),
            Ycent = mean(Ycent_mm, na.rm=T),
            MnDistMoved = mean(DistMoved_mm, na.rm=T),
            SumDistMoved = sum(DistMoved_mm, na.rm=T),
            #Meander = mean(Meander_degmm, na.rm=T),
            #CircMnTurnAngleAbs = deg(circ.mean.na(rad(TurnAngleAbs_deg))),
            SumTurnAngleRel = sum(TurnAngleRel_deg, na.rm=T),
            InZone_FZ1 = max(InZone_FZ1),
            InZone_FZ2 = max(InZone_FZ2),
            InZone_FZ3 = max(InZone_FZ3),
            InZone_FZ4 = max(InZone_FZ4),
            InZone_Any = max(InZone_Any)) %>%
  ungroup() %>%
  data.frame()

# rather than summarize the meander at each step, recalculate it at these summarized steps by taking the mean heading (turn angle over the 0.2 secs) and divide it by the total distance moved in that same period, following the calculations made by Ethovision to calculate meander. 
GSdatasum$Meander = GSdatasum$SumTurnAngleRel/GSdatasum$SumDistMoved
GSdatasum$spp<-"GS"
```

```{r add calc conc}
# see parallel chunk above for set up

chemcsvGS = filter(chemcsv, spp=="GS")
GSdatasum1 <- merge(GSdatasum, chemcsvGS[,c("nomconc","calcConc","color")], by="color", all.x=T)

```
## add metadata
```{r add metadata to GS}

GSdatasum2 = merge(GSdatasum1,
                   fdataGS[,c("spp","nomconc","trialIID","barrel",
                              "hatchdate","dph","treattemp","colorRep","ExposeRep",
                              "accstart","foodstart","testtemp","tlmm","massg")],
                   by.x=c("spp","nomconc","exptTrialID","barrel"),
                   by.y=c("spp","nomconc","trialIID","barrel"), 
                   all.x=T)

```



#### combine WS and GS
```{r comb data}

DataSum = rbind(WSdatasum2, GSdatasum2)

DataSum$uniqueID = paste(DataSum$spp, DataSum$color, DataSum$prepost, DataSum$exptTrialID, sep="-")

```


#### write out cleaned dataframe for use in subsequent codes
```{r write out data, echo=FALSE, eval=FALSE}

write.csv(DataSum, "outputData/Foraging_GSWS_Fipronil2021_Cleaned_Conc.csv", row.names=F)

```
























Old Code:

Insert ~ ln200

#### interpolate missing datapoints - testing testing fail
```{r interpolate attempt1, eval=FALSE, include=FALSE}
# about 6% of the timepoints in the reduced dataset are missing data at the MnDistMoved column (41,006 out of 669,600 total) because of removed data points in filtering
# of those the vast majority are GS (40173 of 41006) because of the poorer recording conditions

# here I remove all rows without X and Y centroids, and use my own function to calculate distance moved between the summarized centroids. I can't use this abbreviated dataset 

DataSum2496nom_dist = DataSum2496nom %>%
  group_by(uniqueID) %>%
  subset(!is.na(MnDistMoved)) %>%
  mutate(SumDistMoved.Abbrev = distmov(x1=lag(Xcent), x2=Xcent, y1=lag(Ycent), y2=Ycent) ) %>%
  ungroup() %>%
  data.frame()
           
# merge it back into the interpolated data 
DS = merge(DataSum2496nom, DataSum2496nom_dist[, c("lineID","SumDistMoved.Abbrev")], by="lineID", all.x=T)



# look at point differences when use these two methods; does it vary by species, treatment, or time?
ggplot(DS, aes(x=factor(Treatment), y=(SumDistMoved - SumDistMoved.Abbrev) ) ) + 
         geom_point() + geom_hline(yintercept=0, col="steelblue3") + 
         facet_grid(ExposureHrs~Spp) + 
         ylab("Difference in Distance Moved\nCalculated at 30fps vs 4fps centroids") + 
         theme_bw()
# removed 41,192 rows without data

# A negative number indicates that the distance calculated from 5fps centroids is greater than the distance calculated from 30fps. This makes sense because if there is a missing point between two detections, the distance between those detections isn't included in the total estimate of distance by ethovision but with my code it is included and assumed to be a straight line (underestimate). Additionall;y, with this code any erroneous points that weren't filtered out successfully (likely because they didn't cause a distance to be recorded in the ethovision track, but the points were still present), the erroneous points are included in the interpolation and additional ines are drawn from the fish tothe cross-dish reflection and back. Argh. However, sometimes the 5fps is smaller than 30 fps (positive point) because there was tortuosity in the path that was eliminated during abbreviation/summarization step going from 20-5fps. 

# it seems as though the difference is larger for GS, which makes sense if it's linked to poor detections, extra manual filtering, and both missing and erroneous points. 


# look at differences in total distance for each trial 
DS.totaldist = DS %>%
  group_by(Spp, Treatment, ExposureHrs, Replicate, Arena) %>%
  summarize(total.dist.30fps = sum(SumDistMoved, na.rm=T), 
            total.dist.5fps = sum(SumDistMoved.Abbrev, na.rm=T)) %>%
  data.frame()

ggplot(subset(DS.totaldist, Spp=="GS"), aes(x=Replicate, y=total.dist.30fps)) + 
  geom_point(pch=16, color="green3") + geom_point(aes(y=total.dist.5fps), pch=16, color="steelblue3") +
  facet_grid(ExposureHrs ~ Treatment)

ggplot(subset(DS.totaldist, Spp=="WS"), aes(x=Replicate, y=total.dist.30fps)) + 
  geom_point(pch=17, color="green3") + geom_point(aes(y=total.dist.5fps), pch=16, color="steelblue3") +
  facet_grid(ExposureHrs ~ Treatment)

# 30fps is always longer total distance than 5fps but the trends seem consistent and there doesn't seem to be an obvious visual bias by treatment

DS.distsd = DS.totaldist %>%
  group_by(Spp, Treatment, ExposureHrs) %>%
  summarize(sd.30fps = sd(total.dist.30fps, na.rm=T), 
          sd.5fps = sd(total.dist.5fps, na.rm=T)) %>%
  ungroup() %>%
  data.frame()

ggplot(DS.distsd, aes(x=factor(Treatment), y=sd.30fps)) + 
  geom_point(pch=17, color="green3") + geom_point(aes(y=sd.5fps), pch=16, color="steelblue3") +
  facet_grid(Spp ~ ExposureHrs) 
# variance among trials is simliar for GS but slightly lower at 5fps, but for WS the trend isn't as clear. At 24hrs, the variance is higher with 5fps uexcept for the 2000 exposure, and at 96hrs its all over the board, but generally the 30fps is higher (100, 1000, 2000), but sometimes lower (1000) and sometimes the same (0, 5).  

```

```{r interpolation notes only, eval=FALSE, include=FALSE}

## To summarize (8/18/2021) I've attempted to explore the usefulness of calculating distance moved from the 30fps dataset in ethovision, or calculating distance moved from the 5fps dataset after it has been condensed/sumarized. In the step for re-calculating distance after the fact, I've also used all sequential locations and assumed linear paths between them, even when there were substantial temporal gaps between detections. The results from this do not lead in a clear direction for continued analysis. The options are:   
#1) use Ethovision's estimated distance, and de-facto assume the fish is still when the track is lost (often true but not always)  
#2) use distances calculated here, at 5 fps, but this feels unsatisfying because it is clear that this does lose some tortuosity (unclear whether that is real or erronious, but if we're trusting the software and post-processing then we must assume it's largely real).  Also, upon a second review of the editing process, there were occational erroneous points left in as long as they didn't create long-distance movements. So with the ethovision distance estimate, erroneous points should not have a large effect. However, if I interpolate between all existing points then I'll be adding these long-distance erroneous movement to/from the reflection point BACK into the distance estimate. This is not correct, and likely more of a problem then the assumption that missing data = stationary fish. So this choice isn't preferable. 
#3) re-jigger this code to calculate post-hoc distance moved for 30fps but for all sequential detections. This seems the most satisfying because it won't lose the tortuosity of the track but it will allow us to estimate an distance moved when the software loses a moving fish (if it is stationary it will also account for that). However, again, there is the3 issue with the poor detection/reflection and the limited editing. I think the editing is fine for if I use the ethovision distances, but maybe problematic if I interpolate. 

#- so after all this days work, I think perhaps we go with the data we have, fill in the zeros for moving/not moving, fill in the zone ID for the last known location, and start the analysis. 
#- Analysis will include four output variables for effects of treatment and time for each species: distance = activity index; % time active = activity index; turning or meander = directionality (body control?), center zone = thigmotaxis and boldness). Two four-panel plots to show results (raw and predicted? just raw?). 
```
