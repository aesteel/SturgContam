---
title: "Exposure_Analysis3 - Model Selection"
author: "Anna Steel"
date: "9/3/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(readtext) # need this because the ethovision output .txt files have unusual encoding as UTF-16
library(lme4)
library(rethinking)
library(rprojroot) # only used for find_rstudio_root_file() to set project wd as root
library(patchwork)
library(circular)
library(chron)
library(rstatix)
library(viridis)

knitr::opts_knit$set(root.dir = find_rstudio_root_file()) # sets root directory to match project directory, not rmd file location
```

```{r utility functions, include=FALSE}
# calculate hypotenuse of triangle created by two xy locations

distmov = function(x1,x2,y1,y2) { dm = sqrt((x1-x2)^2 + (y1-y2)^2); return(dm)}

# calculate number steps between detections; use summarized dataset (5 pos/sec)
nstep = function(t2,t1, interv=0.2) {
  if (t2-t1 < 0) stop('time steps backwards?')
  nstep <- ( (t2-t1) / interv)
  return(nstep)
  }


circ.mean.na = function(x) {
  x2 = x[!is.na(x)]
  sinr <- sum(sin(x2))
  cosr <- sum(cos(x2))
  circmean <- atan2(sinr, cosr)
  return(circmean)
}


circ.disp.na = function(x) {
  x2 = x[!is.na(x)]
    n <- length(x2)
    c <- sum(cos(x2))
    s <- sum(sin(x2))
    r <- sqrt(c^2 + s^2)
    rbar <- r/n
    var <- 1 - rbar
    data.frame(n, r, rbar, var)
}

```


## Read in Cleaned Data ("Exposure_Analysis1.Rmd")
```{r read in clean data}
DataSum96.raw = read.csv("outputData/Exposure_Outputdata/Fipronil_2021_Cleaned_NoConc_96hrs.csv")

# can repeat for more exposure timepoints later, if desired
```

## Add measured concentrations (versus nominal)
```{r chem analysis results}
chemcsv.raw = read.csv("//Users/Anna/Documents/ResearchGit/SturgContam/rawData/ChemAnalysis_Fipronil_2021_Summary.csv")
  chemcsv <- chemcsv.raw[chemcsv.raw$chemical=="fipronil" & chemcsv.raw$sample=="spike", c("spp", "nomconc", "calcConc")]
 
  
DataSum96 <- merge(DataSum96.raw, chemcsv, by.x=c("Spp","Treatment"), by.y=c("spp","nomconc"), all.x=T)
 DataSum96$calcConc = as.numeric(DataSum96$calcConc)
 
```
# this uses 'spike' water analysis, and will report final composite sample in the paper. I think. Remember these were the chemical analysis results that were odd...likely because we used two seperate stock solutions for <100 and >500, which had been mixed by someone else and which were 2-3 months old when I used them. Used the same ones for both GS and WS, and they likely were degrading in the refridgerator between exposures. The best explanation for the chem results we saw was that there were high levels of degredate in the stock solution prior to initiation of the trial, leading to high levels for many of the chemical constituants for the 500 and 1000 ug/L exposures. 

## Add water temps at end of trial
```{r add indiv water temp increase}
gstemp = read.csv("//Users/Anna/Documents/ResearchGit/SturgContam/rawData/Exposure_IndivBehaviorVideo_GS2021_Temps.csv")
wstemp = read.csv("//Users/Anna/Documents/ResearchGit/SturgContam/rawData/Exposure_IndivBehaviorVideo_WS2021_Temps.csv")

# interpolate missing temps 
tempdat = rbind(gstemp, wstemp)
tempdat$time <- times(paste0(tempdat$time, ":00"))

ggplot(data=tempdat, aes(x=time, y=endtemp)) + geom_point()

tempdat.redu = tempdat[!(tempdat$Exposure.Hr=="24" & tempdat$species=="WS" & tempdat$Tray %in% c("A","B","C","D")),] # legitimate notes for high temps for A,B, but also outliers for c,d if we're trying to make a high quality line for temp relationship with exposure video times
 ggplot(data=tempdat.redu, aes(x=time, y=endtemp)) + geom_point(aes(color=species))

templm = lm(endtemp ~ time + species, data=tempdat.redu)
 summary(templm) # temp = 6.83281 + 21.94528*time + 0.42187*WS + error
 plot(templm)

tempdat$pred.endtemp[tempdat$species=="GS"] = 6.83281 + 21.94528*tempdat$time[tempdat$species=="GS"]

tempdat$pred.endtemp[tempdat$species=="WS"] = 6.83281 + 21.94528*tempdat$time[tempdat$species=="WS"] + 0.42187

ggplot(tempdat, aes(x=endtemp, y=pred.endtemp, color=species)) + geom_point() + geom_line(data = data.frame(x=14:20, y=14:20), aes(x=x, y=y), color="black", lty=2)

DataSum96.T = merge(DataSum96, tempdat, by.x=c("Spp","ExposureHrs","Tray","Replicate"), by.y=c("species","Exposure.Hr","Tray","rep"), all.x=T)
 # this uses the control as a sample for all of the corresponding replicate numbers

```


### remove results for GS trial 8 until can review them in ethovision; all six concentrations had very high distances for this trial at 96 hrs, and not at any other timepoints. Look suspecious and likely an Ethovision error? Temps normal, but experiment notes say I set a box of glass bottles on the video cabinet bottom shelf during this trial, so perhaps moved camera 4 too much to get good tracks? 
```{r remove trial 8-GS}
DataSum96 = DataSum96[!(DataSum96$Replicate==8 & DataSum96$Spp=="GS"),]

```


# plots and exploration are in Exposure_Analysis2, with select plots copied here



# Statistical Models, predictions, and other posterior queries for each metric (Total distance travelled, Mean velocity, Meander and Turn angle, Use of center zone (% time), Time Active, Full Rotations vs distance traveled) 


## Distance #####
```{r distance data, echo=F}

## Summarize to take total distance (sum moved in a trial) for each fish replicates
DataSum96.dist = DataSum96.T %>%
  group_by(index, Trial, Arena, Replicate, ExposureHrs, Treatment, calcConc, Spp, Tray, RepID, pred.endtemp) %>%
  summarize(TotalfishDist_m = sum(SumDistMoved, na.rm=T)/(10*100)) %>%
  ungroup()  %>%
  
  mutate(lnCalcConc = log(calcConc+1)) %>%
  mutate(lnCalcConc2 = (log(calcConc+1))^2) %>%
  #mutate(lnCalcConcC= scale(lnCalcConc, scale=FALSE)) %>%
  #mutate(lnCalcConcC2 = lnCalcConcC^2 ) %>% 
   # order of transformations matters (log then scale then square)

  data.frame()


```

```{r distance rawdata plots}
# classic veridis box plots
totfishdist96 = ggplot(DataSum96.dist, aes(fill=factor(Treatment), y=TotalfishDist_m, 
                               x=factor(ExposureHrs) ) ) + 
                      geom_boxplot(outlier.size = .75) + 
                      facet_wrap(~Spp, labeller = labeller(
                        Spp = c("GS"="Green Sturgeon","WS"="White Sturgeon")),#)+
                        scales="free") +
                      ylab("Total Trial Distance (m)") + 
                      xlab("Exposure Hours") +
                      scale_fill_viridis_d(name="Nominal Fpironil\nConcentration (ug/L)") + 
                      theme_bw()

totfishdist96

# change from paired control
  # 
  # DataSum96.dist.cont = DataSum96.dist[DataSum96.dist$Treatment==0, c("Spp","ExposureHrs","Replicate","Tray","TotalfishDist_m")]
  #    DataSum96.dist.cont = rename(DataSum96.dist.cont,
  #                                  ControlTotaldist = TotalfishDist_m)
  #    
  # DataSum96.dist.treat = DataSum96.dist[DataSum96.dist$Treatment!=0, c("Spp","ExposureHrs","Replicate","Tray","calcConc","TotalfishDist_m")]
  # 
  # DataSum96.dist.pseudowide = merge(DataSum96.dist.treat, DataSum96.dist.cont, all.x=T)
  # 
  # dist.dist.func = function(a,b) { 
  #   g <- expand.grid(data.frame(a, b))
  #   PercDiff <- (g$b - g$a)/g$a
  #   return(PercDiff) 
  #   }
  #   
  # PercChg = DataSum96.dist.pseudowide %>%
  #   group_by(Spp, calcConc, Replicate) %>%
  #   summarize(PercChg = dist.dist.func(a=ControlTotaldist, b=TotalfishDist_m)) %>%
  #            ungroup() %>% data.frame()
  # 
  # 
  # DistnChgfishdist = ggplot(PercChg, 
  #                          aes(y=PercChg, x=factor(calcConc)) ) + 
  #                        geom_hline(yintercept = 0, lwd=.6, linetype="dashed", color="black")+
  #                        geom_boxplot(fill="grey60") + 
  #                        facet_grid(.~Spp, labeller = labeller(
  #                          Spp = c("GS"="Green Sturgeon","WS"="White Sturgeon")) )+
  #                        geom_hline(yintercept = (-0.5), lwd=.6, 
  #                                   linetype="dashed", color="red")+
  #                        ylab("Percent Change in Swimming Distance (m)") + 
  #                        xlab("Fipronil Nominal Conc") +
  #                        theme_bw()
  # DistnChgfishdist
  # 
  # MeanPercChgDistns = PercChg %>%
  #   group_by(Spp, ExposureHrs, calcConc) %>%
  #   summarize(mean_PercChg = mean(PercChg, na.rm=T), median_PercChg = median(PercChg, na.rm=T), sd_PercChg = sd(PercChg, na.rm=T)) %>%
  #   ungroup() %>% data.frame()
  # 
  # 
  # 
  # DistnChgfishdist.mean = ggplot(MeanPercChgDistns, 
  #                          aes(y=mean_PercChg, x=factor(calcConc)) ) + 
  #                        geom_hline(yintercept = 0, lwd=.6, color="black")+
  #                        geom_col(fill="grey60") + 
  #                        geom_errorbar(aes(ymin = mean_PercChg-sd_PercChg,
  #                                          ymax = mean_PercChg+sd_PercChg), width=.15)+
  #                        facet_grid(ExposureHrs~Spp, labeller = labeller(
  #                          Spp = c("GS"="Green Sturgeon","WS"="White Sturgeon"),
  #                          ExposureHrs = c("24"="24 hrs", "48" = "48 hrs",
  #                                          "72" = "72 hrs", "96"="96 hrs")))+
  #                        geom_hline(yintercept = (-0.5), lwd=.6, 
  #                                   linetype="dashed", color="red")+
  #                       # geom_hline(yintercept = (-0.2), lwd=.6, 
  #                                   #linetype="dashed", color="blue")+
  #                        ylab("Percent Change in Swimming Distance (m)") + 
  #                        xlab("Fipronil Nominal Conc") +
  #                        theme_bw()
  # DistnChgfishdist.mean

```


```{r distance frequentist models}

DataSum96.distGS = DataSum96.dist[DataSum96.dist$Spp=="GS",]
DataSum96.distWS = DataSum96.dist[DataSum96.dist$Spp=="WS",]

# basic linear models, no random effects nor polynomials
dist.lmfactGS = lm(TotalfishDist_m ~ factor(Treatment),#lnCalcConc, # 
               data=DataSum96.distGS)
dist.aovGS = summary(aov(dist.lmfactGS))
dist.aovGS
 TukeyHSD(aov(dist.lmfactGS)) # no significant effects
 
dist.lmfactWS = lm(TotalfishDist_m ~ factor(Treatment),#lnCalcConc, # 
               data=DataSum96.distWS)
dist.aovWS = summary(aov(dist.lmfactWS))
dist.aovWS
 TukeyHSD(aov(dist.lmfactWS)) # 1000 is sig dif from all others, no other effects
 
 
# add random effect for tray (stand in for testing time and location in water bath) and polynomial effect of conc. 
dist.lmGS = lm(TotalfishDist_m ~ lnCalcConc + lnCalcConc2 + pred.endtemp,
               data=DataSum96.distGS) 
 summary(dist.lmGS) # adding the temp only altered the intercept but not the effect of contaminant at all. That's nice. But then again, there was no effect of contaminant, so not really important afterall. 
dist.lmmGS = lmer(TotalfishDist_m ~ lnCalcConc + lnCalcConc2 + pred.endtemp + (1|Tray), data=DataSum96.distGS)
 summary(dist.lmmGS) # same as the non-mixed model. Adding the temp only blows up the std.error and doesn't change the effect of concentration. 


dist.lmWS = lm(TotalfishDist_m ~ lnCalcConc + lnCalcConc2 + pred.endtemp,
               data=DataSum96.distWS, na.action=na.fail) 
 summary(dist.lmWS) # temp is more important here; makes sense because the fish moved more and there was generally more capacity to detect differences
  # all the variables are significant. These are so much harder to interpret
 dredge(dist.lmWS)
  # best mdoel includes all variable. Of course. Model without temp only has weight of 0.022 (second best model), delta AIC of 7.62
 ## emmeans for dist.lmWS??
 
dist.lmmWS = lmer(TotalfishDist_m ~ lnCalcConc + lnCalcConc2 + pred.endtemp + (1|Tray), data=DataSum96.distWS, na.action=na.fail) 
 summary(dist.lmmWS) # adding the random effect makes the effect estimate for temp stronger, actually. That's interesting...I'd have thought it would take away explanatory value from the temp variable. 
 dredge(dist.lmmWS) # model without temp is second still, and has weight of 0.091, deltaAIC of 4.6

 ## emmeans for dist.lmWS??

### I prefer mixed models due to thier appropriateness for the data structure and the slightly smaller standard error for the effects; however, I can't get SE for the plot with these models, and so will use the lm for the presentation graphs because it is much more straight foward to get SE ###

```

## plot frequentist model predictions
```{r model predictions}
preddat.WS = data.frame(lnCalcConc= unique(DataSum96.distWS$lnCalcConc),
                        pred.endtemp = rep(mean(DataSum96.distWS$pred.endtemp),6))#,
                        #Tray = rep("Z",6))
preddat.WS$lnCalcConc2 = preddat.WS$lnCalcConc^2
preddat.WS = preddat.WS[order(preddat.WS$lnCalcConc),]
                                           
WSpreds = predict(dist.lmWS, newdata=preddat.WS, se.fit=TRUE) #allow.new.levels = TRUE)
preddat.WS$predTotalDist_m = WSpreds$fit
preddat.WS$predSE_TotalDist_m = WSpreds$se.fit
  preddat.WS$spp="WS"

                
                
preddat.GS = data.frame(lnCalcConc= unique(DataSum96.distGS$lnCalcConc), pred.endtemp = rep(mean(DataSum96.distGS$pred.endtemp),6))#, Tray = rep("Z",6) )
preddat.GS$lnCalcConc2 = preddat.GS$lnCalcConc^2
preddat.GS = preddat.GS[order(preddat.GS$lnCalcConc),]
                        
GSpreds = predict(dist.lmGS, newdata=preddat.GS, se.fit=TRUE) #allow.new.levels = TRUE)
preddat.GS$predTotalDist_m = GSpreds$fit
preddat.GS$predSE_TotalDist_m = GSpreds$se.fit
  preddat.GS$spp="GS"
  
 preddat = rbind(preddat.GS, preddat.WS)

 # plot model predictions with raw conc scale
ggplot(preddat, aes(x=exp(lnCalcConc), y=predTotalDist_m, fill=spp)) +
  geom_errorbar(aes(ymin = predTotalDist_m - predSE_TotalDist_m, 
                    ymax = predTotalDist_m + predSE_TotalDist_m)) + 
  geom_line(size=0.7) + 
  geom_point(pch=21, size=3) + 
  scale_fill_manual(values=c("GS"="green3","WS"="grey80"),
                    labels=c("Green Sturgeon","White Sturgeon"),
                    name="Species") + 
  scale_y_continuous(name="Total Distance Traversed (cm)", 
                     breaks=seq(0,30,5), 
                     labels=seq(0,30,5)*100, 
                     limits=c(0,29)) + 
  xlab("Fipronil Concentration (ug/L)") +
  theme_bw()

 # plot model predictions with log conc scale
ggplot(preddat, aes(x=(lnCalcConc), y=predTotalDist_m, fill=spp)) +
  geom_errorbar(aes(ymin = predTotalDist_m - predSE_TotalDist_m, 
                    ymax = predTotalDist_m + predSE_TotalDist_m)) + 
  geom_smooth(method="loess", color="black", size=.7) + 
  geom_point(pch=21, size=3) + 
  scale_fill_manual(values=c("GS"="green3","WS"="grey80"),
                    labels=c("Green Sturgeon","White Sturgeon"),
                    name="Species") + 
  scale_y_continuous(name="Total Distance Traversed (cm)", 
                     breaks=seq(0,30,5), 
                     labels=seq(0,30,5)*100, 
                     limits=c(0,29)) + 
  xlab("Fipronil Concentration (ug/L)") +
  theme_bw()


## plot model predictions over raw boxplots
chemcsv$lnCalcConc = log(as.numeric(chemcsv$calcConc)+1)
preddat2 = merge(preddat, chemcsv, all.x=T)
preddat2$ExposureHrs=96
preddat2 = rename(preddat2, c(Treatment=nomconc, Spp=spp))

totfishdist96.pred = ggplot(DataSum96.dist, aes(fill=factor(Treatment), y=TotalfishDist_m, 
                               x=factor(Treatment)) ) + 
                      geom_boxplot(outlier.size = .75) + 
                      geom_errorbar(data=preddat2, 
                                    aes(x=factor(Treatment), y=predTotalDist_m,
                                        ymin = predTotalDist_m - predSE_TotalDist_m, 
                                        ymax = predTotalDist_m + predSE_TotalDist_m),
                                    color="grey60", width=.2) + 
                      geom_point(data=preddat2, 
                                 aes(x=factor(Treatment), y=predTotalDist_m), 
                                 pch=21, size=3, fill="grey60") +
                      facet_wrap(~Spp, labeller = labeller(
                        Spp = c("GS"="Green Sturgeon","WS"="White Sturgeon")),#)+
                        scales="free") +
                      ylab("Total Trial Distance (m)") + 
                      xlab("Fipronil Concentration (ug/L)") +
                      scale_fill_viridis_d(name="Nominal Fpironil\nConcentration (ug/L)")+ 
                      theme_bw()
totfishdist96.pred
```                  


```{r models and plots without top two conc}
#MODELS
dist.lmGS.redu = lm(TotalfishDist_m ~ lnCalcConc + lnCalcConc2 + pred.endtemp,
               data=DataSum96.distGS[DataSum96.distGS$Treatment %in% c(0,1,10,100),]) 
 summary(dist.lmGS.redu) 
 
dist.lmWS.redu = lm(TotalfishDist_m ~ lnCalcConc + lnCalcConc2 + pred.endtemp,
               data=DataSum96.distWS[DataSum96.distWS$Treatment %in% c(0,1,10,100),]) 
 summary(dist.lmWS.redu) 

#PREDICTIONS
preddat.WS.redu = data.frame(lnCalcConc= unique(DataSum96.distWS[DataSum96.distWS$Treatment %in% c(0,1,10,100),"lnCalcConc"]),
                        pred.endtemp = rep(mean(DataSum96.distWS[DataSum96.distWS$Treatment %in% c(0,1,10,100),"pred.endtemp"]),4))
preddat.WS.redu$lnCalcConc2 = preddat.WS.redu$lnCalcConc^2
preddat.WS.redu = preddat.WS.redu[order(preddat.WS.redu$lnCalcConc),]
                                           
WSpreds.redu = predict(dist.lmWS.redu, newdata=preddat.WS.redu, se.fit=TRUE) 
preddat.WS.redu$predTotalDist_m = WSpreds.redu$fit
preddat.WS.redu$predSE_TotalDist_m = WSpreds.redu$se.fit
  preddat.WS.redu$spp="WS"

                
                
preddat.GS.redu = data.frame(lnCalcConc= unique(DataSum96.distGS[DataSum96.distGS$Treatment %in% c(0,1,10,100),"lnCalcConc"]), pred.endtemp = rep(mean(DataSum96.distGS[DataSum96.distGS$Treatment %in% c(0,1,10,100),"pred.endtemp"]),4))
preddat.GS.redu$lnCalcConc2 = preddat.GS.redu$lnCalcConc^2
preddat.GS.redu = preddat.GS.redu[order(preddat.GS.redu$lnCalcConc),]
                        
GSpreds.redu = predict(dist.lmGS.redu, newdata=preddat.GS.redu, se.fit=TRUE) 
preddat.GS.redu$predTotalDist_m = GSpreds.redu$fit
preddat.GS.redu$predSE_TotalDist_m = GSpreds.redu$se.fit
  preddat.GS.redu$spp="GS"
  
 preddat.redu = rbind(preddat.GS.redu, preddat.WS.redu) 
 
#PLOTS 
chemcsv$lnCalcConc = log(as.numeric(chemcsv$calcConc)+1)
preddat2.redu = merge(preddat.redu, chemcsv, all.x=T)
preddat2.redu = rename(preddat2.redu, c(Treatment=nomconc, Spp=spp)) 
fourcolors = viridis(6)[1:4] 

totfishdist96.pred.redu = ggplot(DataSum96.dist[DataSum96.dist$Treatment %in% c(0,1,10,100),],
                            aes(fill=factor(Treatment), y=TotalfishDist_m, 
                               x=factor(Treatment)) ) + 
                      geom_boxplot(outlier.size = .75) + 
                      geom_errorbar(data=preddat2.redu, 
                                    aes(x=factor(Treatment), y=predTotalDist_m,
                                        ymin = predTotalDist_m - predSE_TotalDist_m, 
                                        ymax = predTotalDist_m + predSE_TotalDist_m),
                                    color="grey30", width=.2, size=.3) + 
                      geom_point(data=preddat2.redu, 
                                 aes(x=factor(Treatment), y=predTotalDist_m), 
                                 pch=21, size=3, fill="grey60", color="grey30") +
                      facet_wrap(~Spp, labeller = labeller(
                        Spp = c("GS"="Green Sturgeon","WS"="White Sturgeon")),#)+
                        scales="free") +
                      scale_y_continuous(name="Total Distance Traversed (cm)", 
                                         breaks=seq(0,40,5), 
                                         labels=seq(0,40,5)*100, 
                                         limits=c(0,39)) + 
                      xlab("Nominal Fipronil Concentration (ug/L)") +
                      theme_bw() +
                      scale_fill_manual(values=fourcolors)
                      #scale_fill_viridis_d(name="Nominal Fipronil\nConc.(ug/L)")+ 

totfishdist96.pred.redu
tiff("figures/Exposure_OutputFigs/TotalDistance_Fip2021_GSWS_0to100_withPreds.tiff", width=140, height=70, units="mm", compression="lzw", res=150)
totfishdist96.pred.redu
dev.off()        

# patchwork code to plot results from 2020 and 2021 side by side; need to run code from Exposure_Analysis3.Rmd prior to running this
# (totfishdist96bif.pred + scale_fill_viridis_d(guide=FALSE) +
#     scale_y_continuous(name="Total Distance Traversed (cm)", 
#                                           breaks=seq(0,40,10), 
#                                           labels=seq(0,40,10)*100, 
#                                           limits=c(0,39)) ) /
# (totfishdist96.pred.redu + scale_fill_manual(values=fourcolors, guide=FALSE)   
#      scale_y_continuous(name="Total Distance Traversed (cm)", 
#                                           breaks=seq(0,40,10), 
#                                           labels=seq(0,40,10)*100, 
#                                           limits=c(0,39)) )

       
# are the estimates different from control?      
 summary(dist.lmGS.redu)
  summary(aov(dist.lmGS.redu))
 # none of the concentrations are significantly different for GS
 summary(dist.lmWS.redu)
  summary(aov(dist.lmWS.redu))
  trash = lm(TotalfishDist_m ~ factor(lnCalcConc) + factor(lnCalcConc2) + pred.endtemp,
               data=DataSum96.distWS[DataSum96.distWS$Treatment %in% c(0,1,10,100),]) 
    summary(trash) 
    plot(trash)
      TukeyHSD(aov(trash))
  # if this is a legit way to model it, the 100 is sig dif from 0. 

```



```{r distance multi-level Bayesmodels selection, echo=F, eval=F}
# try setting up the linear model in a bayesian form, same as frequentist model above

DataSum96.dist$lnCalcConcMod = DataSum96.dist$lnCalcConc+1
DataSum96.dist$lnCalcConc2Mod = (DataSum96.dist$lnCalcConcMod^2)
DSdist_bmoddat = DataSum96.dist[ ,c("TotalfishDist_m","lnCalcConcMod","lnCalcConc2Mod","Spp","Tray")]
DSdist_bmoddat$SppDummy <- ifelse(DSdist_bmoddat$Spp=="GS", 0,1)

# remove fish from Tray D, GS, 96hrs because I suspect strange tracks (Dec 2021)
DSdist_bmoddat = DSdist_bmoddat[!(DSdist_bmoddat$Tray=="D" & DSdist_bmoddat$Spp=="GS"),]

set.seed(1995)
fipdist.blm_int1.ri = map2stan(
  alist(
    TotalfishDist_m ~ dnorm(mu, sigma),
      mu  <- a_tray[Tray] + 
              bs*SppDummy + 
              bt*(lnCalcConcMod) + 
              bt2*(lnCalcConc2Mod) + 
              bts*(SppDummy)*(lnCalcConcMod) + 
              bts2*(SppDummy)*(lnCalcConc2Mod),
          a_tray[Tray] ~ dnorm(a,a_sig),
            a ~ dnorm(0,10),
            a_sig ~ dcauchy(0,10),
        bs ~ dnorm(0,10),
        bt ~ dnorm(0,10),
        bt2 ~ dnorm(0,10),
        bts ~ dnorm(0,10),
        bts2 ~ dnorm(0,10),
    sigma ~ dcauchy(0,10)
    ) ,
  data = DSdist_bmoddat, iter = 2000, warmup = 500, chains = 4)

precis(fipdist.blm_int1.ri)
plot(precis(fipdist.blm_int1.ri))
plot(fipdist.blm_int1.ri)

set.seed(1995)
fipdist.blm_int2.ri = map2stan(
  alist(
    TotalfishDist_m ~ dnorm(mu, sigma),
      mu  <- a_tray[Tray] + 
              bs*SppDummy + 
              bt*(lnCalcConc) + 
              bts*(SppDummy)*(lnCalcConc) + 
              bts2*(SppDummy)*(lnCalcConc2),
          a_tray[Tray] ~ dnorm(a,a_sig),
            a ~ dnorm(0,10),
            a_sig ~ dcauchy(0,10),
        bs ~ dnorm(0,10),
        bt ~ dnorm(0,10),
        bts ~ dnorm(0,10),
        bts2 ~ dnorm(0,10),
    sigma ~ dcauchy(0,10)
    ) ,
  data = DSdist_bmoddat, iter = 2000, warmup = 500, chains = 4)

precis(fipdist.blm_int2.ri)
plot(precis(fipdist.blm_int2.ri))
plot(fipdist.blm_int2.ri)

# the models run fine, but the curve that is produced by the quadratic isn't the right shape for the data. How do I pick something else? 

```
###


```{r distance multi-level Bayesmodels predict, echo=F, eval=F}

# pull posterior from model:
set.seed(42)
post = extract.samples(fipdist.blm_int1.ri)

# set up dataframe to plot posterior predictions
preddat = list(CalcConc=rep(seq(0, 2250, 2), 4), 
               lnCalcConc=log(rep(seq(0, 2250, 2),4)+1), 
               lnCalcConcC=(log(rep(seq(0, 2250, 2),4)+1)) - 
                 mean(DataSum96.dist$lnCalcConc) ,
               lnCalcConcC2=((log(rep(seq(0, 2250, 2),4)+1)) - 
                 mean(DataSum96.dist$lnCalcConc))^2 ,               
              SppDummy = rep(rep(c(0,1),each=1126),2), 
               Tray = rep(2,4504))

# make zeros for individual random effects to predict to mean only -> model doesn't have any 'a' this way
a_tray_zeros = matrix(0,6000,90)  # use this to make the tray-offset zero
a_global = matrix(post$a,6000,90) # use this if model built with a single intercept (not a global intercept + offset)

# use link to predict to mean only
link.1.ri <- link(fipdist.blm_int1.ri, n=1000, data= preddat, 
                         replace = list(a_tray = a_global) )
                  
preddat.df <- data.frame(sapply(preddat,c)) # thanks stack overflow! https://stackoverflow.com/questions/4227223/convert-a-list-to-a-data-frame

preddat.df$link_mu_mn <- apply(link.1.ri, 2, mean) 
preddat.df$link_PI05 = apply(link.1.ri, 2, PI, .95)[1,] 
preddat.df$link_PI95 = apply(link.1.ri, 2, PI, .95)[2,] 

# plot data
  preddat.df$Spp <- ifelse(preddat.df$SppDummy==0,"GS","WS")

DistPred_transf_plot = ggplot() + 
  geom_point(data=DataSum96.dist,
             aes(x=(lnCalcConcC),                          
                 y=TotalfishDist_m, 
                 color=factor(Spp))) + 
  geom_ribbon(data = preddat.df, aes(x=(lnCalcConcC), 
              ymin=link_PI05, ymax=link_PI95), 
              alpha=.4, col="grey70")+
  geom_line(data = preddat.df, aes(x=(lnCalcConcC), y=link_mu_mn), lwd=.2)+
    facet_grid(Spp~., scales="free", labeller = labeller(
      Spp = c("GS" = "Green Sturgeon", "WS" = "White Sturgeon")))+
    scale_color_manual(values=c("green3", "steelblue3"), guide=FALSE)+
    ylab("Total Distance Traveled (m)") + 
    scale_x_continuous(name="Fipronil Concentration (ug/L)") +
    theme_bw()


DistPred_orig_plot = ggplot() + 
  geom_point(data=DataSum96.dist,
             aes(x=(calcConc),                          
                 y=TotalfishDist_m, 
                 color=factor(Spp))) + 
  geom_ribbon(data = preddat.df, aes(x=(CalcConc), 
              ymin=link_PI05, ymax=link_PI95), 
              alpha=.4, col="grey70")+
  geom_line(data = preddat.df, aes(x=(CalcConc), y=link_mu_mn), lwd=.2)+
  facet_grid(Spp~., scales="free", labeller = labeller(
    Spp = c("GS" = "Green Sturgeon", "WS" = "White Sturgeon")))+
  scale_color_manual(values=c("green3", "steelblue3"), guide=FALSE)+
  ylab("Total Distance Traveled (cm)") + 
  scale_x_continuous(name="Fipronil Concentration (ug/L)") + 
  theme_bw()

DistPred_transf_plot
DistPred_orig_plot

 = ggplot(data=DataSum96.dist,
             aes(x=log(calcConc),                          
                 y=log(TotalfishDist_m), 
                 color=factor(Spp), group=
                   Spp)) + 
  geom_point() +
  geom_smooth()

```
 
 
### Distance Contrasts (bayesian models)

### Study questions: 

###  1) is there an effect (all treatment vs control), and which metrics show an effect

###  2) does that effect change with time [96 treat vs 96 control and 24 treat vs 24 control OR individual change from 24 to 96 (all treatments) as compared to individual change for control between 24 and 96]

###  3) Does the magnitude of the effect vary between species

```{r distance multi-level model density plots, echo=F, eval=F}
set.seed(1983) 
postdist = extract.samples(distspp.blm_int5.rise.2)  # maybe change to distspp.blm_int3.rise, and if so, change the model prediction parts in the following chunk and the next. Argh. 


# reference table to convert from treatment to centered, log-transformed measured concentrations
TreatCalcTable = unique(DataSum2496.dist[order(DataSum2496.dist$Treatment)
                                             ,c("Spp", "Treatment","lnCalcConc", "lnCalcConcC")])
TreatCalcTable$lnCalcConcC2 = TreatCalcTable$lnCalcConcC ^ 2



# calculate differences between control and treatment at each time point for each species (20 contrasts)
GS0bif24 = postdist$a +
  postdist$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==0)$lnCalcConcC) +
  postdist$bt2*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==0)$lnCalcConcC2)
GS5bif24 = postdist$a + 
  postdist$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==5)$lnCalcConcC) +
  postdist$bt2*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==5)$lnCalcConcC2)
GS100bif24 = postdist$a + 
  postdist$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==100)$lnCalcConcC) +
  postdist$bt2*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==100)$lnCalcConcC2)
GS500bif24 = postdist$a + 
  postdist$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==500)$lnCalcConcC) +
  postdist$bt2*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==500)$lnCalcConcC2)
GS1000bif24 = postdist$a +
  postdist$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==1000)$lnCalcConcC) + 
  postdist$bt2* as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==1000)$lnCalcConcC2)
GS2000bif24 = postdist$a + 
  postdist$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==2000)$lnCalcConcC) + 
  postdist$bt2*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==2000)$lnCalcConcC2)

mean(GS0bif24)
mean(GS5bif24)
 cont.GS_0.5bif_24 = (sum(GS0bif24<GS5bif24) / length(GS0bif24)) 
 cont.GS_0.5bif_24 #72.0% prob that 5 is more than 0
mean(GS100bif24)
 cont.GS_0.100bif_24 = (sum(GS0bif24<GS100bif24) / length(GS0bif24)) 
 cont.GS_0.100bif_24 #62.4% prob that 100 is more than 0
mean(GS500bif24)
 cont.GS_0.500bif_24 = (sum(GS0bif24<GS500bif24) / length(GS0bif24)) 
 cont.GS_0.500bif_24 #40.7% prob that 500 is more than 0
mean(GS1000bif24)
 cont.GS_0.1000bif_24 = (sum(GS0bif24<GS1000bif24) / length(GS0bif24)) 
 cont.GS_0.1000bif_24 #32.8% prob that 1000 is more than 0
mean(GS2000bif24)
 cont.GS_0.2000bif_24 = (sum(GS0bif24<GS2000bif24) / length(GS0bif24)) 
 cont.GS_0.2000bif_24 #13.7% prob that 2000 is more than 0 (86.3% chance that 2000 is less than 0)

GS24.plot = ggplot() + geom_density(aes(x=GS0bif24, color="black")) + 
  geom_density(aes(x=GS5bif24, color="green3")) + 
  geom_density(aes(x=GS100bif24, color="goldenrod")) + 
  geom_density(aes(x=GS500bif24, color="red3")) + 
  geom_density(aes(x=GS1000bif24, color="pink")) + 
  geom_density(aes(x=GS2000bif24, color="steelblue3")) + 
  scale_color_manual(name="Nominal Bifenthrin\nConcentration", 
                     values=c("black"="black", "green3"="green3", "goldenrod"="goldenrod",
                              "red3"="red3", "pink"="pink","steelblue3"="steelblue3"), 
                     labels=c("0 ng/L", "5 ng/L", "100ng/L", 
                              "500ng/L", "1000ng/L", "2000 ng/L") ) + 
  xlab("Distance moved (GS @ 24hr)")+
  theme_bw()


# repeat for green sturgeon, 96hr

GS0bif96 = postdist$a + postdist$be +
  postdist$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==0)$lnCalcConcC) +
  postdist$bt2*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==0)$lnCalcConcC2)
GS5bif96 = postdist$a + postdist$be + 
  postdist$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==5)$lnCalcConcC) +
  postdist$bt2*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==5)$lnCalcConcC2)
GS100bif96 = postdist$a + postdist$be + 
  postdist$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==100)$lnCalcConcC) +
  postdist$bt2*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==100)$lnCalcConcC2)
GS500bif96 = postdist$a + postdist$be + 
  postdist$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==500)$lnCalcConcC) +
  postdist$bt2*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==500)$lnCalcConcC2)
GS1000bif96 = postdist$a + postdist$be +
  postdist$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==1000)$lnCalcConcC) + 
  postdist$bt2* as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==1000)$lnCalcConcC2)
GS2000bif96 = postdist$a + postdist$be + 
  postdist$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==2000)$lnCalcConcC) + 
  postdist$bt2*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==2000)$lnCalcConcC2)

mean(GS0bif96)
mean(GS5bif96)
 cont.GS_0.5bif_96 = (sum(GS0bif96<GS5bif96) / length(GS0bif96)) 
 cont.GS_0.5bif_96 #72.0% prob that 5 is more than 0
mean(GS100bif96)
mean(GS500bif96)
mean(GS1000bif96)
mean(GS2000bif96)

GS96.plot = ggplot() + geom_density(aes(x=GS0bif96), color="black") + 
  geom_density(aes(x=GS5bif96), color="green3") + 
  geom_density(aes(x=GS100bif96), color="goldenrod") + 
  geom_density(aes(x=GS500bif96), color="red3") + 
  geom_density(aes(x=GS1000bif96), color="pink") + 
  geom_density(aes(x=GS2000bif96), color="steelblue3") + 
  scale_color_manual(name="Nominal Bifenthrin\nConcentration", 
                     values=c("black"="black", "green3"="green3", "goldenrod"="goldenrod",
                              "red3"="red3", "pink"="pink","steelblue3"="steelblue3"), 
                     labels=c("0 ng/L", "5 ng/L", "100ng/L", 
                              "500ng/L", "1000ng/L", "2000 ng/L") ) + 
  xlab("Distance moved (GS @ 96hr)")+
  theme_bw()


# repeat for white sturgeon, 24hr

WS0bif24 = postdist$a + postdist$bs +
  postdist$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==0)$lnCalcConcC) +
  postdist$bt2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==0)$lnCalcConcC2) +
  postdist$bts1*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==0)$lnCalcConcC) +
  postdist$bts2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==0)$lnCalcConcC2)
WS5bif24 = postdist$a + postdist$bs + 
  postdist$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==5)$lnCalcConcC) +
  postdist$bt2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==5)$lnCalcConcC2)+
  postdist$bts1*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==5)$lnCalcConcC) +
  postdist$bts2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==5)$lnCalcConcC2)
WS100bif24 = postdist$a + postdist$bs + 
  postdist$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==100)$lnCalcConcC) +
  postdist$bt2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==100)$lnCalcConcC2)+
  postdist$bts1*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==100)$lnCalcConcC) +
  postdist$bts2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==100)$lnCalcConcC2)
WS500bif24 = postdist$a + postdist$bs + 
  postdist$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==500)$lnCalcConcC) +
  postdist$bt2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==500)$lnCalcConcC2)+
  postdist$bts1*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==500)$lnCalcConcC) +
  postdist$bts2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==500)$lnCalcConcC2)
WS1000bif24 = postdist$a + postdist$bs +
  postdist$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==1000)$lnCalcConcC) + 
  postdist$bt2* as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==1000)$lnCalcConcC2)+
  postdist$bts1*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==1000)$lnCalcConcC) + 
  postdist$bts2* as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==1000)$lnCalcConcC2)
WS2000bif24 = postdist$a + postdist$bs + 
  postdist$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==2000)$lnCalcConcC) + 
  postdist$bt2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==2000)$lnCalcConcC2)+
  postdist$bts1*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==2000)$lnCalcConcC) + 
  postdist$bts2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==2000)$lnCalcConcC2)

mean(WS0bif24)
mean(WS5bif24)
 cont.WS_0.5bif_24 = (sum(WS0bif24<WS5bif24) / length(WS0bif24)) 
 cont.WS_0.5bif_24 #100% prob that 5 is more than 0
mean(WS100bif24)
 cont.WS_0.100bif_24 = (sum(WS0bif24<WS100bif24) / length(WS0bif24)) 
 cont.WS_0.100bif_24 #100% prob that 100 is more than 0
mean(WS500bif24)
 cont.WS_0.500bif_24 = (sum(WS0bif24<WS500bif24) / length(WS0bif24)) 
 cont.WS_0.500bif_24 #55% prob that 500 is more than 0
mean(WS1000bif24)
 cont.WS_0.1000bif_24 = (sum(WS0bif24<WS1000bif24) / length(WS0bif24)) 
 cont.WS_0.1000bif_24 #0% prob that 1000 is more than 0 (i.e. 100% prob that 1000 is less than 0)
mean(WS2000bif24)
 cont.WS_0.2000bif_24 = (sum(WS0bif24<WS2000bif24) / length(WS0bif24)) 
 cont.WS_0.2000bif_24 #0% prob that 2000 is more than 0 (i.e. 100% prob that 1000 is less than 0)
 
WS24.plot = ggplot() + geom_density(aes(x=WS0bif24), color="black") + 
  geom_density(aes(x=WS5bif24), color="green3") + 
  geom_density(aes(x=WS100bif24), color="goldenrod") + 
  geom_density(aes(x=WS500bif24), color="red3") + 
  geom_density(aes(x=WS1000bif24), color="pink") + 
  geom_density(aes(x=WS2000bif24), color="steelblue3") + 
  scale_color_manual(name="Nominal Bifenthrin\nConcentration", 
                     values=c("black"="black", "green3"="green3", "goldenrod"="goldenrod",
                              "red3"="red3", "pink"="pink","steelblue3"="steelblue3"), 
                     labels=c("0 ng/L", "5 ng/L", "100ng/L", 
                              "500ng/L", "1000ng/L", "2000 ng/L") ) + 
  xlab("Distance moved (WS @ 24hr)")+
  theme_bw()


# repeat for white sturgeon, 96hr


WS0bif96 = postdist$a + postdist$bs + postdist$be + post$bse + 
  postdist$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==0)$lnCalcConcC) +
  postdist$bt2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==0)$lnCalcConcC2) +
  postdist$bts1*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==0)$lnCalcConcC) +
  postdist$bts2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==0)$lnCalcConcC2)
WS5bif96 = postdist$a + postdist$bs + postdist$be + post$bse + 
  postdist$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==5)$lnCalcConcC) +
  postdist$bt2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==5)$lnCalcConcC2) +
  postdist$bts1*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==5)$lnCalcConcC) +
  postdist$bts2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==5)$lnCalcConcC2)
WS100bif96 = postdist$a + postdist$bs + postdist$be + post$bse + 
  postdist$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==100)$lnCalcConcC) +
  postdist$bt2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==100)$lnCalcConcC2) +
  postdist$bts1*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==100)$lnCalcConcC) +
  postdist$bts2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==100)$lnCalcConcC2)
WS500bif96 = postdist$a + postdist$bs + postdist$be + post$bse + 
  postdist$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==500)$lnCalcConcC) +
  postdist$bt2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==500)$lnCalcConcC2) +
  postdist$bts1*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==500)$lnCalcConcC) +
  postdist$bts2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==500)$lnCalcConcC2)
WS1000bif96 = postdist$a + postdist$bs + postdist$be + post$bse + 
  postdist$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==1000)$lnCalcConcC) + 
  postdist$bt2* as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==1000)$lnCalcConcC2) +
  postdist$bts1*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==1000)$lnCalcConcC) + 
  postdist$bts2* as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==1000)$lnCalcConcC2)
WS2000bif96 = postdist$a + postdist$bs + postdist$be + post$bse + 
  postdist$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==2000)$lnCalcConcC) + 
  postdist$bt2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==2000)$lnCalcConcC2) +
  postdist$bts1*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==2000)$lnCalcConcC) + 
  postdist$bts2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==2000)$lnCalcConcC2)

mean(WS0bif96)
mean(WS5bif96)
 cont.WS_0.5bif_96 = (sum(WS0bif96<WS5bif96) / length(WS0bif96)) 
 cont.WS_0.5bif_96 #100% prob that 5 is more than 0
mean(WS100bif96)
 cont.WS_0.100bif_96 = (sum(WS0bif96<WS100bif96) / length(WS0bif96)) 
 cont.WS_0.100bif_96 #100% prob that 100 is more than 0
mean(WS500bif96)
 cont.WS_0.500bif_96 = (sum(WS0bif96<WS500bif96) / length(WS0bif96)) 
 cont.WS_0.500bif_96 #55.0% prob that 500 is more than 0
mean(WS1000bif96)
 cont.WS_0.1000bif_96 = (sum(WS0bif96<WS1000bif96) / length(WS0bif96)) 
 cont.WS_0.1000bif_96 #0% prob that 1000 is more than 0 (i.e. 100% prob that 1000 is less than 0)
mean(WS2000bif96)
 cont.WS_0.2000bif_96 = (sum(WS0bif96<WS2000bif96) / length(WS0bif96)) 
 cont.WS_0.2000bif_96 #0% prob that 2000 is more than 0 (i.e. 100% prob that 2000 is less than 0)

WS96.plot = ggplot() + geom_density(aes(x=WS0bif96), color="black") + 
  geom_density(aes(x=WS5bif96), color="green3") + 
  geom_density(aes(x=WS100bif96), color="goldenrod") + 
  geom_density(aes(x=WS500bif96), color="red3") + 
  geom_density(aes(x=WS1000bif96), color="pink") + 
  geom_density(aes(x=WS2000bif96), color="steelblue3") + 
  scale_color_manual(name="Nominal Bifenthrin\nConcentration", 
                     values=c("black"="black", "green3"="green3", "goldenrod"="goldenrod",
                              "red3"="red3", "pink"="pink","steelblue3"="steelblue3"), 
                     labels=c("0 ng/L", "5 ng/L", "100ng/L", 
                              "500ng/L", "1000ng/L", "2000 ng/L") ) + 
  xlab("Distance moved (WS @ 96hr)")+
  theme_bw()

GS24.plot + GS96.plot + WS24.plot + WS96.plot

predgroups = list(GS0bif24, GS5bif24,GS100bif24,GS500bif24,GS1000bif24,GS2000bif24,
                  GS0bif96, GS5bif96,GS100bif96,GS500bif96,GS1000bif96,GS2000bif96,
                  WS0bif24, WS5bif24,WS100bif24,WS500bif24,WS1000bif24,WS2000bif24,
                  WS0bif96, WS5bif96,WS100bif96,WS500bif96,WS1000bif96,WS2000bif96)
PredGroupNames =  as.character(expression(GS0bif24,GS5bif24,GS100bif24,GS500bif24,
                                          GS1000bif24,GS2000bif24,
                   GS0bif96, GS5bif96,GS100bif96,GS500bif96,GS1000bif96,GS2000bif96,
                   WS0bif24, WS5bif24,WS100bif24,WS500bif24,WS1000bif24,WS2000bif24,
                   WS0bif96, WS5bif96,WS100bif96,WS500bif96,WS1000bif96,WS2000bif96))
posterior.preds = data.frame(PredGroupNames = PredGroupNames, 
                             PredMeans = sapply(predgroups, mean),
                             Pred95CIl = sapply(predgroups, quantile, 0.05),
                             Pred95CIu = sapply(predgroups, quantile, 0.95))
```
#### if use this in a paper, recolor to a more intuitive gradient and add legend
 
 
```{r distance multi-level model time and spp contrasts, echo=F, eval=F}
# this uses the predicted posteriors for distance moved, calculated above

# GS vs WS
cont.GS.WS_0bif_24 = sum(GS0bif24<WS0bif24) / length(GS0bif24)
 cont.GS.WS_0bif_24 # 100% probability that GS will move less than WS

 cont.GS.WS_0bif_96 = sum(GS0bif96<WS0bif96) / length(GS0bif96)
 cont.GS.WS_0bif_96 # 100% probability that GS will move less than WS
cont.GS.WS_2000bif_96 = sum(GS2000bif96<WS2000bif96) / length(GS2000bif96)
 cont.GS.WS_2000bif_96 # 99.89% probability that GS will move less than WS


# Green Sturgeon, Exposure Hr
cont.GS0bif_96.24 = (sum(GS0bif96<GS0bif24) / length(GS0bif96)) 
# cont.GS5bif_96.24 = (sum(GS5bif96<GS5bif24) / length(GS5bif96))
# cont.GS100bif_96.24 = (sum(GS100bif96<GS100bif24) / length(GS100bif96))
# cont.GS500bif_96.24 = (sum(GS500bif96<GS500bif24) / length(GS500bif96))
# cont.GS1000bif_96.24 = (sum(GS1000bif96<GS1000bif24) / length(GS1000bif96))
# cont.GS2000bif_96.24 = (sum(GS2000bif96<GS2000bif24) / length(GS2000bif96))

cont.GS0bif_96.24
# ; cont.GS5bif_96.24; cont.GS100bif_96.24; cont.GS500bif_96.24; cont.GS1000bif_96.24; cont.GS2000bif_96.24

# ha! they're all the same, because there's no interaction of exposure time and treatment. 
 # 4.8% of the samples from the posterior showed less distance moved at 96 than 24; so most likely that movement is greater at 96 than 24 (95.2%)

GS0bif_96.24.plot = ggplot() + geom_density(aes(x=GS0bif96), color="steelblue3") + 
  geom_density(aes(x=GS0bif24), color="green3") + 
  xlab("Distance moved - GS @ 0 ng/L bifenthrin\n24 vs 96 hrs)") +
  theme_bw()
# GS5bif_96.24.plot = ggplot() + geom_density(aes(x=GS5bif96), color="steelblue3") + 
#   geom_density(aes(x=GS5bif24), color="green3") + 
#   xlab("Distance moved - GS @ 5 ng/L bifenthrin\n24 vs 96 hrs)") +
#   theme_bw()
# GS100bif_96.24.plot = ggplot() + geom_density(aes(x=GS100bif96), color="steelblue3") + 
#   geom_density(aes(x=GS100bif24), color="green3") + 
#   xlab("Distance moved - GS @ 100 ng/L bifenthrin\n24 vs 96 hrs)") +
#   theme_bw()
# GS500bif_96.24.plot = ggplot() + geom_density(aes(x=GS500bif96), color="steelblue3") + 
#   geom_density(aes(x=GS500bif24), color="green3") + 
#   xlab("Distance moved - GS @ 500 ng/L bifenthrin\n24 vs 96 hrs)") +
#   theme_bw()
# GS1000bif_96.24.plot = ggplot() + geom_density(aes(x=GS1000bif96), color="steelblue3") + 
#   geom_density(aes(x=GS1000bif24), color="green3") + 
#   xlab("Distance moved - GS @ 1000 ng/L bifenthrin\n24 vs 96 hrs)") +
#   theme_bw()
# GS2000bif_96.24.plot = ggplot() + geom_density(aes(x=GS2000bif96), color="steelblue3") + 
#   geom_density(aes(x=GS2000bif24), color="green3") + 
#   xlab("Distance moved - GS @ 2000 ng/L bifenthrin\n24 vs 96 hrs)") +
#   theme_bw()

# use patchwork grammar to plot multiple plots
GS0bif_96.24.plot
#(GS0bif_96.24.plot|GS5bif_96.24.plot|GS100bif_96.24.plot)/(GS500bif_96.24.plot|GS1000bif_96.plot|GS2000bif_96.plot)

cont.GS0bif_96.24 # 4.8% chance that GS move less at 96hrs than 24hrs (ie: move more with age)
# cont.GS5bif_96.24
# cont.GS100bif_96.24
# cont.GS500bif_96.24
# cont.GS1000bif_96.24
# cont.GS2000bif_96.24



# White Sturgeon: probability of a difference between 24 and 96 hours, at each treatment level
cont.WS0bif_96.24 = (sum(WS0bif96<WS0bif24) / length(WS0bif96)) 
cont.WS0bif_96.24
# 4.8% of the samples from the posterior showed less distance moved at 96 than 24; so most likely that movement is greater at 96 than 24 (95.2%)

WS0bif_96.24.plot = ggplot() + geom_density(aes(x=WS0bif96), color="steelblue3") + 
  geom_density(aes(x=WS0bif24), color="green3") + 
  xlab("Distance moved - WS @ 0 ng/L bifenthrin\n24 vs 96 hrs)") +
  theme_bw()
WS0bif_96.24.plot


```

#### well, these plots all look about the same, as they should since there's no interaction for concentration * exposure time; which fits the contrast value - it is 95.2% likely (for all comparisons of concentation, because there isn't an interaction) that for Green Sturgeon the distance moved at 96hrs (7ph) is greater than the distance moved at 24hrs (4 dph). But for white sturgeon, it's a 100% chance that there is less movement at 96hrs than at 24hrs exposure. 






 
     

## Velocity Models - abandoned b/c very similar pattern to distance #####
### Velocity 
```{r velocity plots, echo=F}

## Summarize movement velocity
 DataSum9696.vel = DataSum2496.raw %>%
  group_by(index, Trial, Arena, Replicate, ExposureHrs, Treatment, calcConc, Spp, RepID) %>%
  summarize(MnVel = mean(MnVel, na.rm=T), npos = n()) %>%
  ungroup()  %>%
  data.frame()
```



```{r velocity models, echo=F}
vel.lm = lm(MnVel ~ factor(Spp)+ factor(Treatment)*factor(ExposureHrs) , data = DataSum2496.vel)
velspp.lm = lm(MnVel ~ factor(Spp)*factor(Treatment)*factor(ExposureHrs) , data = DataSum2496.vel)

velspp.lmm = lmer(MnVel ~ factor(Spp)*factor(Treatment)*factor(ExposureHrs)+ (1| RepID), data = DataSum2496.vel)

 plot(velspp.lmm)
 qqnorm(resid(velspp.lmm)); qqline(resid(velspp.lmm))
 # plots look okay; the tree-way interaction makes for a better distn of residuals
 
 summary(velspp.lm) # everything is significant except for expsure hrs when modeled with log(conc)
   # effect of species is vastly stronger than anything else
   
   TukeyHSD(aov(velspp.lm))[[4]]
    # for WS, 2000 vs all other treatments are sig diff, and only one other (1000-100)
    # for GS, no GS-GS concentrations were significantly different in this model
   
   TukeyHSD(aov(velspp.lm))[[5]]
    # Ws-GS different at 24 and 69 hours, and WS-WS / GS-GS different at 24 & 96 hours; should do custom contrasts to publish because this is making all possible contrasts. Acutally, should fit in baysian model to publish and compare poterior predicted distribitions to compare. 
  
   TukeyHSD(aov(velspp.lm))[[6]]
    ## if use the three-way interaction model, identify custom contrasts of interest. Thus applies to frequentist of bayesian analysis

```





## Meander Models  #####
```{r meander data, echo=F}
## Add transformations of concentrations, exposure hours, and meander
 
DataSum2496 <- DataSum2496.raw %>%
  mutate(MeanderCircLog = log(abs(MeanderCirc)+1)) %>%
  mutate(lnCalcConc = log(calcConc+1)) %>%
  mutate(lnCalcConc2 = lnCalcConc^2) %>%
  mutate(lnCalcConcC= as.numeric(scale(lnCalcConc, scale=FALSE))) %>%
  mutate(lnCalcConcC2 = lnCalcConcC ^ 2 ) %>% 
   # order of transformations matters (log then scale then square)
  data.frame()

## Summarize meander and turn angle

# trying this to see if the tiny are causing the problems - could reasonably be argued that these are within the error range of the computer tracking
DataSum2496[!is.na(DataSum2496$MeanderCirc) & DataSum2496$MeanderCirc<1,"MeanderCirc"] <- NA

## Summarize meander and turn angle
DataSum2496.meand = DataSum2496 %>%
  group_by(index, Trial, Arena, Replicate, ExposureHrs, Treatment, 
           calcConc, lnCalcConc, lnCalcConc2, lnCalcConcC, lnCalcConcC2, Spp, RepID) %>%
  summarize(MnTurnAngle = deg(circ.mean.na(rad(TurnAngleCirc))), 
            VarTurnAngle = deg(circ.disp.na(rad(TurnAngleCirc))$var), # circular variance
            MnMeander = mean(MeanderCirc, na.rm=T),
            SDMeander = sd(MeanderCirc, na.rm=T))  %>%
  ungroup()  %>%
  data.frame()



#keep raw data but remove missing points
#DataSum2496.mraw = DataSum2496[!is.na(DataSum2496$TurnAngle_deg),]
# MeanMeand0 = DataSum2496.meand %>%
#   subset(Treatment==0) %>%
#   group_by(Spp, ExposureHrs) %>%
#   summarize(mean0_meand = mean(MnMeander)) %>%
#   ungroup()  %>%
#   data.frame()
# 
# DataSumDiff.meand = merge(DataSum2496.meand, MeanMeand0, all.x=T)
# DataSumDiff.meand$DistDiff = DataSumDiff.meand$MnMeander - DataSumDiff.meand$mean0_meand


```


```{r meander single-level Bayesmodels selection, echo=F, eval=F}
# try setting up the linear model in a bayesian form, same as frequentist model above
# use all meander data points, not summarized data
DSmeand_bmoddat = DataSum2496.meand[,c("SDMeander","calcConc","lnCalcConcC","lnCalcConcC2","ExposureHrs","Spp","RepID")]
DSmeand_bmoddat = DSmeand_bmoddat[!is.na(DSmeand_bmoddat$SDMeander),] # drops 26.1% of the data points when using full dataset; none if using summarized dataset 

DSmeand_bmoddat$lnCalcConcC = as.numeric(DSmeand_bmoddat$lnCalcConcC) 
DSmeand_bmoddat$lnCalcConcC2 = as.numeric(DSmeand_bmoddat$lnCalcConcC2) 
DSmeand_bmoddat$SppDummy <- as.numeric(ifelse(DSmeand_bmoddat$Spp=="GS", 0,1))
DSmeand_bmoddat$ExposeDummy <- as.numeric(ifelse(DSmeand_bmoddat$ExposureHrs=="24", 0,1))
#DSmeand_bmoddat$MeanderCircLog = as.numeric(DSmeand_bmoddat$MeanderCircLog) 

# remove fish with only one timepoint of detection, because cant add random slope with one timepoint
DSmeand_bmoddat = DSmeand_bmoddat[!(DSmeand_bmoddat$RepID %in% paste0(c(0,5,100,500,1000,2000), "-WS-4")),]
DSmeand_bmoddat$RepID = as.factor(as.character(DSmeand_bmoddat$RepID))

# let treatment effect and curve vary by species and exposure, and let exposure effect vary by species (all interactions, no multilevel)
set.seed(1983)
meandspp.blm_1 = map2stan(
  alist(
    SDMeander ~ dnorm(mu, sigma), 
      mu  <-  a + 
              be*ExposeDummy + 
              bs*SppDummy + 
              bse*(SppDummy)*(ExposeDummy) +
              bt*(lnCalcConcC) +
              bte*(ExposeDummy)*(lnCalcConcC) +
              bts*(SppDummy)*(lnCalcConcC) +
              bt2*(lnCalcConcC2) +
              bt2e*(ExposeDummy)*(lnCalcConcC2) +
              bt2s*(SppDummy)*(lnCalcConcC2) ,
        a ~ dnorm(0,10),
        be ~ dnorm(0,10),
        bs ~ dnorm(0,10),
        bse ~ dnorm(0,10),
        bt ~ dnorm(0,10),
        bte ~ dnorm(0,10),
        bts ~ dnorm(0,10),
        bt2 ~ dnorm(0,10),
        bt2e ~ dnorm(0,10),
        bt2s ~ dnorm(0,10),
    sigma ~ dcauchy(0,10)
    ) ,
  data = DSmeand_bmoddat, iter = 1000, warmup = 300, chains = 4)

saveRDS(meandspp.blm_1, "meandspp.blm_1.Rds")


# drop s*e
set.seed(1983)
meandspp.blm_2 = map2stan(
  alist(
    SDMeander ~ dnorm(mu, sigma), 
      mu  <-  a + 
              be*ExposeDummy + 
              bs*SppDummy + 
              bt*(lnCalcConcC) +
              bte*(ExposeDummy)*(lnCalcConcC) +
              bts*(SppDummy)*(lnCalcConcC) +
              bt2*(lnCalcConcC2) +
              bt2e*(ExposeDummy)*(lnCalcConcC2) +
              bt2s*(SppDummy)*(lnCalcConcC2) ,
        a ~ dnorm(0,10),
        be ~ dnorm(0,10),
        bs ~ dnorm(0,10),
        bt ~ dnorm(0,10),
        bte ~ dnorm(0,10),
        bts ~ dnorm(0,10),
        bt2 ~ dnorm(0,10),
        bt2e ~ dnorm(0,10),
        bt2s ~ dnorm(0,10),
      sigma ~ dcauchy(0,10)
    ) ,
  data = DSmeand_bmoddat, iter = 1000, warmup = 300, chains = 4)

saveRDS(meandspp.blm_2, "meandspp.blm_2.Rds")
## removing s*e improved model by 5.8 AIC points. Will keep it out



# drop all t interactions
set.seed(1983)
meandspp.blm_2b = map2stan(
  alist(
    SDMeander ~ dnorm(mu, sigma), 
      mu  <-  a + 
              be*ExposeDummy + 
              bs*SppDummy + 
              bt*(lnCalcConcC) +
              bt2*(lnCalcConcC2),
        a ~ dnorm(0,10),
        be ~ dnorm(0,10),
        bs ~ dnorm(0,10),
        bt ~ dnorm(0,10),
        bt2 ~ dnorm(0,10),
      sigma ~ dcauchy(0,10)
    ) ,
  data = DSmeand_bmoddat, iter = 1000, warmup = 300, chains = 4)


# add back in interaction with spp and treatment - below as blm_4

# remove exposure interaction with treatment effect (keep with quadratic)
set.seed(1983)
meandspp.blm_3 = map2stan(
  alist(
    SDMeander ~ dnorm(mu, sigma), 
      mu  <-  a + 
              be*ExposeDummy + 
              bs*SppDummy + 
              bt*(lnCalcConcC) +
              bts*(SppDummy)*(lnCalcConcC) +
              bt2*(lnCalcConcC2) +
              bt2e*(ExposeDummy)*(lnCalcConcC2) +
              bt2s*(SppDummy)*(lnCalcConcC2) ,
        a ~ dnorm(0,10),
        be ~ dnorm(0,10),
        bs ~ dnorm(0,10),
        bt ~ dnorm(0,10),
        bts ~ dnorm(0,10),
        bt2 ~ dnorm(0,10),
        bt2e ~ dnorm(0,10),
        bt2s ~ dnorm(0,10),
      sigma ~ dcauchy(0,10)
    ) ,
  data = DSmeand_bmoddat, iter = 1000, warmup = 300, chains = 4)

saveRDS(meandspp.blm_3, "meandspp.blm_3.Rds")



# remove exposure interaction with both straight and squadratic treatment effect 
set.seed(1983)
meandspp.blm_4 = map2stan(
  alist(
    SDMeander ~ dnorm(mu, sigma), 
      mu  <-  a + 
              be*ExposeDummy + 
              bs*SppDummy + 
              bt*(lnCalcConcC) +
              bts*(SppDummy)*(lnCalcConcC) +
              bt2*(lnCalcConcC2) +
              bt2s*(SppDummy)*(lnCalcConcC2) ,
        a ~ dnorm(0,10),
        be ~ dnorm(0,10),
        bs ~ dnorm(0,10),
        bt ~ dnorm(0,10),
        bts ~ dnorm(0,10),
        bt2 ~ dnorm(0,10),
        bt2s ~ dnorm(0,10),
      sigma ~ dcauchy(0,10)
    ) ,
  data = DSmeand_bmoddat, iter = 1000, warmup = 300, chains = 4)

saveRDS(meandspp.blm_4, "meandspp.blm_4.Rds")

# remove exposure interaction with both straight and squadratic treatment effect but add bace s*e (match distance model)
set.seed(1983)
meandspp.blm_5 = map2stan(
  alist(
    SDMeander ~ dnorm(mu, sigma), 
      mu  <-  a + 
              be*ExposeDummy + 
              bs*SppDummy + 
              bse*SppDummy*ExposeDummy + 
              bt*(lnCalcConcC) +
              bts*(SppDummy)*(lnCalcConcC) +
              bt2*(lnCalcConcC2) +
              bt2s*(SppDummy)*(lnCalcConcC2) ,
        a ~ dnorm(0,10),
        be ~ dnorm(0,10),
        bs ~ dnorm(0,10),
        bse ~ dnorm(0,10),
        bt ~ dnorm(0,10),
        bts ~ dnorm(0,10),
        bt2 ~ dnorm(0,10),
        bt2s ~ dnorm(0,10),
      sigma ~ dcauchy(0,10)
    ) ,
  data = DSmeand_bmoddat, iter = 1000, warmup = 300, chains = 4)

saveRDS(meandspp.blm_5, "meandspp.blm_5.Rds")
# model without s*e is still better, even when there isn't an interaction between exposure and the treatment and quadratic of treatment. 


# remove species interaction with straight treatment effect 
set.seed(1983)
meandspp.blm_6 = map2stan(
  alist(
    SDMeander ~ dnorm(mu, sigma), 
      mu  <-  a + 
              be*ExposeDummy + 
              bs*SppDummy + 
              bt*(lnCalcConcC) +
              bt2*(lnCalcConcC2) +
              bt2s*(SppDummy)*(lnCalcConcC2) ,
        a ~ dnorm(0,10),
        be ~ dnorm(0,10),
        bs ~ dnorm(0,10),
        bt ~ dnorm(0,10),
        bt2 ~ dnorm(0,10),
        bt2s ~ dnorm(0,10),
      sigma ~ dcauchy(0,10)
    ) ,
  data = DSmeand_bmoddat, iter = 1000, warmup = 300, chains = 4)

saveRDS(meandspp.blm_6, "meandspp.blm_6.Rds")


compare(meandspp.blm_2,meandspp.blm_3,meandspp.blm_4,meandspp.blm_5,meandspp.blm_6)
```

```{r meander multi-level Baysemodels selection, echo=F, eval=F}

# use all meander data points, not summarized data
DSmeand_bmoddat = DataSum2496.meand[,c("SDMeander","lnCalcConc","lnCalcConc2",
                                       "lnCalcConcC","lnCalcConcC2",
                                     "ExposureHrs","Spp","RepID")]
DSmeand_bmoddat = DSmeand_bmoddat[!is.na(DSmeand_bmoddat$SDMeander),] # drops 26.1% of the data points when using full dataset; none if using summarized dataset 

DSmeand_bmoddat$lnCalcConcC = as.numeric(DSmeand_bmoddat$lnCalcConcC) 
DSmeand_bmoddat$lnCalcConcC2 = as.numeric(DSmeand_bmoddat$lnCalcConcC2) 
DSmeand_bmoddat$SppDummy <- as.numeric(ifelse(DSmeand_bmoddat$Spp=="GS", 0,1))
DSmeand_bmoddat$ExposeDummy <- as.numeric(ifelse(DSmeand_bmoddat$ExposureHrs=="24", 0,1))
#DSmeand_bmoddat$MeanderCircLog = as.numeric(DSmeand_bmoddat$MeanderCircLog) 

# remove fish with only one timepoint of detection, because cant add random slope with one timepoint
DSmeand_bmoddat = DSmeand_bmoddat[!(DSmeand_bmoddat$RepID %in% paste0(c(0,5,100,500,1000,2000), "-WS-4")),]
DSmeand_bmoddat$RepID = as.factor(as.character(DSmeand_bmoddat$RepID))

DSmeand_bmoddat = DSmeand_bmoddat[order(DSmeand_bmoddat$RepID),]

# let treatment effect and curve vary by species and exposure (all interactions except for s*e) and include random intercept for each individual, and let effect of exposure time vary by individual
set.seed(2016)
meandspp.blm_2.rise = map2stan(
  alist(
    SDMeander ~ dnorm(mu, sigma), 
      mu  <-  a_fish[RepID] + 
              be_fish[RepID]*ExposeDummy + 
              bs*SppDummy + 
              bse*SppDummy*ExposeDummy + 
              bt*(lnCalcConc) +
              bte*(ExposeDummy)*(lnCalcConc) +
              bts*(SppDummy)*(lnCalcConc) +
              bt2*(lnCalcConc2) +
              bt2e*(ExposeDummy)*(lnCalcConc2) +
              bt2s*(SppDummy)*(lnCalcConc2) ,
           c(a_fish,be_fish)[RepID] ~ dmvnorm2(Mu=c(a,be), sigma=sigma_fish, Rho=Rho), 
                   a ~ dnorm(100,10),
                   be ~ dnorm(0,10),
                   sigma_fish ~ dcauchy(0,10),
                   Rho ~ dlkjcorr(2),
        bs ~ dnorm(0,10),
        bt ~ dnorm(0,10),
        bse ~ dnorm(0,10),
        bte ~ dnorm(0,10),
        bts ~ dnorm(0,10),
        bt2 ~ dnorm(0,10),
        bt2e ~ dnorm(0,10),
        bt2s ~ dnorm(0,10),
    sigma ~ dcauchy(0,10)
    ) ,
  data = DSmeand_bmoddat, iter = 2000, warmup = 700, chains = 4)
 
#saveRDS(meandspp.blm_2.rise, "meandspp.blm_2.rise.Rds")

# check model
 precis(meandspp.blm_2.rise, prob = .95, digits=3)
 plot(precis(meandspp.blm_2.rise, prob = .95))
 plot(precis(meandspp.blm_2.rise, prob = .95, depth=2))

 plot(meandspp.blm_2.rise)
 
# the model without removing the tiny meanders (0-1) fit to actual observations TERRIBLY. could be a plotting thing, but I think it's that the estimtd for the curvature of GS are way too high. Same with the basic blm_2 model above, but less so.  

# tried without the tiny meanders, an Rhat/ neff looked better (not great, but better). Sigma has some issues being estimated, but I think the rest look much muhc better than before the filtering.  Hwoever, the model still doesn't fit the data at all. Soemthing weird is going on. 
 
# tried it without centered concentration variables and it worked way better. strange. Still not great. 
 
 
 
set.seed(2019)
meandspp.blm_3.ri = map2stan(
  alist(
    SDMeander ~ dnorm(mu, sigma), 
      mu  <-  a_fish[RepID] + 
              be*ExposeDummy + 
              bs*SppDummy + 
              bse*SppDummy*ExposeDummy + 
              bt*(lnCalcConc) +
              bte*(ExposeDummy)*(lnCalcConc) +
              bts*(SppDummy)*(lnCalcConc) +
              bt2*(lnCalcConc2) +
              bt2e*(ExposeDummy)*(lnCalcConc2) +
              bt2s*(SppDummy)*(lnCalcConc2) ,
                  a_fish[RepID] ~ dnorm(a, sigma_fish), 
                     a ~ dnorm(100,10),
                     sigma_fish ~ dcauchy(0,10),
        be ~ dnorm(0,10),
        bs ~ dnorm(0,10),
        bt ~ dnorm(0,10),
        bse ~ dnorm(0,10),
        bte ~ dnorm(0,10),
        bts ~ dnorm(0,10),
        bt2 ~ dnorm(0,10),
        bt2e ~ dnorm(0,10),
        bt2s ~ dnorm(0,10),
    sigma ~ dcauchy(0,10)
    ) ,
  data = DSmeand_bmoddat, iter = 2000, warmup = 700, chains = 4)
  ## compared this to a model without s*e and this one had an AIC that was 13.3 lower. So keep s*e; I also think it makes the model fit better when overlaid on the points. 

  ## this model (Without random effect for individual slope for exposure time) seems to fit better bawsed on Rhat and neff. The trace plots look cleaner too; not perfect but better. 


 

# use all meander data points, not summarized data
DSmeand_bmoddat_cat = DataSum2496.meand[,c("SDMeander","lnCalcConc","lnCalcConc2",
                                     "ExposureHrs","Spp","RepID")]
DSmeand_bmoddat_cat = DSmeand_bmoddat_cat[!is.na(DSmeand_bmoddat_cat$SDMeander),] # drops 26.1% of the data points when using full dataset; none if using summarized dataset 

DSmeand_bmoddat_cat$GS24dummy <- as.numeric(ifelse(DSmeand_bmoddat_cat$Spp=="GS" & 
                                                 DSmeand_bmoddat_cat$ExposureHrs==24,1,0))
DSmeand_bmoddat_cat$GS96dummy <- as.numeric(ifelse(DSmeand_bmoddat_cat$Spp=="GS" & 
                                                 DSmeand_bmoddat_cat$ExposureHrs==96,1,0))
DSmeand_bmoddat_cat$WS24dummy <- as.numeric(ifelse(DSmeand_bmoddat_cat$Spp=="WS" & 
                                                 DSmeand_bmoddat_cat$ExposureHrs==24,1,0))
DSmeand_bmoddat_cat$WS96dummy <- as.numeric(ifelse(DSmeand_bmoddat_cat$Spp=="WS" & 
                                                 DSmeand_bmoddat_cat$ExposureHrs==96,1,0))

# remove fish with only one timepoint of detection, because cant add random slope with one timepoint
DSmeand_bmoddat_cat = DSmeand_bmoddat_cat[!(DSmeand_bmoddat_cat$RepID %in% paste0(c(0,5,100,500,1000,2000), "-WS-4")),]
DSmeand_bmoddat_cat$RepID = as.factor(as.character(DSmeand_bmoddat_cat$RepID))

DSmeand_bmoddat_cat = DSmeand_bmoddat_cat[order(DSmeand_bmoddat_cat$RepID),] 


set.seed(2019)
meandspp.blm_cat.ri = map2stan(
  alist(
    SDMeander ~ dnorm(mu, sigma), 
      mu  <-  a_fish[RepID] + 
      
              bGS24*GS24dummy + 
              bGS96*GS96dummy +
              bWS24*WS24dummy +
              bWS96*WS96dummy +
      
              bt*(lnCalcConc) +
              bt2*(lnCalcConc2) +
      
              bt_GS24*(lnCalcConc)*(GS24dummy) +
              bt2_GS24*(lnCalcConc2)*(GS24dummy) +
              bt_GS96*(lnCalcConc)*(GS96dummy) +
              bt2_GS96*(lnCalcConc2)*(GS96dummy) +
              bt_WS24*(lnCalcConc)*(WS24dummy) +
              bt2_WS24*(lnCalcConc2)*(WS24dummy) +
              bt_WS96*(lnCalcConc)*(WS96dummy) +
              bt2_WS96*(lnCalcConc2)*(WS96dummy),
      
                  a_fish[RepID] ~ dnorm(a, sigma_fish), 
                     a ~ dnorm(100,10),
                     sigma_fish ~ dcauchy(0,10),
        bGS24 ~ dnorm(0,10),
        bGS96 ~ dnorm(0,10),
        bWS24 ~ dnorm(0,10),
        bWS96 ~ dnorm(0,10),
        bt ~ dnorm(0,10),
        bt2 ~ dnorm(0,10),
        bt_GS24 ~ dnorm(0,10),
        bt_GS96 ~ dnorm(0,10),
        bt_WS24 ~ dnorm(0,10),
        bt_WS96 ~ dnorm(0,10),
        bt2_GS24 ~ dnorm(0,10),
        bt2_GS96 ~ dnorm(0,10),
        bt2_WS24 ~ dnorm(0,10),
        bt2_WS96 ~ dnorm(0,10),
    
    sigma ~ dcauchy(0,10)
    ) ,
  data = DSmeand_bmoddat_cat, iter = 2000, warmup = 700, chains = 4)




DSmeand_bmoddat96 = DSmeand_bmoddat[DSmeand_bmoddat$ExposureHrs==96,]


set.seed(2019)
meandspp.blm_96 = map2stan(
  alist(
    SDMeander ~ dnorm(mu, sigma), 
      mu  <-  a +
              #a_tray[RepID] +
              bs*SppDummy + 
              bt*(lnCalcConc) +
              bts*(SppDummy)*(lnCalcConc) +
              bt2*(lnCalcConc2) +
              bt2s*(SppDummy)*(lnCalcConc2) ,
        a ~ dnorm(100,10),
        bs ~ dnorm(0,10),
        bt ~ dnorm(0,10),
        bts ~ dnorm(0,10),
        bt2 ~ dnorm(0,10),
        bt2s ~ dnorm(0,10),
    sigma ~ dcauchy(0,10)
    ) ,
  data = DSmeand_bmoddat96, iter = 2000, warmup = 700, chains = 4)
 
```
### _2.rise is a logical model, and pretty well matches the other models, and lets us test the questions we're interested in. But the neff for sigma is pretty low. Tried various levels of dcauchy(0,X) and estimates didn't change too dramatically: with dcauchy(0,20) neff=26. With dcauchy(0,50) neff=4. with dcauchy(0,5) neff=30. with dcauchy(0,10) neff=25. Rhat ~1.1 - 1.2 for most also. Traceplots look okay but not perfect. Some sections where one or two of the chains don't mix (ie: are pretty thin lines). And sigma trace plots don't look great. But likely an okay model to use anyway. 

### tried with a prior for alpha that was (100,10) (mean SDMeader was 195). And that alone didn't help much

### tried filtering out the tiny meanders, because there were a lot and it seems like they could be within the range of error of the computer tracking.  

### Unfortunately, none of these changes to make the model converge better have improved the fit with the raw data. The curve of the GS preduction is too big, and potentially even in the wrong direction (should be concave but it's convex). And the WS is too flat when it should be curved. It's almost as though the bt2 element was added to the wrong place....hm. 
 
### tried it without centering the variables for concentration; I coulnd't wrap my head around how a quadratic would work with centered vars. Tried a 'guess and check' method to see if I could pick parameters that would make approximately the right shape, and I couldn't find them 
 
### Comparing the models with and wihtout random effects, we see that when random effects are added the estimates all move closer to zero (shrinkage?) and the variance gets arger for alle stimates that do not include any effect of exposure time (since that is the random slope). Those which do include exposure time show reduced sd values because some of the variation assocaited with exposure time is accounted for by the individual clustering. I think this all makes sense


```{r meander multi-level Bayesmodels predict, echo=F, eval=F}

# pull posterior from model:
set.seed(42)
post = extract.samples(meandspp.blm_96)

# set up dataframe to plot posterior predictions
# preddat = list(CalcConc=rep(seq(0, 2250, 2), 4), 
#                lnCalcConc=log(rep(seq(0, 2250, 2),4)+1), 
#                lnCalcConc2=log(rep(seq(0, 2250, 2),4)+1) ^2, 
#                lnCalcConcC=   (log(rep(seq(0, 2250, 2),4)+1)) - 
#                  mean(DataSum2496.dist$lnCalcConc) ,
#                lnCalcConcC2=( (log(rep(seq(0, 2250, 2),4)+1)) - 
#                  mean(DataSum2496.dist$lnCalcConc) ) ^ 2 ,               
#                ExposeDummy = rep(c(0,1), each=1126*2), 
#                SppDummy = rep(rep(c(0,1),each=1126),2), 
#                RepID = rep(16,4504))

preddat = list(CalcConc=rep(seq(0, 2250, 2), 2), 
               lnCalcConc=log(rep(seq(0, 2250, 2),2)+1), 
               lnCalcConc2=log(rep(seq(0, 2250, 2),2)+1) ^2, 
               lnCalcConcC=   (log(rep(seq(0, 2250, 2),2)+1)) - 
                 mean(DataSum2496.dist$lnCalcConc) ,
               lnCalcConcC2=( (log(rep(seq(0, 2250, 2),2)+1)) - 
                 mean(DataSum2496.dist$lnCalcConc) ) ^ 2 ,               
               SppDummy = rep(c(0,1), each=1126))

# replace individual fish estimates with global estimate; this should predict to the average individual in a population...so since I want to get at the population level response this seems most appropriate.
a_global = matrix(post$a,5200,90) # 5200 = 1300 samples per chain x 4 chains
be_global = matrix(post$be,5200,90)

# use link to predict to mean only
link.2.rise <- link(meandspp.blm_96, n=1000, data= preddat)#, 
                        replace = list(a_fish = a_global)), 
                                        be_fish = be_global) )

preddat.df <- data.frame(sapply(preddat,c)) # thanks stack overflow! https://stackoverflow.com/questions/4227223/convert-a-list-to-a-data-frame

preddat.df$link_mu_mn <- apply(link.2.rise, 2, mean) 
preddat.df$link_PI05 = apply(link.2.rise, 2, PI, .95)[1,] 
preddat.df$link_PI95 = apply(link.2.rise, 2, PI, .95)[2,] 


  # plot back-transformed data
  preddat.df$Spp <- ifelse(preddat.df$SppDummy==0,"GS","WS")
  preddat.df$ExposureHrs <- ifelse(preddat.df$ExposeDummy==0,"24","96")


MeandPred_transf_plot = ggplot() + 
  geom_point(data=DSmeand_bmoddat96,
             aes(x=(lnCalcConc),                          
                 y=SDMeander, 
                 color=factor(Spp))) + 
  geom_ribbon(data = preddat.df, aes(x=(lnCalcConc), 
              ymin=link_PI05, ymax=link_PI95), 
              alpha=.4, col="grey70")+
  geom_line(data = preddat.df, aes(x=(lnCalcConc), y=link_mu_mn), lwd=.2)+
    facet_grid(Spp~ExposureHrs, scales="free", labeller = labeller(
      ExposureHrs = c("24"="24 Hours Exposure","96"="96 Hours Exposure"),
      Spp = c("GS" = "Green Sturgeon", "WS" = "White Sturgeon")))+
    scale_color_manual(values=c("green3", "steelblue3"), guide=FALSE)+
    ylab("SD of Track Meander (deg/mm)") + 
    scale_x_continuous(name="Log-centered Bifenthrin Concentration (ng/L)") + #, breaks = seq(-7.5,5, 2.5), labels=(seq(-7.5,5, 2.5)+3.73) ) +
    theme_bw()

MeandPred_transf_plot96 = ggplot() + 
  geom_point(data=DataSum2496.meand,
             aes(x=(lnCalcConcC),                          
                 y=SDMeander, 
                 color=factor(Spp))) + 
  geom_ribbon(data = preddat.df, aes(x=(lnCalcConcC), 
              ymin=link_PI05, ymax=link_PI95), 
              alpha=.4, col="grey70")+
  geom_line(data = preddat.df, aes(x=(lnCalcConcC), y=link_mu_mn), lwd=.2)+
    facet_wrap(Spp~., scales="free", labeller = labeller(
      Spp = c("GS" = "Green Sturgeon", "WS" = "White Sturgeon")))+
    scale_color_manual(values=c("green3", "steelblue3"), guide=FALSE)+
    ylab("SD of Track Meander (deg/mm)") + 
    scale_x_continuous(name="Log-centered Bifenthrin Concentration (ng/L)") + #, breaks = seq(-7.5,5, 2.5), labels=(seq(-7.5,5, 2.5)+3.73) ) +
    theme_bw()


MeandPred_transf_plot_smooth = ggplot(data=DataSum2496.meand,
             aes(x=(lnCalcConcC),                          
                 y=SDMeander, 
                 color=factor(Spp))) + geom_point() + geom_smooth(span=1.25) + 
    facet_grid(Spp~ExposureHrs, scales="free", labeller = labeller(
      ExposureHrs = c("24"="24 Hours Exposure","96"="96 Hours Exposure"),
      Spp = c("GS" = "Green Sturgeon", "WS" = "White Sturgeon")))+
    scale_color_manual(values=c("green3", "steelblue3"), guide=FALSE)+
    ylab("SD of Track Meander (deg/mm)") + 
    scale_x_continuous(name="Log-centered Bifenthrin Concentration (ng/L)") + #, breaks = seq(-7.5,5, 2.5), labels=(seq(-7.5,5, 2.5)+3.73) ) +
    theme_bw()

MeandPred_orig_plot = ggplot() + 
  geom_point(data=DataSum2496.meand,
             aes(x=exp(lnCalcConc),                          
                 y=SDMeander, 
                 color=factor(Spp))) + 
  geom_ribbon(data = preddat.df, aes(x=(CalcConc), 
              ymin=link_PI05, ymax=link_PI95), 
              alpha=.4, col="grey70")+
  geom_line(data = preddat.df, aes(x=(CalcConc), y=link_mu_mn), lwd=.2)+
  facet_grid(Spp~ExposureHrs, scales="free", labeller = labeller(
    ExposureHrs = c("24"="24 Hours Exposure","96"="96 Hours Exposure"),
    Spp = c("GS" = "Green Sturgeon", "WS" = "White Sturgeon")))+
  scale_color_manual(values=c("green3", "steelblue3"), guide=FALSE)+
  ylab("SD of Track Meander (deg/mm)") + 
  scale_x_continuous(name="Bifenthrin Concentration (ng/L)") + #, breaks = seq(-7.5,5, 2.5), labels=(seq(-7.5,5, 2.5)+3.73) ) +
  theme_bw()

MeandPred_transf_plot_smooth
MeandPred_transf_plot
MeandPred_orig_plot 

```
 
 
### MeanderSD Contrasts

### Study questions: 

###  1) is there an effect (all treatment vs control), and which metrics show an effect

###  2) does that effect change with time [96 treat vs 96 control and 24 treat vs 24 control OR individual change from 24 to 96 (all treatments) as compared to individual change for control between 24 and 96]

###  3) Does the magnitude of the effect vary between species

```{r meander multi-level model density plots, echo=F}
set.seed(1983) 
postmeand = extract.samples(meandspp.blm_2.rise)  

# reference table to convert from treatment to centered, log-transformed measured concentrations
TreatCalcTable = unique(DataSum2496.meand[order(DataSum2496.meand$Treatment)
                                             ,c("Spp", "Treatment","lnCalcConc", "lnCalcConcC")])
TreatCalcTable$lnCalcConcC2 = TreatCalcTable$lnCalcConcC ^ 2



# calculate differences between control and treatment at each time point for each species (20 contrasts)
GS0bif24m = postmeand$a +
  postmeand$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==0)$lnCalcConcC) +
  postmeand$bt2*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==0)$lnCalcConcC2)
GS5bif24m = postmeand$a + 
  postmeand$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==5)$lnCalcConcC) +
  postmeand$bt2*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==5)$lnCalcConcC2)
GS100bif24m = postmeand$a + 
  postmeand$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==100)$lnCalcConcC) +
  postmeand$bt2*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==100)$lnCalcConcC2)
GS500bif24m = postmeand$a + 
  postmeand$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==500)$lnCalcConcC) +
  postmeand$bt2*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==500)$lnCalcConcC2)
GS1000bif24m = postmeand$a +
  postmeand$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==1000)$lnCalcConcC) + 
  postmeand$bt2* as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==1000)$lnCalcConcC2)
GS2000bif24m = postmeand$a + 
  postmeand$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==2000)$lnCalcConcC) + 
  postmeand$bt2*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==2000)$lnCalcConcC2)

mean(GS0bif24m)
mean(GS5bif24m)
 cont.GS_0.5bif_24m = (sum(GS0bif24m<GS5bif24m) / length(GS0bif24m)) 
 cont.GS_0.5bif_24m #72.0% prob that 5 is more than 0
mean(GS100bif24m)
 cont.GS_0.100bif_24m = (sum(GS0bif24m<GS100bif24m) / length(GS0bif24m)) 
 cont.GS_0.100bif_24m #62.4% prob that 100 is more than 0
mean(GS500bif24m)
 cont.GS_0.500bif_24m = (sum(GS0bif24m<GS500bif24m) / length(GS0bif24m)) 
 cont.GS_0.500bif_24m #40.7% prob that 500 is more than 0
mean(GS1000bif24m)
 cont.GS_0.1000bif_24m = (sum(GS0bif24m<GS1000bif24m) / length(GS0bif24m)) 
 cont.GS_0.1000bif_24m #32.8% prob that 1000 is more than 0
mean(GS2000bif24m)
 cont.GS_0.2000bif_24m = (sum(GS0bif24m<GS2000bif24m) / length(GS0bif24m)) 
 cont.GS_0.2000bif_24m #13.7% prob that 2000 is more than 0 (86.3% chance that 2000 is less than 0)

GS24m.plot = ggplot() + geom_density(aes(x=GS0bif24m, color="black")) + 
  geom_density(aes(x=GS5bif24m, color="green3")) + 
  geom_density(aes(x=GS100bif24m, color="goldenrod")) + 
  geom_density(aes(x=GS500bif24m, color="red3")) + 
  geom_density(aes(x=GS1000bif24m, color="pink")) + 
  geom_density(aes(x=GS2000bif24m, color="steelblue3")) + 
  scale_color_manual(name="Nominal Bifenthrin\nConcentration", 
                     values=c("black"="black", "green3"="green3", "goldenrod"="goldenrod",
                              "red3"="red3", "pink"="pink","steelblue3"="steelblue3"), 
                     labels=c("0 ng/L", "5 ng/L", "100ng/L", 
                              "500ng/L", "1000ng/L", "2000 ng/L") ) + 
  xlab("SD Track Meander (GS @ 24hr)")+
  theme_bw()


# repeat for green sturgeon, 96hr

GS0bif96m = postmeand$a + postmeand$be +
  postmeand$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==0)$lnCalcConcC) +
  postmeand$bt2*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==0)$lnCalcConcC2)
GS5bif96m = postmeand$a + postmeand$be + 
  postmeand$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==5)$lnCalcConcC) +
  postmeand$bt2*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==5)$lnCalcConcC2)
GS100bif96m = postmeand$a + postmeand$be + 
  postmeand$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==100)$lnCalcConcC) +
  postmeand$bt2*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==100)$lnCalcConcC2)
GS500bif96m = postmeand$a + postmeand$be + 
  postmeand$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==500)$lnCalcConcC) +
  postmeand$bt2*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==500)$lnCalcConcC2)
GS1000bif96m = postmeand$a + postmeand$be +
  postmeand$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==1000)$lnCalcConcC) + 
  postmeand$bt2* as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==1000)$lnCalcConcC2)
GS2000bif96m = postmeand$a + postmeand$be + 
  postmeand$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==2000)$lnCalcConcC) + 
  postmeand$bt2*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==2000)$lnCalcConcC2)

mean(GS0bif96m)
mean(GS5bif96m)
 cont.GS_0.5bif_96m = (sum(GS0bif96m<GS5bif96m) / length(GS0bif96m)) 
 cont.GS_0.5bif_96m #72.0% prob that 5 is more than 0
mean(GS100bif96m)
mean(GS500bif96m)
mean(GS1000bif96m)
mean(GS2000bif96m)

GS96m.plot = ggplot() + geom_density(aes(x=GS0bif96m), color="black") + 
  geom_density(aes(x=GS5bif96m), color="green3") + 
  geom_density(aes(x=GS100bif96m), color="goldenrod") + 
  geom_density(aes(x=GS500bif96m), color="red3") + 
  geom_density(aes(x=GS1000bif96m), color="pink") + 
  geom_density(aes(x=GS2000bif96m), color="steelblue3") + 
  scale_color_manual(name="Nominal Bifenthrin\nConcentration", 
                     values=c("black"="black", "green3"="green3", "goldenrod"="goldenrod",
                              "red3"="red3", "pink"="pink","steelblue3"="steelblue3"), 
                     labels=c("0 ng/L", "5 ng/L", "100ng/L", 
                              "500ng/L", "1000ng/L", "2000 ng/L") ) + 
  xlab("SD Track Meander (GS @ 96hr)")+
  theme_bw()


# repeat for white sturgeon, 24hr

WS0bif24m = postmeand$a + postmeand$bs +
  postmeand$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==0)$lnCalcConcC) +
  postmeand$bt2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==0)$lnCalcConcC2) +
  postmeand$bts1*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==0)$lnCalcConcC) +
  postmeand$bts2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==0)$lnCalcConcC2)
WS5bif24m = postmeand$a + postmeand$bs + 
  postmeand$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==5)$lnCalcConcC) +
  postmeand$bt2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==5)$lnCalcConcC2)+
  postmeand$bts1*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==5)$lnCalcConcC) +
  postmeand$bts2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==5)$lnCalcConcC2)
WS100bif24m = postmeand$a + postmeand$bs + 
  postmeand$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==100)$lnCalcConcC) +
  postmeand$bt2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==100)$lnCalcConcC2)+
  postmeand$bts1*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==100)$lnCalcConcC) +
  postmeand$bts2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==100)$lnCalcConcC2)
WS500bif24m = postmeand$a + postmeand$bs + 
  postmeand$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==500)$lnCalcConcC) +
  postmeand$bt2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==500)$lnCalcConcC2)+
  postmeand$bts1*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==500)$lnCalcConcC) +
  postmeand$bts2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==500)$lnCalcConcC2)
WS1000bif24m = postmeand$a + postmeand$bs +
  postmeand$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==1000)$lnCalcConcC) + 
  postmeand$bt2* as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==1000)$lnCalcConcC2)+
  postmeand$bts1*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==1000)$lnCalcConcC) + 
  postmeand$bts2* as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==1000)$lnCalcConcC2)
WS2000bif24m = postmeand$a + postmeand$bs + 
  postmeand$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==2000)$lnCalcConcC) + 
  postmeand$bt2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==2000)$lnCalcConcC2)+
  postmeand$bts1*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==2000)$lnCalcConcC) + 
  postmeand$bts2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==2000)$lnCalcConcC2)

mean(WS0bif24m)
mean(WS5bif24m)
 cont.WS_0.5bif_24m = (sum(WS0bif24m<WS5bif24m) / length(WS0bif24m)) 
 cont.WS_0.5bif_24m #100% prob that 5 is more than 0
mean(WS100bif24m)
 cont.WS_0.100bif_24m = (sum(WS0bif24m<WS100bif24m) / length(WS0bif24m)) 
 cont.WS_0.100bif_24m #100% prob that 100 is more than 0
mean(WS500bif24m)
 cont.WS_0.500bif_24m = (sum(WS0bif24m<WS500bif24m) / length(WS0bif24m)) 
 cont.WS_0.500bif_24m #55% prob that 500 is more than 0
mean(WS1000bif24m)
 cont.WS_0.1000bif_24m = (sum(WS0bif24m<WS1000bif24m) / length(WS0bif24m)) 
 cont.WS_0.1000bif_24m #0% prob that 1000 is more than 0 (i.e. 100% prob that 1000 is less than 0)
mean(WS2000bif24m)
 cont.WS_0.2000bif_24m = (sum(WS0bif24m<WS2000bif24m) / length(WS0bif24m)) 
 cont.WS_0.2000bif_24m #0% prob that 2000 is more than 0 (i.e. 100% prob that 1000 is less than 0)
 
WS24m.plot = ggplot() + geom_density(aes(x=WS0bif24m), color="black") + 
  geom_density(aes(x=WS5bif24m), color="green3") + 
  geom_density(aes(x=WS100bif24m), color="goldenrod") + 
  geom_density(aes(x=WS500bif24m), color="red3") + 
  geom_density(aes(x=WS1000bif24m), color="pink") + 
  geom_density(aes(x=WS2000bif24m), color="steelblue3") + 
  scale_color_manual(name="Nominal Bifenthrin\nConcentration", 
                     values=c("black"="black", "green3"="green3", "goldenrod"="goldenrod",
                              "red3"="red3", "pink"="pink","steelblue3"="steelblue3"), 
                     labels=c("0 ng/L", "5 ng/L", "100ng/L", 
                              "500ng/L", "1000ng/L", "2000 ng/L") ) + 
  xlab("SD Track Meander (WS @ 24hr)")+
  theme_bw()


# repeat for white sturgeon, 96hr


WS0bif96m = postmeand$a + postmeand$bs + postmeand$be + 
  postmeand$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==0)$lnCalcConcC) +
  postmeand$bt2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==0)$lnCalcConcC2) +
  postmeand$bts1*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==0)$lnCalcConcC) +
  postmeand$bts2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==0)$lnCalcConcC2)
WS5bif96m = postmeand$a + postmeand$bs + postmeand$be + 
  postmeand$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==5)$lnCalcConcC) +
  postmeand$bt2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==5)$lnCalcConcC2) +
  postmeand$bts1*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==5)$lnCalcConcC) +
  postmeand$bts2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==5)$lnCalcConcC2)
WS100bif96m = postmeand$a + postmeand$bs + postmeand$be + 
  postmeand$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==100)$lnCalcConcC) +
  postmeand$bt2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==100)$lnCalcConcC2) +
  postmeand$bts1*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==100)$lnCalcConcC) +
  postmeand$bts2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==100)$lnCalcConcC2)
WS500bif96m = postmeand$a + postmeand$bs + postmeand$be + 
  postmeand$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==500)$lnCalcConcC) +
  postmeand$bt2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==500)$lnCalcConcC2) +
  postmeand$bts1*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==500)$lnCalcConcC) +
  postmeand$bts2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==500)$lnCalcConcC2)
WS1000bif96m = postmeand$a + postmeand$bs + postmeand$be +  
  postmeand$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==1000)$lnCalcConcC) + 
  postmeand$bt2* as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==1000)$lnCalcConcC2) +
  postmeand$bts1*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==1000)$lnCalcConcC) + 
  postmeand$bts2* as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==1000)$lnCalcConcC2)
WS2000bif96m = postmeand$a + postmeand$bs + postmeand$be + 
  postmeand$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==2000)$lnCalcConcC) + 
  postmeand$bt2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==2000)$lnCalcConcC2) +
  postmeand$bts1*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==2000)$lnCalcConcC) + 
  postmeand$bts2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==2000)$lnCalcConcC2)

mean(WS0bif96m)
mean(WS5bif96m)
 cont.WS_0.5bif_96m = (sum(WS0bif96m<WS5bif96m) / length(WS0bif96m)) 
 cont.WS_0.5bif_96m #100% prob that 5 is more than 0
mean(WS100bif96m)
 cont.WS_0.100bif_96m = (sum(WS0bif96m<WS100bif96m) / length(WS0bif96m)) 
 cont.WS_0.100bif_96m #100% prob that 100 is more than 0
mean(WS500bif96m)
 cont.WS_0.500bif_96m = (sum(WS0bif96m<WS500bif96m) / length(WS0bif96m)) 
 cont.WS_0.500bif_96m #55.0% prob that 500 is more than 0
mean(WS1000bif96m)
 cont.WS_0.1000bif_96m = (sum(WS0bif96m<WS1000bif96m) / length(WS0bif96m)) 
 cont.WS_0.1000bif_96m #0% prob that 1000 is more than 0 (i.e. 100% prob that 1000 is less than 0)
mean(WS2000bif96m)
 cont.WS_0.2000bif_96m = (sum(WS0bif96m<WS2000bif96m) / length(WS0bif96m)) 
 cont.WS_0.2000bif_96m #0% prob that 2000 is more than 0 (i.e. 100% prob that 2000 is less than 0)

WS96m.plot = ggplot() + geom_density(aes(x=WS0bif96m), color="black") + 
  geom_density(aes(x=WS5bif96m), color="green3") + 
  geom_density(aes(x=WS100bif96m), color="goldenrod") + 
  geom_density(aes(x=WS500bif96m), color="red3") + 
  geom_density(aes(x=WS1000bif96m), color="pink") + 
  geom_density(aes(x=WS2000bif96m), color="steelblue3") + 
  scale_color_manual(name="Nominal Bifenthrin\nConcentration", 
                     values=c("black"="black", "green3"="green3", "goldenrod"="goldenrod",
                              "red3"="red3", "pink"="pink","steelblue3"="steelblue3"), 
                     labels=c("0 ng/L", "5 ng/L", "100ng/L", 
                              "500ng/L", "1000ng/L", "2000 ng/L") ) + 
  xlab("SD Track Meander (WS @ 96hr)")+
  theme_bw()

GS24m.plot + GS96m.plot + WS24m.plot + WS96m.plot

predgroups = list(GS0bif24m, GS5bif24m,GS100bif24m,GS500bif24m,GS1000bif24m,GS2000bif24m,
                  GS0bif96m, GS5bif96m,GS100bif96m,GS500bif96m,GS1000bif96m,GS2000bif96m,
                  WS0bif24m, WS5bif24m,WS100bif24m,WS500bif24m,WS1000bif24m,WS2000bif24m,
                  WS0bif96m, WS5bif96m,WS100bif96m,WS500bif96m,WS1000bif96m,WS2000bif96m)
PredGroupNames =  as.character(expression(GS0bif24m,GS5bif24m,GS100bif24m,GS500bif24m,
                                          GS1000bif24m,GS2000bif24m,
                   GS0bif96m, GS5bif96m,GS100bif96m,GS500bif96m,GS1000bif96m,GS2000bif96m,
                   WS0bif24m, WS5bif24m,WS100bif24m,WS500bif24m,WS1000bif24m,WS2000bif24m,
                   WS0bif96m, WS5bif96m,WS100bif96m,WS500bif96m,WS1000bif96m,WS2000bif96m))
posterior.preds = data.frame(PredGroupNames = PredGroupNames, 
                             PredMeans = sapply(predgroups, mean),
                             Pred95CIl = sapply(predgroups, quantile, 0.05),
                             Pred95CIu = sapply(predgroups, quantile, 0.95))
```
#### if use this in a paper, recolor to a more intuitive gradient and add legend
 
 
```{r meander multi-level model time and spp contrasts, echo=F}
# this uses the predicted posteriors for distance moved, calculated above

# GS vs WS
cont.GS.WS_0bif_24m = sum(GS0bif24m<WS0bif24m) / length(GS0bif24m)
 cont.GS.WS_0bif_24m # 100% probability that GS will move less than WS

 cont.GS.WS_0bif_96m = sum(GS0bif96m<WS0bif96m) / length(GS0bif96m)
 cont.GS.WS_0bif_96m # 100% probability that GS will move less than WS
cont.GS.WS_2000bif_96m = sum(GS2000bif96m<WS2000bif96m) / length(GS2000bif96m)
 cont.GS.WS_2000bif_96m # 99.89% probability that GS will move less than WS


# Green Sturgeon, Exposure Hr
cont.GS0bif_96.24m = (sum(GS0bif96m<GS0bif24m) / length(GS0bif96m)) 
cont.GS5bif_96.24m = (sum(GS5bif96m<GS5bif24m) / length(GS5bif96m)) 
cont.GS100bif_96.24m = (sum(GS100bif96m<GS100bif24m) / length(GS100bif96m)) 
cont.GS500bif_96.24m = (sum(GS500bif96m<GS500bif24m) / length(GS500bif96m)) 
cont.GS1000bif_96.24m = (sum(GS1000bif96m<GS1000bif24m) / length(GS1000bif96m)) 
cont.GS2000bif_96.24m = (sum(GS2000bif96m<GS2000bif24m) / length(GS2000bif96m)) 

cont.GS0bif_96.24m
cont.GS5bif_96.24m
cont.GS100bif_96.24m
cont.GS500bif_96.24m
cont.GS1000bif_96.24m
cont.GS2000bif_96.24m


GS0bif_96.24m.plot = ggplot() + geom_density(aes(x=GS0bif96m), color="steelblue3") + 
  geom_density(aes(x=GS0bif24m), color="green3") + 
  xlab("SD Meander - GS @ 0 ng/L bifenthrin\n24 vs 96 hrs)") +
  theme_bw()
GS2000bif_96.24m.plot = ggplot() + geom_density(aes(x=GS2000bif96m), color="steelblue3") + 
  geom_density(aes(x=GS2000bif24m), color="green3") + 
  xlab("SD Meander - GS @ 2000 ng/L bifenthrin\n24 vs 96 hrs)") +
  theme_bw()
# can repeat these for each concentration if interesting

# use patchwork grammar to plot multiple plots together
GS0bif_96.24m.plot + GS2000bif_96.24m.plot   




# White Sturgeon: probability of a difference between 24 and 96 hours, at each treatment level
cont.WS0bif_96.24m = (sum(WS0bif96m<WS0bif24m) / length(WS0bif96m)) 
cont.WS0bif_96.24m


WS0bif_96.24m.plot = ggplot() + geom_density(aes(x=WS0bif96m), color="steelblue3") + 
  geom_density(aes(x=WS0bif24m), color="green3") + 
  xlab("SD Meander - WS @ 0 ng/L bifenthrin\n24 vs 96 hrs)") +
  theme_bw()
WS0bif_96.24m.plot


```

#### well, these plots all look about the same, as they should since there's no interaction for concentration * exposure time; which fits the contrast value - it is 95.2% likely (for all comparisons of concentation, because there isn't an interaction) that for Green Sturgeon the distance moved at 96hrs (7ph) is greater than the distance moved at 24hrs (4 dph). But for white sturgeon, it's a 100% chance that there is less movement at 96hrs than at 24hrs exposure. 




########### 
     
## Center Zone Models - good and complete! #####
```{r center zone data, echo=F, eval=F} 
DataSum2496.centC = DataSum2496.raw %>%
  filter(!is.na(InZoneC)) %>%  ### will this bias the data if I remove those points where there isn't a detection? If the fish is more likely to be in the center when it's stationary, and it's more likely to be undetected when it's stationary, this may bias these values and under-represent the effect of the bifenthrin (more stationary when strongly affected)
  # also note, this line doesn't actually change the results because summing the InZoneC column drops all NA automatically; this line above just makes that explicit
  group_by(index, Trial, Arena, Replicate, ExposureHrs, Treatment, calcConc, Spp, RepID) %>%
  summarize(InZoneC = sum(InZoneC, na.rm=T), InZoneB = sum(InZoneB, na.rm=T), npos = n()) %>%
  mutate(PercZoneC1 = InZoneC / npos) %>%
  mutate(PercZoneC2 = InZoneC / (InZoneC+InZoneB)) %>%
  # ran this comparison to see how much the NA can influence the data, and it seems to be minor
  ungroup()  %>%
  data.frame()

 DataSum2496.centC$lnCalcConc = log(DataSum2496.centC$calcConc+1)
 DataSum2496.centC$lnCalcConcC= scale(DataSum2496.centC$lnCalcConc, scale=FALSE)
 DataSum2496.centC$lnCalcConcC2 = DataSum2496.centC$lnCalcConcC^2 
    # order of transformations matters (log then scale then square)

 # add a tiny amount to the perc to keep it above zero (issues for fitting because logit(0)=Inf
 # but don't add so much that the max will be =>1
 DataSum2496.centC$PercZoneC1 = DataSum2496.centC$PercZoneC1 +.001
 DataSum2496.centC$PercZoneC2 = DataSum2496.centC$PercZoneC2 +.001
 
```

```{r center zone data 2, echo=F} 
DataSum2496.centC = DataSum2496.raw %>%
  filter(!is.na(InZoneC)) %>%  ### will this bias the data if I remove those points where there isn't a detection? If the fish is more likely to be in the center when it's stationary, and it's more likely to be undetected when it's stationary, this may bias these values and under-represent the effect of the bifenthrin (more stationary when strongly affected)
  # also note, this line doesn't actually change the results because summing the InZoneC column drops all NA automatically; this line above just makes that explicit
  group_by(index, Trial, Arena, Replicate, ExposureHrs, Treatment, calcConc, Spp, RepID) %>%
  summarize(nCent = sum(InZoneC), npos = n()) %>%
  ungroup()  %>%
  data.frame()

 DataSum2496.centC$lnCalcConc = log(DataSum2496.centC$calcConc+1)
 DataSum2496.centC$lnCalcConcC= scale(DataSum2496.centC$lnCalcConc, scale=FALSE)
 DataSum2496.centC$lnCalcConcC2 = DataSum2496.centC$lnCalcConcC^2 
    # order of transformations matters (log then scale then square)

 DataSum2496.centC$nOuter = DataSum2496.centC$npos - DataSum2496.centC$nCent
 
 
```


```{r centerzone multi-level Bayesmodels selection, echo=F, eval=F}
# try setting up the linear model in a bayesian form, same as frequentist model above
# use all meander data points, not summarized data
DScent_bmoddat = DataSum2496.centC[,c("nCent", "npos", "lnCalcConcC","lnCalcConcC2",
                                     "ExposureHrs","Spp","RepID")]
DScent_bmoddat$lnCalcConcC = as.numeric(DScent_bmoddat$lnCalcConcC) 
DScent_bmoddat$lnCalcConcC2 = as.numeric(DScent_bmoddat$lnCalcConcC2) 
DScent_bmoddat$SppDummy <- as.numeric(ifelse(DScent_bmoddat$Spp=="GS", 0,1))
DScent_bmoddat$ExposeDummy <- as.numeric(ifelse(DScent_bmoddat$ExposureHrs=="24", 0,1))

# remove fish with only one timepoint of detection, because cant add random slope with one timepoint
DScent_bmoddat = DScent_bmoddat[!(DScent_bmoddat$RepID %in% paste0(c(0,5,100,500,1000,2000), "-WS-4")),]
DScent_bmoddat$RepID = as.factor(as.character(DScent_bmoddat$RepID))


set.seed(1983)
centspp.blm_int_a = map2stan(
  alist(
    nCent ~ dbinom(npos, p), 
      logit(p)  <- a_fish[RepID] + 
              be*ExposeDummy + 
              bs*SppDummy + 
              bt*(lnCalcConcC) ,
    
           a_fish[RepID] ~ dnorm(a,sigma_fish),
           a ~ dnorm(4,10), # approximate mean of base case (GS-24hr)
           sigma_fish ~ dcauchy(0,2),
        be ~ dnorm(0,10),
        bs ~ dnorm(0,10),
        bt ~ dnorm(0,10)
    ) ,
  data = DScent_bmoddat, iter = 2000, warmup = 300, chains = 3)
# wanders around the parameter space a lot. Doens't look very good at all. Hm. 

set.seed(1983)
centspp.blm_int1 = map2stan(
  alist(
    nCent ~ dbinom(npos, p), 
      logit(p)  <- a_fish[RepID] + 
              be_fish[RepID]*ExposeDummy + 
              bs*SppDummy + 
              bt*(lnCalcConcC) ,
    
           c(a_fish,be_fish)[RepID] ~ dmvnorm2(c(a, be),sigma_fish, Rho),# 
           a ~ dnorm(4,10), # approximate mean of base case (GS-24hr)
           be ~ dnorm(0,10),
           sigma_fish ~ dcauchy(0,2),
           Rho ~ dlkjcorr(2), # not as flat as (1) but biases against strong correlations of intercept and slope
    
        bs ~ dnorm(0,10),
        bt ~ dnorm(0,10)
    ) ,
  data = DScent_bmoddat, iter = 2000, warmup = 300, chains = 3)

set.seed(1983)
centspp.blm_int2 = map2stan(
  alist(
    nCent ~ dbinom(npos, p), 
      logit(p)  <-  a_fish[RepID] + 
              be_fish[RepID]*ExposeDummy + 
              bs*SppDummy + 
              bt*(lnCalcConcC) + 
              bt2*(lnCalcConcC2), 
      
           c(a_fish,be_fish)[RepID] ~ dmvnorm2(c(a, be),sigma_fish, Rho),# 
           a ~ dnorm(4,10), # approximate mean of base case (GS-24hr)
           be ~ dnorm(0,10),
           sigma_fish ~ dcauchy(0,2),
           Rho ~ dlkjcorr(2), # not as flat as (1) but biases against strong correlations of intercept and slope
    
        bs ~ dnorm(0,10),
        bt ~ dnorm(0,10),
        bt2 ~ dnorm(0,10)
    ) ,
  data = DScent_bmoddat, iter = 2000, warmup = 300, chains = 3)

set.seed(1983)
centspp.blm_int3 = map2stan(
  alist(
      nCent ~ dbinom(npos, p), 
      logit(p)  <-  a_fish[RepID] + 
              be_fish[RepID]*ExposeDummy + 
              bs*SppDummy + 
              bt*(lnCalcConcC) + 
              bt2*(lnCalcConcC2) + 
              bt2e*(lnCalcConcC2)*(ExposeDummy), 
      
           c(a_fish,be_fish)[RepID] ~ dmvnorm2(c(a, be),sigma_fish, Rho),# 
           a ~ dnorm(4,10), # approximate mean of base case (GS-24hr)
           be ~ dnorm(0,10),
           sigma_fish ~ dcauchy(0,2),
           Rho ~ dlkjcorr(2), # not as flat as (1) but biases against strong correlations of intercept and slope
    
        bs ~ dnorm(0,10),
        bt ~ dnorm(0,10),
        bt2 ~ dnorm(0,10),
        bt2e ~ dnorm(0,10)
    ) ,
  data = DScent_bmoddat, iter = 2000, warmup = 300, chains = 3)

set.seed(1983)
centspp.blm_int4 = map2stan(
  alist(
    nCent ~ dbinom(npos, p), 
      logit(p)  <- a_fish[RepID] + 
              be_fish[RepID]*ExposeDummy + 
              bs*SppDummy + 
              bt*(lnCalcConcC) + 
              bt2*(lnCalcConcC2) + 
              bt2s*(lnCalcConcC2)*(SppDummy), 
       
           c(a_fish,be_fish)[RepID] ~ dmvnorm2(c(a, be),sigma_fish, Rho),# 
           a ~ dnorm(4,10), # approximate mean of base case (GS-24hr)
           be ~ dnorm(0,10),
           sigma_fish ~ dcauchy(0,2),
           Rho ~ dlkjcorr(2), # not as flat as (1) but biases against strong correlations of intercept and slope
    
        bs ~ dnorm(0,10),
        bt ~ dnorm(0,10),
        bt2 ~ dnorm(0,10),
        bt2s ~ dnorm(0,10)
    ) ,
  data = DScent_bmoddat, iter = 2000, warmup = 300, chains = 3)
## 2294 transitions after warmup that exceeded max treedepth; wants more sampling too

set.seed(1983)
centspp.blm_int5 = map2stan(
  alist(
    nCent ~ dbinom(npos, p),
      logit(p)  <- a_fish[RepID] +
              be_fish[RepID]*ExposeDummy +
              bs*SppDummy +
              bt*(lnCalcConcC) +
              bte*(lnCalcConcC)*(ExposeDummy)+
              bt2*(lnCalcConcC2) +
              bt2s*(lnCalcConcC2)*(SppDummy),

           c(a_fish,be_fish)[RepID] ~ dmvnorm2(c(a, be),sigma_fish, Rho),#
           a ~ dnorm(4,10), # approximate mean of base case (GS-24hr)
           be ~ dnorm(0,10),
           sigma_fish ~ dcauchy(0,2),
           Rho ~ dlkjcorr(2), # not as flat as (1) but biases against strong correlations of intercept and slope

        bs ~ dnorm(0,10),
        bt ~ dnorm(0,10),
        bte ~ dnorm(0,10),
        bt2 ~ dnorm(0,10),
        bt2s ~ dnorm(0,10)
    ) ,
  data = DScent_bmoddat, iter = 2000, warmup = 300, chains = 3)


set.seed(1983)
centspp.blm_int6 = map2stan(
  alist(
    nCent ~ dbinom(npos, p),
      logit(p)  <- a_fish[RepID] +
              be_fish[RepID]*ExposeDummy +
              bs*SppDummy +
              bt*(lnCalcConcC) +
              bte*(lnCalcConcC)*(ExposeDummy)+
              bts*(lnCalcConcC)*(SppDummy),

           c(a_fish,be_fish)[RepID] ~ dmvnorm2(c(a, be),sigma_fish, Rho),#
           a ~ dnorm(4,10), # approximate mean of base case (GS-24hr)
           be ~ dnorm(0,10),
           sigma_fish ~ dcauchy(0,2),
           Rho ~ dlkjcorr(2), # not as flat as (1) but biases against strong correlations of intercept and slope

        bs ~ dnorm(0,10),
        bt ~ dnorm(0,10),
        bte ~ dnorm(0,10),
        bts ~ dnorm(0,10)
    ) ,
  data = DScent_bmoddat, iter = 2000, warmup = 300, chains = 3)

set.seed(1983)
centspp.blm_int7 = map2stan(
  alist(
    nCent ~ dbinom(npos, p),
      logit(p)  <- a_fish[RepID] +
              be_fish[RepID]*ExposeDummy +
              bs*SppDummy +
              bt*(lnCalcConcC) +
              bse*(SppDummy)*(ExposeDummy)+
              bte*(lnCalcConcC)*(ExposeDummy)+
              bts*(lnCalcConcC)*(SppDummy)+
              bt2*(lnCalcConcC2) +
              bt2e*(lnCalcConcC2)*(ExposeDummy)+
              bt2s*(lnCalcConcC2)*(SppDummy),

           c(a_fish,be_fish)[RepID] ~ dmvnorm2(c(a, be),sigma_fish, Rho),#
           a ~ dnorm(4,10), # approximate mean of base case (GS-24hr)
           be ~ dnorm(0,10),
           sigma_fish ~ dcauchy(0,2),
           Rho ~ dlkjcorr(2), # not as flat as (1) but biases against strong correlations of intercept and slope

        bs ~ dnorm(0,10),
        bt ~ dnorm(0,10),
        bse ~ dnorm(0,10),
        bte ~ dnorm(0,10),
        bts ~ dnorm(0,10),
        bt2 ~ dnorm(0,10),
        bt2e ~ dnorm(0,10),
        bt2s ~ dnorm(0,10)
    ) ,
  data = DScent_bmoddat, iter = 2000, warmup = 300, chains = 3)

set.seed(1983)
centspp.blm_int8 = map2stan(
  alist(
    nCent ~ dbinom(npos, p),
      logit(p)  <- a_fish[RepID] +
              be_fish[RepID]*ExposeDummy +
              bs*SppDummy +
              bt*(lnCalcConcC) +
              bse*(SppDummy)*(ExposeDummy)+
              bts*(lnCalcConcC)*(SppDummy)+
              bt2*(lnCalcConcC2) +
              bt2s*(lnCalcConcC2)*(SppDummy),

           c(a_fish,be_fish)[RepID] ~ dmvnorm2(c(a, be),sigma_fish, Rho),#
           a ~ dnorm(4,10), # approximate mean of base case (GS-24hr)
           be ~ dnorm(0,10),
           sigma_fish ~ dcauchy(0,2),
           Rho ~ dlkjcorr(2), # not as flat as (1) but biases against strong correlations of intercept and slope

        bs ~ dnorm(0,10),
        bt ~ dnorm(0,10),
        bse ~ dnorm(0,10),
        bts ~ dnorm(0,10),
        bt2 ~ dnorm(0,10),
        bt2s ~ dnorm(0,10)
    ) ,
  data = DScent_bmoddat, iter = 2000, warmup = 300, chains = 3)

compare(centspp.blm_int1, centspp.blm_int2, centspp.blm_int3, centspp.blm_int4, centspp.blm_int5, centspp.blm_int6, centspp.blm_int7,centspp.blm_int8)
## models are basically all the same...8 is slightly better WAIC than 7 (1.6) suggesting there isn't a need for the interacgtion between treatment and exposure period. But 7 is the only one that is >2 different from the 'best' which are models 2 and 4

```

```{r centerzone multi-level Bayesmodels final, echo=F}
DScent_bmoddat = DataSum2496.centC[,c("nCent", "npos", "lnCalcConcC","lnCalcConcC2", "ExposureHrs","Spp","RepID")]
DScent_bmoddat$lnCalcConcC = as.numeric(DScent_bmoddat$lnCalcConcC) 
DScent_bmoddat$lnCalcConcC2 = as.numeric(DScent_bmoddat$lnCalcConcC2) 
DScent_bmoddat$SppDummy <- as.numeric(ifelse(DScent_bmoddat$Spp=="GS", 0,1))
DScent_bmoddat$ExposeDummy <- as.numeric(ifelse(DScent_bmoddat$ExposureHrs=="24", 0,1))

# remove fish with only one timepoint of detection, because cant add random slope with one timepoint
DScent_bmoddat = DScent_bmoddat[!(DScent_bmoddat$RepID %in% paste0(c(0,5,100,500,1000,2000), "-WS-4")),]
DScent_bmoddat$RepID = as.factor(as.character(DScent_bmoddat$RepID))



set.seed(1983)
centspp.blm_int8 = map2stan(
  alist(
    nCent ~ dbinom(npos, p),
      logit(p)  <- a_fish[RepID] +
              be_fish[RepID]*ExposeDummy +
              bs*SppDummy +
              bt*(lnCalcConcC) +
              bse*(SppDummy)*(ExposeDummy)+
              bts*(lnCalcConcC)*(SppDummy)+
              bt2*(lnCalcConcC2) +
              bt2s*(lnCalcConcC2)*(SppDummy),

           c(a_fish,be_fish)[RepID] ~ dmvnorm2(c(a, be),sigma_fish, Rho),#
           a ~ dnorm(4,10), # approximate mean of base case (GS-24hr)
           be ~ dnorm(0,10),
           sigma_fish ~ dcauchy(0,2),
           Rho ~ dlkjcorr(2), # not as flat as (1) but biases against strong correlations of intercept and slope

        bs ~ dnorm(0,10),
        bt ~ dnorm(0,10),
        bse ~ dnorm(0,10),
        bts ~ dnorm(0,10),
        bt2 ~ dnorm(0,10),
        bt2s ~ dnorm(0,10)
    ) ,
  data = DScent_bmoddat, iter = 2000, warmup = 300, chains = 3)


# check model
 precis(centspp.blm_int8, prob = .95, digits=3)
 plot(precis(centspp.blm_int8, prob = .95))
 plot(precis(centspp.blm_int8, prob = .95, depth=2))

 plot(centspp.blm_int8)
```

```{r center zone multi-level Bayesmodels predict, echo=F, eval=F}

# pull posterior from model:
set.seed(42)
post = extract.samples(centspp.blm_int8)

# set up dataframe to plot posterior predictions
preddat = list(CalcConc=rep(seq(0, 2250, 2), 4), 
               lnCalcConc=log(rep(seq(0, 2250, 2),4)+1), 
               lnCalcConcC=(log(rep(seq(0, 2250, 2),4)+1)) - 
                 mean(DataSum2496.centC$lnCalcConc) ,
               lnCalcConcC2=((log(rep(seq(0, 2250, 2),4)+1)) - 
                 mean(DataSum2496.centC$lnCalcConc))^2 ,               
               ExposeDummy = rep(c(0,1), each=1126*2), 
               SppDummy = rep(rep(c(0,1),each=1126),2), 
               RepID = rep(2,4504),
               npos = rep(mean(DataSum2496.centC$npos), 4504) )

# make zeros for individual random effects to predict to mean only -> model doesn't have any 'a' this way
  # a_fish_zeros = matrix(0,12000,90)
  # be_fish_zeros = matrix(0,12000,90)

# use estimated posteriors for population of individuals to simulate new fish; shapes of distributions between model posteriors and predicted posteriors are nearly identical, not what I want...but it does predict uncertainty across individuals, but might as well just take predictions for individual fish are put them in as the data...not quote grasping this
  # a_fish_sim = matrix(rnorm(12000*90, mean(post$a_fish), mean(post$sigma_fish[,1])),12000,90)
  # be_fish_sim = matrix(rnorm(12000*90, mean(post$be_fish), mean(post$sigma_fish[,2])),12000,90)

# replace individual fish estimates with global estimate; this should predict to the average individual in a population...so since I want to get at the population level response this seems more appropriate.
a_global = matrix(post$a,459000,90)
be_global = matrix(post$be,459000,90)

# use link to predict to mean only
# link.int2 <- link(centspp.blm_int2, n=1000, data= preddat, 
#                          replace = list(a_fish = a_global, 
#                                         be_fish = be_global) )
# link.int3 <- link(centspp.blm_int3, n=1000, data= preddat, 
#                          replace = list(a_fish = a_global, 
#                                         be_fish = be_global) )
# link.int4 <- link(centspp.blm_int4, n=1000, data= preddat, 
#                          replace = list(a_fish = a_global, 
#                                         be_fish = be_global) )
# link.int5 <- link(centspp.blm_int5, n=1000, data= preddat, 
#                          replace = list(a_fish = a_global, 
#                                         be_fish = be_global) )
# link.int6 <- link(centspp.blm_int6, n=1000, data= preddat, 
#                          replace = list(a_fish = a_global, 
#                                         be_fish = be_global) )
# link.int7 <- link(centspp.blm_int7, n=1000, data= preddat, 
#                          replace = list(a_fish = a_global, 
#                                         be_fish = be_global) )
link.int8 <- link(centspp.blm_int8, n=1000, data= preddat, 
                         replace = list(a_fish = a_global, 
                                        be_fish = be_global) )
preddat.df <- data.frame(sapply(preddat,c)) # thanks stack overflow! (turns the list into a dataframe) https://stackoverflow.com/questions/4227223/convert-a-list-to-a-data-frame

preddat.df$link_mu_mn <- apply(link.int8, 2, mean) 
preddat.df$link_PI05 = apply(link.int8, 2, PI, .95)[1,] 
preddat.df$link_PI95 = apply(link.int8, 2, PI, .95)[2,] 

# preddat.df$link_mu_mn <- apply(link.int5, 2, mean) 
# preddat.df$link_PI05 = apply(link.int5, 2, PI, .95)[1,] 
# preddat.df$link_PI95 = apply(link.int5, 2, PI, .95)[2,] 
 

# # predict from posteriors (on transformed scale)
#   link_pred <- link(distspp.blm_int2.rise, data = preddat, n=1000) 
#   preddat$link_mu_mn <- apply(link_pred, 2, mean)
#   preddat$link_PI05 = apply(link_pred, 2, PI, .95)[1,]
#   preddat$link_PI95 = apply(link_pred, 2, PI, .95)[2,]
#   
#  # predict with sim; it's my understanding that this integrates the error estimates too?
#   sim_pred <- sim(distspp.blm_int2.rise, data = preddat, n=1000) 
#   preddat$sim_mu_mn <- apply(sim_pred, 2, mean)
#   preddat$sim_PI05 = apply(sim_pred, 2, PI, .95)[1,]
#   preddat$sim_PI95 = apply(sim_pred, 2, PI, .95)[2,]
#  
  # plot predictions and data
  preddat.df$Spp <- ifelse(preddat.df$SppDummy==0,"GS","WS")
  preddat.df$ExposureHrs <- ifelse(preddat.df$ExposeDummy==0,"24","96")


CentPred_transf_plot2_mod8 = ggplot() + 
  geom_point(data=DataSum2496.centC,
             aes(x=(lnCalcConcC),                          
                 y=nCent/npos, 
                 color=factor(Spp))) + 
  geom_ribbon(data = preddat.df, aes(x=(lnCalcConcC), 
              ymin=link_PI05, ymax=link_PI95), 
              alpha=.4, col="grey70")+
  geom_line(data = preddat.df, aes(x=(lnCalcConcC), y=link_mu_mn), lwd=.2)+ 
    facet_grid(Spp~ExposureHrs, scales="free", labeller = labeller(
      ExposureHrs = c("24"="24 Hours Exposure","96"="96 Hours Exposure"),
      Spp = c("GS" = "Green Sturgeon", "WS" = "White Sturgeon")))+
    scale_color_manual(values=c("green3", "steelblue3"), guide=FALSE)+
    ylab("Proportion of Positions within Central Zone") + 
    scale_x_continuous(name="log(Bifenthrin Concentration) (ng/L)") + #, breaks = seq(-7.5,5, 2.5), labels=(seq(-7.5,5, 2.5)+3.73) ) +
    theme_bw()


CentPred_orig_plot2_mod8 = ggplot() + 
  geom_point(data=DataSum2496.centC,
             aes(x=(calcConc),                          
                 y=nCent/npos, 
                 color=factor(Spp))) + 
  geom_ribbon(data = preddat.df, aes(x=(CalcConc), 
              ymin=link_PI05, ymax=link_PI95), 
              alpha=.4, col="grey70")+
  geom_line(data = preddat.df, aes(x=(CalcConc), y=link_mu_mn), lwd=.2)+
  facet_grid(Spp~ExposureHrs, scales="free", labeller = labeller(
    ExposureHrs = c("24"="24 Hours Exposure","96"="96 Hours Exposure"),
    Spp = c("GS" = "Green Sturgeon", "WS" = "White Sturgeon")))+
  scale_color_manual(values=c("green3", "steelblue3"), guide=FALSE)+
  ylab("Proportion of Positions within Central Zone") + 
  scale_x_continuous(name="Bifenthrin Concentration (ng/L)") + #, breaks = seq(-7.5,5, 2.5), labels=(seq(-7.5,5, 2.5)+3.73) ) +
  theme_bw()


CentPred_orig_plot_96_mod8 = ggplot() + 
  geom_point(data=DataSum2496.centC[DataSum2496.centC$ExposureHrs==96,],
             aes(x=(calcConc),                          
                 y=nCent/npos, 
                 color=factor(Spp))) + 
  geom_ribbon(data = preddat.df[preddat.df$ExposureHrs==96,], 
              aes(x=(CalcConc), 
              ymin=link_PI05, ymax=link_PI95), 
              alpha=.4, col="grey70")+
  geom_line(data = preddat.df[preddat.df$ExposureHrs==96,],
            aes(x=(CalcConc), y=link_mu_mn), lwd=.2)+
  facet_grid(Spp~., scales="free", labeller = labeller(
    Spp = c("GS" = "Green Sturgeon", "WS" = "White Sturgeon")))+
  scale_color_manual(values=c("green3", "steelblue3"), guide=FALSE)+
  ylab("Proportion of Positions within Central Zone") + 
  scale_x_continuous(name="Bifenthrin Concentration (ng/L)") + #, breaks = seq(-7.5,5, 2.5), labels=(seq(-7.5,5, 2.5)+3.73) ) +
  theme_bw()


# CentPred_transf_plot2_mod1
# CentPred_transf_plot2_mod2
# CentPred_transf_plot2_mod3
# CentPred_transf_plot2_mod4
# CentPred_transf_plot2_mod5
# CentPred_transf_plot2_mod6
# CentPred_transf_plot2_mod7
CentPred_transf_plot2_mod8

# CentPred_orig_plot2_mod1
# CentPred_orig_plot2_mod2
# CentPred_orig_plot2_mod3
# CentPred_orig_plot2_mod4
# CentPred_orig_plot2_mod5
# CentPred_orig_plot2_mod6
# CentPred_orig_plot2_mod7
CentPred_orig_plot2_mod8
CentPred_orig_plot_96_mod8
```
 ### Hm. WAIC suggests they're nearly all equal, except for 7 (barely, nearly better). From looking at the fit of the prediction lines, I think 6 is not a good model because without the quadratic it doesn't fit the curve of the data and the mechanism we expected. Model 5 allows the quadratic to vary by species (green sturgeon curve becomes flatter in the transformed plots), and the effect of concentration to vary by exposure period (24 hr curve becomes flatter). This looks pretty good, but the confidence bands are wider than those for model 4 while the trend is very smiliar. Model 3 lets the quadratic vary by exposure period (but not spp), so I built/fit Model 7 to let both the standard and quadratic effectws for treatment vary by exposure period and species (ie: seperate line for each of the four facets). This model seems to be better, or at least not worse, based on AIC, and the plots look better too. Let's go with 7 - I think it's similar to the model for distance too, which will make the paper easier to write. Oops. Model 8 matches the distance model. And it is slightly better on AIC - it removes the interactions between treatment and exposure time. 
 
 
 
### Central Zone Contrasts

### Study questions: 

###  1) is there an effect (all treatment vs control), and which metrics show an effect
- posterior for bt x control vs posteriors for bt x each level of treatment (5 comps)
- in reality, this seems better nested under the following two contrast grouping, because the early-life stange behavior of the two species is so different, and it also seems that the WS are more affected (or perhaps just more mobile and this easier to detect change?)

###  2) Does the magnitude of the effect vary between species
- posterior for bt X GS x control vs posteriors for bt x GS x each level of treatment (5 comps)
- posterior for bt x WS x control vs posteriors for bt x WS x each level of treatment (5 comps)
= 10 comparisons

###  3) does that effect change with time [96 treat vs 96 control and 24 treat vs 24 control OR individual change from 24 to 96 (all treatments) as compared to individual change for control between 24 and 96]
- posterior for bt-24control vs bt-24xtreatments (n=5) and bt-96control vs bt-96 treatments (n=5) = 10 comparisons
- OR the above comparisions by species
= 20 comparisons. 


### Esh. Appendix table? mean difference, 95%CI or probability that the difference is not zero, which is more comparable to a p-value I think. It's the confidence that there IS a difference in the direction indicated (+ or -)



```{r cent multi-level model density plots and conc contrasts, echo=F}
set.seed(1983) 
postcent = extract.samples(centspp.blm_int8)
 
    # # reference table to convert from treatment to centered, log-transformed measured concentrations
TreatCalcTable = unique(DataSum2496.centC[order(DataSum2496.centC$Treatment)
                                             ,c("Spp", "Treatment", 
                                                "lnCalcConc", "lnCalcConcC")])
TreatCalcTable$lnCalcConcC2 = TreatCalcTable$lnCalcConcC ^ 2



# calculate differences between control and treatment at each time point for each species (20 contrasts)
GS0bif24cent = postcent$a +
  postcent$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==0)$lnCalcConcC) +
  postcent$bt2*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==0)$lnCalcConcC2)
GS5bif24cent = postcent$a + 
  postcent$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==5)$lnCalcConcC) +
  postcent$bt2*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==5)$lnCalcConcC2)
GS100bif24cent = postcent$a + 
  postcent$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==100)$lnCalcConcC) +
  postcent$bt2*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==100)$lnCalcConcC2)
GS500bif24cent = postcent$a + 
  postcent$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==500)$lnCalcConcC) +
  postcent$bt2*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==500)$lnCalcConcC2)
GS1000bif24cent = postcent$a +
  postcent$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==1000)$lnCalcConcC) + 
  postcent$bt2* as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==1000)$lnCalcConcC2)
GS2000bif24cent = postcent$a + 
  postcent$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==2000)$lnCalcConcC) + 
  postcent$bt2*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==2000)$lnCalcConcC2)

# complile into a list
GS24cent.list = list(GS0bif24cent, GS5bif24cent, GS100bif24cent,
                     GS500bif24cent, GS1000bif24cent, GS2000bif24cent)

# write come output functions to reduce code length
logistic.summary.func = function(x) { mean = logistic(mean(x))
                                      Lower95CI = logistic(quantile(x,.025))
                                      Upper95CI = logistic(quantile(x,.975))
                                      return(data.frame(mean = mean,
                                                        U95CI = Upper95CI,
                                                        L95CI=Lower95CI)) }

# use functions to 
   pred.muGS24 = data.frame(nomconc = c(0,5,100,500,1000,2000), 
                            Spp = "GS",
                            ExposureHrs = 24,
                     pred.centZone = t(sapply(GS24cent.list,logistic.summary.func)),
                       diff.meancontrol = c(NA, sapply(GS24cent.list[2:6], function(x) mean(GS24cent.list[[1]]) - mean(x) )),
                     prob.greater0 = c(NA, mapply(function(x,y) sum(x<y), GS24cent.list[1], GS24cent.list[2:6]) / length(GS24cent.list[[1]]) ) )

         
 
GS24cent.plot = ggplot() + geom_density(aes(x=logistic(GS0bif24cent), color="black")) + 
  geom_density(aes(x=logistic(GS5bif24cent), color="green3")) + 
  geom_density(aes(x=logistic(GS100bif24cent), color="goldenrod")) + 
  geom_density(aes(x=logistic(GS500bif24cent), color="red3")) + 
  geom_density(aes(x=logistic(GS1000bif24cent), color="pink")) + 
  geom_density(aes(x=logistic(GS2000bif24cent), color="steelblue3")) + 
  scale_color_manual(name="Nominal Bifenthrin\nConcentration", 
                     values=c("black"="black", "green3"="green3", 
                              "goldenrod"="goldenrod","red3"="red3", 
                              "pink"="pink","steelblue3"="steelblue3"), 
                     labels=c("0 ng/L", "5 ng/L", "100ng/L", 
                              "500ng/L", "1000ng/L", "2000 ng/L") ) + 
  xlab("probability of Detection in Central Zone (GS @ 24hr)")+
  xlim(c(0,1))+
  theme_bw()







# repeat for green sturgeon, 96hr

GS0bif96cent = postcent$a + postcent$be +
  postcent$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==0)$lnCalcConcC) +
  postcent$bt2*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==0)$lnCalcConcC2) 
GS5bif96cent = postcent$a + postcent$be + 
  postcent$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==5)$lnCalcConcC) +
  postcent$bt2*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==5)$lnCalcConcC2)
GS100bif96cent = postcent$a + postcent$be + 
  postcent$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==100)$lnCalcConcC) +
  postcent$bt2*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==100)$lnCalcConcC2)
GS500bif96cent = postcent$a + postcent$be + 
  postcent$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==500)$lnCalcConcC) +
  postcent$bt2*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==500)$lnCalcConcC2)
GS1000bif96cent = postcent$a + postcent$be +
  postcent$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==1000)$lnCalcConcC) + 
  postcent$bt2* as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==1000)$lnCalcConcC2)
GS2000bif96cent = postcent$a + postcent$be + 
  postcent$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==2000)$lnCalcConcC) + 
  postcent$bt2*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==2000)$lnCalcConcC2)

## complile into a list
GS96cent.list = list(GS0bif96cent, GS5bif96cent, GS100bif96cent,
                     GS500bif96cent, GS1000bif96cent, GS2000bif96cent)

# write come output functions to reduce code length
logistic.summary.func = function(x) { mean = logistic(mean(x))
                                      Lower95CI = logistic(quantile(x,.025))
                                      Upper95CI = logistic(quantile(x,.975))
                                      return(data.frame(mean = mean,
                                                        U95CI = Upper95CI,
                                                        L95CI=Lower95CI)) }

# use functions to 
   pred.muGS96 = data.frame(nomconc = c(0,5,100,500,1000,2000), 
                            Spp = "GS",
                            ExposureHrs = 96,
                     pred.centZone = t(sapply(GS96cent.list,logistic.summary.func)),
                     diff.meancontrol = c(NA, sapply(GS96cent.list[2:6], function(x) mean(GS96cent.list[[1]]) - mean(x) )),
                     prob.greater0 = c(NA, mapply(function(x,y) sum(x<y), GS96cent.list[1], GS96cent.list[2:6]) / length(GS96cent.list[[1]]) ) )



GS96cent.plot = ggplot() + geom_density(aes(x=logistic(GS0bif96cent)), color="black") + 
  geom_density(aes(x=logistic(GS5bif96cent)), color="green3") + 
  geom_density(aes(x=logistic(GS100bif96cent)), color="goldenrod") + 
  geom_density(aes(x=logistic(GS500bif96cent)), color="red3") + 
  geom_density(aes(x=logistic(GS1000bif96cent)), color="pink") + 
  geom_density(aes(x=logistic(GS2000bif96cent)), color="steelblue3") + 
  scale_color_manual(name="Nominal Bifenthrin\nConcentration", 
                     values=c("black"="black", "green3"="green3", "goldenrod"="goldenrod",
                              "red3"="red3", "pink"="pink","steelblue3"="steelblue3"), 
                     labels=c("0 ng/L", "5 ng/L", "100ng/L", 
                              "500ng/L", "1000ng/L", "2000 ng/L") ) + 
  xlab("Proportion of Detections in Central Zone (GS @ 96hr)")+
  xlim(c(0,1))+
  theme_bw()


# repeat for white sturgeon, 24hr

WS0bif24cent = postcent$a + postcent$bs +
  postcent$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==0)$lnCalcConcC) +
  postcent$bt2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==0)$lnCalcConcC2) +
  postcent$bt2s*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==0)$lnCalcConcC2)
WS5bif24cent = postcent$a + postcent$bs + 
  postcent$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==5)$lnCalcConcC) +
  postcent$bt2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==5)$lnCalcConcC2)+
  postcent$bt2s*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==5)$lnCalcConcC2)
WS100bif24cent = postcent$a + postcent$bs + 
  postcent$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==100)$lnCalcConcC) +
  postcent$bt2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==100)$lnCalcConcC2)+
  postcent$bt2s*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==100)$lnCalcConcC2)
WS500bif24cent = postcent$a + postcent$bs + 
  postcent$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==500)$lnCalcConcC) +
  postcent$bt2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==500)$lnCalcConcC2)+
  postcent$bt2s*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==500)$lnCalcConcC2)
WS1000bif24cent = postcent$a + postcent$bs +
  postcent$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==1000)$lnCalcConcC) + 
  postcent$bt2* as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==1000)$lnCalcConcC2)+
  postcent$bt2s* as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==1000)$lnCalcConcC2)
WS2000bif24cent = postcent$a + postcent$bs + 
  postcent$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==2000)$lnCalcConcC) + 
  postcent$bt2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==2000)$lnCalcConcC2)+
  postcent$bt2s*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==2000)$lnCalcConcC2)



# complile into a list
WS24cent.list = list(WS0bif24cent, WS5bif24cent, WS100bif24cent,
                     WS500bif24cent, WS1000bif24cent, WS2000bif24cent)

# write come output functions to reduce code length
logistic.summary.func = function(x) { mean = logistic(mean(x))
                                      Lower95CI = logistic(quantile(x,.025))
                                      Upper95CI = logistic(quantile(x,.975))
                                      return(data.frame(mean = mean,
                                                        U95CI = Upper95CI,
                                                        L95CI=Lower95CI)) }

# use functions to 
   pred.muWS24 = data.frame(nomconc = c(0,5,100,500,1000,2000), 
                            Spp = "WS",
                            ExposureHrs = 24,
                     pred.centZone = t(sapply(WS24cent.list,logistic.summary.func)),
                     diff.meancontrol = c(NA, sapply(WS24cent.list[2:6], function(x) mean(WS24cent.list[[1]]) - mean(x) )),
                     prob.greater0 = c(NA, mapply(function(x,y) sum(x<y), WS24cent.list[1], WS24cent.list[2:6]) / length(WS24cent.list[[1]]) ) )

   
WS24cent.plot = ggplot() + geom_density(aes(x=logistic(WS0bif24cent)), color="black") + 
  geom_density(aes(x=logistic(WS5bif24cent)), color="green3") + 
  geom_density(aes(x=logistic(WS100bif24cent)), color="goldenrod") + 
  geom_density(aes(x=logistic(WS500bif24cent)), color="red3") + 
  geom_density(aes(x=logistic(WS1000bif24cent)), color="pink") + 
  geom_density(aes(x=logistic(WS2000bif24cent)), color="steelblue3") + 
  scale_color_manual(name="Nominal Bifenthrin\nConcentration", 
                     values=c("black"="black", "green3"="green3", "goldenrod"="goldenrod",
                              "red3"="red3", "pink"="pink","steelblue3"="steelblue3"), 
                     labels=c("0 ng/L", "5 ng/L", "100ng/L", 
                              "500ng/L", "1000ng/L", "2000 ng/L") ) + 
  xlab("Proportion of Detections in Central Zone (WS @ 24hr)")+
  xlim(c(0,1))+
  theme_bw()


# repeat for white sturgeon, 96hr


WS0bif96cent = postcent$a + postcent$bs + postcent$be + postcent$bse + 
  postcent$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==0)$lnCalcConcC) +
  postcent$bt2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==0)$lnCalcConcC2) +
  postcent$bt2s*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==0)$lnCalcConcC2)

WS5bif96cent = postcent$a + postcent$bs + postcent$be + postcent$bse +
  postcent$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==5)$lnCalcConcC) +
  postcent$bt2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==5)$lnCalcConcC2) +
  postcent$bt2s*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==5)$lnCalcConcC2)

WS100bif96cent = postcent$a + postcent$bs + postcent$be + postcent$bse +
  postcent$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==100)$lnCalcConcC) +
  postcent$bt2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==100)$lnCalcConcC2) +
  postcent$bt2s*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==100)$lnCalcConcC2)

WS500bif96cent = postcent$a + postcent$bs + postcent$be + postcent$bse +
  postcent$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==500)$lnCalcConcC) +
  postcent$bt2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==500)$lnCalcConcC2) +
  postcent$bt2s*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==500)$lnCalcConcC2)

WS1000bif96cent = postcent$a + postcent$bs + postcent$be + postcent$bse +
  postcent$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==1000)$lnCalcConcC) + 
  postcent$bt2* as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==1000)$lnCalcConcC2) +
  postcent$bt2s* as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==1000)$lnCalcConcC2)

WS2000bif96cent = postcent$a + postcent$bs + postcent$be + postcent$bse +
  postcent$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==2000)$lnCalcConcC) + 
  postcent$bt2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==2000)$lnCalcConcC2) +
  postcent$bt2s*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==2000)$lnCalcConcC2)


## complile into a list
WS96cent.list = list(WS0bif96cent, WS5bif96cent, WS100bif96cent,
                     WS500bif96cent, WS1000bif96cent, WS2000bif96cent)

# write come output functions to reduce code length
logistic.summary.func = function(x) { mean = logistic(mean(x))
                                      Lower95CI = logistic(quantile(x,.025))
                                      Upper95CI = logistic(quantile(x,.975))
                                      return(data.frame(mean = mean,
                                                        U95CI = Upper95CI,
                                                        L95CI=Lower95CI)) }

# use functions to 
   pred.muWS96 = data.frame(nomconc = c(0,5,100,500,1000,2000), 
                            Spp = "WS",
                            ExposureHrs = 96,
                     pred.centZone = t(sapply(WS96cent.list,logistic.summary.func)),
                     diff.meancontrol = c(NA, sapply(WS96cent.list[2:6], function(x) mean(WS96cent.list[[1]]) - mean(x) )),
                     prob.greater0 = c(NA, mapply(function(x,y) sum(x<y), WS96cent.list[1], WS96cent.list[2:6]) / length(WS96cent.list[[1]]) ) )


WS96cent.plot = ggplot() + geom_density(aes(x=logistic(WS0bif96cent)), color="black") + 
  geom_density(aes(x=logistic(WS5bif96cent)), color="green3") + 
  geom_density(aes(x=logistic(WS100bif96cent)), color="goldenrod") + 
  geom_density(aes(x=logistic(WS500bif96cent)), color="red3") + 
  geom_density(aes(x=logistic(WS1000bif96cent)), color="pink") + 
  geom_density(aes(x=logistic(WS2000bif96cent)), color="steelblue3") + 
  scale_color_manual(name="Nominal Bifenthrin\nConcentration", 
                     values=c("black"="black", "green3"="green3", "goldenrod"="goldenrod",
                              "red3"="red3", "pink"="pink","steelblue3"="steelblue3"), 
                     labels=c("0 ng/L", "5 ng/L", "100ng/L", 
                              "500ng/L", "1000ng/L", "2000 ng/L") ) + 
  xlab("Proportion of Detections in Central Zone (WS @ 96hr)")+
  xlim(c(0,1))+
  theme_bw()

GS24cent.plot + GS96cent.plot + WS24cent.plot + WS96cent.plot


# compile it for output
predgroups = list(GS0bif24cent, GS5bif24cent, GS100bif24cent,
                  GS500bif24cent, GS1000bif24cent, GS2000bif24cent,
                  GS0bif96cent, GS5bif96cent, GS100bif96cent,
                  GS500bif96cent, GS1000bif96cent, GS2000bif96cent,
                  WS0bif24cent, WS5bif24cent, WS100bif24cent,
                  WS500bif24cent, WS1000bif24cent, WS2000bif24cent,
                  WS0bif96cent, WS5bif96cent, WS100bif96cent,
                  WS500bif96cent, WS1000bif96cent, WS2000bif96cent)
PredGroupNames =  as.character(expression(GS0bif24cent, GS5bif24cent, GS100bif24cent, 
                                          GS500bif24cent, GS1000bif24cent, GS2000bif24cent, 
                                          GS0bif96cent, GS5bif96cent, GS100bif96cent, 
                                          GS500bif96cent, GS1000bif96cent, GS2000bif96cent,
                                          WS0bif24cent, WS5bif24cent, WS100bif24cent, 
                                          WS500bif24cent, WS1000bif24cent, WS2000bif24cent, 
                                          WS0bif96cent, WS5bif96cent, WS100bif96cent,
                                          WS500bif96cent, WS1000bif96cent, WS2000bif96cent))
posterior.preds = data.frame(PredGroupNames = PredGroupNames, 
                             PredMeans = sapply(predgroups, mean),
                             Pred95CIl = sapply(predgroups, quantile, 0.05),
                             Pred95CIu = sapply(predgroups, quantile, 0.95))

# try to compile again in a different way. Didn't know I'd already done this here, and did it again with each spp/exp group above. Oops. 
grouplist = list(pred.muGS24,pred.muGS96,pred.muWS24,pred.muWS96)
posterior.preds2 = do.call(rbind, grouplist)

```
#### if use this in a paper, recolor to a more intuitive gradient and add legend
 
 
```{r center zone  multi-level model time and spp contrasts, echo=F}
# this uses the predicted posteriors for time in central zone, calculated above

# GS vs WS
cont.GS.WS_0bif_24cent = sum(GS0bif24cent<WS0bif24cent) / length(GS0bif24cent)
 cont.GS.WS_0bif_24cent # 19.7% probability that GS will spend less time in center than WS, at 24hrs (ie: GS should be in the center more)

 cont.GS.WS_0bif_96cent = sum(GS0bif96cent<WS0bif96cent) / length(GS0bif96cent)
 cont.GS.WS_0bif_96cent # 42.7% probability that GS will spend less time in center than WS, at 96 hrs, which translates to a 57.2% probability that WS will spend less time in the center than GS. In otherwords, there's not  much difference in time spent in central zone at 96 hours because WS increase their use of the middle as they age
  
cont.GS.WS_5bif_24cent = sum(GS5bif24cent<WS5bif24cent) / length(GS5bif24cent)
 cont.GS.WS_5bif_24cent # 1.6% probability that GS will spend less time in center than WS, after 24 hrs exposure to 100ng/L bifenthrin (ie: GS found in center more than WS)

 cont.GS.WS_5bif_96cent = sum(GS5bif96cent<WS5bif96cent) / length(GS5bif96cent)
 cont.GS.WS_5bif_96cent # 6.2% probability that GS will spend less time in center than WS, after 96 hrs exposure to 100ng/L bifenthrin (ie: GS in center more than WS, but not quite to standard 5% probability 'significance' standard
   
cont.GS.WS_100bif_24cent = sum(GS100bif24cent<WS100bif24cent) / length(GS100bif24cent)
 cont.GS.WS_100bif_24cent # <0.001% probability that GS will spend less time in center than WS after 24hrs of exposure to 100ng/L bifenthrin. Ie: highly likely that GS spend more time in center than WS.
  
cont.GS.WS_100bif_96cent = sum(GS100bif96cent<WS100bif96cent) / length(GS100bif96cent)
 cont.GS.WS_100bif_96cent # 0.02% probability that GS will spend less time in center than WS after 24hrs of exposure to 100ng/L bifenthrin. Ie: highly likely that GS spend more time in center than WS.

 ## etc...
 
 cont.GS.WS_2000bif_96cent = sum(GS2000bif96cent<WS2000bif96cent) / length(GS2000bif96cent)
 cont.GS.WS_2000bif_96cent # 1.1% probability that GS will spend less time in center than WS at 96 hrs, when exposed to 2000ng/L bifenthrin. Ie: highly likely that GS spend more time in center than WS after 96hrs of exposure t0 2000ng/L bifenthrin
 
cont.GS.WS_2000bif_24cent = sum(GS2000bif24cent<WS2000bif24cent) / length(GS2000bif24cent)
 cont.GS.WS_2000bif_24cent # 0.2% probability that GS will spend less time in center than WS after 96hrs of exposure to 2000ng/L bifenthrin. Ie: highly likely that GS spend more time in center than WS.

 cont.GS.WS_2000bif_96cent = sum(GS2000bif96cent<WS2000bif96cent) / length(GS2000bif96cent)
 cont.GS.WS_2000bif_96cent # 0.01% probability that GS will spend less time in center than WS at 96 hrs, when exposed to 2000ng/L bifenthrin. Ie: highly likely that GS spend more time in center than WS after 96hrs of exposure t0 2000ng/L bifenthrin


# Green Sturgeon, Exposure Hr (no change at different levels since no exposure*treatment term in model
cont.GS0bif_96.24cent = (sum(GS0bif96cent<GS0bif24cent) / length(GS0bif96cent)) 
cont.GS0bif_96.24cent
 # 22.7% of the samples from the posterior showed less use of central zone by GS at 96 than 24; so most likely that central-zone use is greater at 96 than 24 (77.3%), but not 'significant' if using standard cut-off thresholds

GS0bif_96.24cent.plot = ggplot() + geom_density(aes(x=GS0bif96cent), color="steelblue3") + 
  geom_density(aes(x=GS0bif24cent), color="green3") + 
  xlab("Distance moved - GS @ 0 ng/L bifenthrin\n24 vs 96 hrs)") +
  theme_bw()

# use patchwork grammar to plot multiple plots
GS0bif_96.24cent.plot



# White Sturgeon: probability of a difference between 24 and 96 hours, at each treatment level
cont.WS0bif_96.24cent = (sum(WS0bif96cent<WS0bif24cent) / length(WS0bif96cent)) 
cont.WS0bif_96.24cent
# 2.1% of the samples from the posterior showed less use of central zone by WS at 96 than 24; so highly likely that WS use of central zone is greater at 96 than 24 (97.9%) 'significant' using standard thresholds

WS0bif_96.24cent.plot = ggplot() + geom_density(aes(x=WS0bif96cent), color="steelblue3") + 
  geom_density(aes(x=WS0bif24cent), color="green3") + 
  xlab("Distance moved - WS @ 0 ng/L bifenthrin\n24 vs 96 hrs)") +
  theme_bw()
WS0bif_96.24cent.plot


```
