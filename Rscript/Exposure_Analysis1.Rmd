---
title: "Exposure Ethovision Analysis - Data Cleaning"
author: "Anna Steel"
date: "2/24/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(readtext) # need this because the ethovision output .txt files have unusual encoding as UTF-16
library(lme4)
library(rethinking)
library(rprojroot) # only used for find_rstudio_root_file() to set project wd as root

knitr::opts_knit$set(root.dir = find_rstudio_root_file()) # sets root directory to match project directory, not rmd file location
```

```{r utility functions}
# calculate hypotenuse of triangle created by two xy locations

distmov = function(x1,x2,y1,y2) { dm = sqrt((x1-x2)^2 + (y1-y2)^2); return(dm)}

# calculate number steps between detections; use summarized dataset (5 pos/sec)
nstep = function(t2,t1, interv=0.2) {
  if (t2-t1 < 0) stop('time steps backwards?')
  nstep <- ( (t2-t1) / interv)
  return(nstep)
  }



```


## Prep Data for 2020 GS/WS Exposures
  
Raw data is after manual data editing in ethovision, primarily for GS trials before addition of the white curtain.  
  
For nearly all instances where there is missing data for fish it is because the fish was still. The ethovision program either lost the fish and didn't record any locations, or the program recorded a moving reflection while the fish was still. These later instances were removed via manual editing, along with other reflection recordings when the track jumped from the fish to the reflection and back again.  

Within the code I will create a second dataset where the missing data are replaced with DistanceMoved=0 to evaluate the % of time a fish was moving. In other places I will use the data with NA for missing data points, and compare this with an interpolation process between the previous and subsequent known points (ideally the fish is near the same location at those two timepoints)

The data used here were tracked with the filter "MDM2 02 7,5 mm" in ethovision projects named "Exposure_GS_Pilot" and "Exposure_WS_Pilot".
  
#### Read in metadata 
```{r read metadata}
# read in exported files
GSfilelist = list.files(path="/Users/Anna/Documents/ResearchGit/SturgContam/rawData/Exposure_EthoExport_Complete_GS2020/GSmeanderTArelative", pattern=".txt")
  
WSfilelist = list.files(path="/Users/Anna/Documents/ResearchGit/SturgContam/rawData/Exposure_EthoExport_Complete_WS2020", pattern="Track") 
  
# read in hand-made triallist to add experimental data to movement file    
GStriallist = read.csv("//Users/Anna/Documents/ResearchGit/SturgContam/rawData/Ethovision Trial List GS2020 Exposure.csv")
    GStriallist$index = paste(GStriallist$Trial, GStriallist$Arena, sep="-")
    
WStriallist = read.csv("/Users/Anna/Documents/ResearchGit/SturgContam/rawData/Ethovision Trial List WS2020 Exposure.csv")
    WStriallist$index = paste(WStriallist$Trial, WStriallist$Arena, sep="-")
```

#### Read in data
```{r read data}
# prep column names for datafiles (buried in .txt header)
    datcolNames = c("TrialTime_s","RecTime_s","Xcent_mm","Ycent_mm",
                    "Area_mm2","AreaChange_mm2","Elong","DistMoved_mm","Vel_mms",
                    "InZoneB","InZoneC","Meander_degmin","TurnAngle_deg","ActivPerc",
                    "ActivState","X", "X1")



# set directory where .txt files are for each species
    GSdatadir = "/Users/Anna/Documents/ResearchGit/SturgContam/rawData/Exposure_EthoExport_Complete_GS2020/GSmeanderTArelative/"
    WSdatadir = "/Users/Anna/Documents/ResearchGit/SturgContam/rawData/Exposure_EthoExport_Complete_WS2020/"
  
 
# function to read and ammend ethovision files to compile later     
    readTrialDat.func =function(datadir, triallist, x) {
      trialidat = read.csv(paste0(datadir, x), sep=",", skip=40, header=F, fileEncoding="UTF-16")
      names(trialidat) = datcolNames
      trialidat$X <-NULL
      trialidat$X1 <-NULL
      
      # add relevant information from filename: 
      #   trial number (1-32) and container/well within  trial (A1 to B3)
      subfilei.pre = regmatches(x, regexpr("[0-9].*[0-9]", x))
      subfilei = unlist(strsplit(subfilei.pre, "-Subject 1"))
      
      trialidat$index = subfilei
      
      # pair file name index (above) with trial list index to assign treatments (conc and hour) to individual fish/trials
      
      trialidat2 = merge(trialidat, triallist, by="index", all.x=T)
      
      print(subfilei) # check point to make sure it's working correctly; can comment out if it is
      return(trialidat2) 
    }
    
    
# do.call function to use above function to read and then rbind all the trial datafiles into one df per species    
  GSdata = do.call(rbind, lapply(GSfilelist, readTrialDat.func, datadir = GSdatadir, triallist= GStriallist) )
    
  WSdata = do.call(rbind, lapply(WSfilelist, readTrialDat.func, datadir = WSdatadir, triallist= WStriallist) )
  
  # Tried to merge these datafiles here, but the result is too large to work with; will combined after reduce through summarizing by time (into intervals of 0.2 seconds)
  #fulldat = rbind(GSdata, WSdata)  
  # nrows = 9,953,850
    
```

#### as I reviewed the data I found a few more edits I hadn't made in ethovision; corrected here 
```{r corrections}
# movement distance too high and brief to be reasonable
GSdata = subset(GSdata, !(index=="6-B1" & TrialTime_s>104.801 & TrialTime_s<104.870))

# Also explored some issues with camera recordings for white sturgeon (batteries died a couple times)
summarize(group_by(WSdata, Trial, Replicate, ExposureHrs, Treatment), max(TrialTime_s, na.rm=T))
 ## Trial 5 (rep4, 24hrs) only recorded for <6 minutes (343 s) 
##  *Will remove entire trial in next chunk

 ## Trial 21 (rel3, 24hrs) only recorded until 15 minutes (903s)
 ## Trial 22 (rep3, 48hrs) only recorded until 15 minutes (925s)
##  *Will cut data for analysis down to 3-15 minutes (12 minutes of footage) after summarizing and combining datasets in next chunk

```

#### summarize the data into larger time-chunks to facilitate analysis and visualization (the large dataset doesn't move particularly fast...). Recorded with 30 positions per second, summarized those to 5 positions per second (each trial thus created 6000 positions over 20 minutes, if all data were collected).    

#### Also add datacolumn for distanced moved where NA is replaced with 0 

```{r cut data}
GSdatasub = GSdata[,c("index","Trial","Arena","Replicate","ExposureHrs","Treatment","Spp","Contaminant","TrialTime_s","Xcent_mm","Ycent_mm","DistMoved_mm","Vel_mms","Meander_degmin","TurnAngle_deg","InZoneB","InZoneC"),]

GSdatasub$DistMoved_mm.NA0 = GSdatasub$DistMoved_mm
 GSdatasub$DistMoved_mm.NA0[is.na(GSdatasub$DistMoved_mm)] <- 0


GSdatasub$cut = cut_width(GSdatasub$TrialTime_s, 0.2, boundary=0, labels=F)

GSdatasum = GSdatasub %>%
  group_by(index, Trial, Arena, Replicate, ExposureHrs, Treatment, Spp, Contaminant, cut) %>%
  summarize(TrialTime = round(mean(TrialTime_s),1),
            Xcent = mean(Xcent_mm, na.rm=T),
            Ycent = mean(Ycent_mm, na.rm=T),
            MnDistMoved = mean(DistMoved_mm, na.rm=T),
            MnDistMoved.NA0 = mean(DistMoved_mm.NA0, na.rm=T),
            SumDistMoved = sum(DistMoved_mm, na.rm=T),
            MnVel = mean(Vel_mms, na.rm=T),
            Meander = mean(Meander_degmin, na.rm=T),
            TurnAngle = mean(TurnAngle_deg, na.rm=T),
            InZoneB = max(InZoneB), 
            InZoneC = max(InZoneC) ) %>%
  ungroup() %>%
  data.frame()



WSdatasub = WSdata[,c("index","Trial","Arena","Replicate","ExposureHrs","Treatment","Spp","Contaminant","TrialTime_s","Xcent_mm","Ycent_mm","DistMoved_mm","Vel_mms","Meander_degmin","TurnAngle_deg","InZoneB","InZoneC"),]#,"ActivPerc","ActivState"),] # active removed because it's defined as the % of pixels moving in a dish at each time step. But with GS most of the movement was refletions not fish,so this isn't a useful netric this year. 
WSdatasub$DistMoved_mm.NA0 = WSdatasub$DistMoved_mm
 WSdatasub$DistMoved_mm.NA0[is.na(WSdatasub$DistMoved_mm)] <- 0

WSdatasub$cut = cut_width(WSdatasub$TrialTime_s, 0.2, boundary=0, labels=F)

WSdatasum = WSdatasub %>%
  group_by(index, Trial, Arena, Replicate, ExposureHrs, Treatment, Spp, Contaminant, cut) %>%
  summarize(TrialTime = round(mean(TrialTime_s),1),
            Xcent = mean(Xcent_mm, na.rm=T),
            Ycent = mean(Ycent_mm, na.rm=T),
            MnDistMoved = mean(DistMoved_mm, na.rm=T),
            MnDistMoved.NA0 = mean(DistMoved_mm.NA0, na.rm=T),
            SumDistMoved = sum(DistMoved_mm, na.rm=T),
            MnVel = mean(Vel_mms, na.rm=T),
            Meander = mean(Meander_degmin, na.rm=T),
            TurnAngle = mean(TurnAngle_deg, na.rm=T),
            InZoneB = max(InZoneB), 
            InZoneC = max(InZoneC) ) %>%
  ungroup() %>%
  data.frame()
```

#### combine WS and GS data
```{r comb data}
DataSum = rbind(GSdatasum, WSdatasum)
 DataSum$Trial = factor(DataSum$Trial) 
 DataSum$Replicate = factor(DataSum$Replicate) 
 DataSum$RepID = as.factor(paste0(DataSum$Treatment, "-", DataSum$Spp, "-", DataSum$Replicate))
 
 DataSum$uniqueID = paste(DataSum$Spp, DataSum$Treatment, DataSum$ExposureHrs, DataSum$Replicate, sep="-") 
```

```{r reduce dataset further} 
# remove WS trial #5 (only 300 sec of data)
 
DataSum = DataSum[!(DataSum$Spp=="WS" & DataSum$Trial==5),] 
 
# reduce range of data to analyze; 3min of acclimation, 12 min of trial (180 - 900 s, should have 3600 data points per fish per trial)
 
DataSumcut15 = DataSum[DataSum$TrialTime<(15*60),]

# even smaller dataset to plot only the exposure hours that are comparable among the two species
DataSum2496nom = DataSumcut15[DataSumcut15$ExposureHrs %in% c(24,96),]

# add unique line id to this reduced dataset
DataSum2496nom$lineID = 1:nrow(DataSum2496nom)

```


#### add measured concentrations (versus nominal)
```{r chem analysis results}
chemcsv = read.csv("//Users/Anna/Documents/ResearchGit/SturgContam/rawData/ChemAnalysis_Bifenthrin_20200725_Summary.csv")
 chemcsv <- chemcsv %>% select(spp, nomconc, calcConc)
 
DataSum2496 <- merge(DataSum2496nom, chemcsv, by.x=c("Spp","Treatment"), by.y=c("spp","nomconc"), all.x=T)
```


#### Evaluate for proper acclimation time - Distance
```{r distance acclim test}

acclimdat = DataSum2496

 acclimdat$acclim_window = cut(acclimdat$TrialTime, breaks=c(0,seq(120,840,120)), labels = seq(120,840,120) )


 tot_acclimdist = acclimdat[!is.na(acclimdat$acclim_window),] %>%
  group_by(ExposureHrs, Treatment, Spp, RepID, acclim_window) %>%
  summarize(TotalfishDist = sum(SumDistMoved, na.rm=T)) %>%
  ungroup()  %>%
  data.frame()

acclimplot = ggplot(tot_acclimdist, aes(x=factor(acclim_window), y=TotalfishDist)) + geom_boxplot(aes(fill = factor(acclim_window)), alpha=.4 ) + 
  scale_fill_manual(values=c("yellow", rep("white",6)))

acclimplot

acclimplot + facet_wrap(~Spp)

acclimplot + facet_wrap(~Treatment)

acclimplot + facet_wrap(~ExposureHrs)


```
### there may be a very slight reduction in distance  moved in the 1st three minutes, but no behavioaral signal after that. Set acclimation time to 3 min.

#### Evaluate for proper acclimation time - Velocity
```{r velocity acclim test}

 tot_acclimvel = acclimdat[!is.na(acclimdat$acclim_window),] %>%
  group_by(ExposureHrs, Treatment, Spp, RepID, acclim_window) %>%
  summarize(MnmnVel = mean(MnVel, na.rm=T)) %>%
  ungroup()  %>%
  data.frame()

acclimplot.vel = ggplot(tot_acclimvel, aes(x=factor(acclim_window), y=MnmnVel)) + geom_boxplot(aes(fill = factor(acclim_window)), alpha=.4 ) + 
  scale_fill_manual(values=c("yellow", rep("white",6)))

acclimplot.vel

acclimplot.vel + facet_wrap(~Spp)

acclimplot.vel + facet_wrap(~Treatment)

acclimplot.vel + facet_wrap(~ExposureHrs)

```
### there may be a very slight increase in swimming velocity in the 1st two minutes, but no acclimation signal after that. Set acclimation time to 3 min.

#### Evaluate for proper acclimation time - Meander
```{r meander acclim test}

 tot_acclimmeander = acclimdat[!is.na(acclimdat$acclim_window),] %>%
  group_by(ExposureHrs, Treatment, Spp, RepID, acclim_window) %>%
  summarize(MnMeander = mean(Meander, na.rm=T)) %>%
  ungroup()  %>%
  data.frame()

acclimplot.meand = ggplot(tot_acclimmeander, aes(x=factor(acclim_window), y=MnMeander)) + geom_boxplot(aes(fill = factor(acclim_window)), alpha=.4 ) + 
  scale_fill_manual(values=c("yellow", rep("white",6)))

acclimplot.meand

acclimplot.meand + facet_wrap(~Spp)

acclimplot.meand + facet_wrap(~Treatment)

acclimplot.meand + facet_wrap(~ExposureHrs)

```
### generally less meander in first two minutes, but no acclimation signal after that. Set acclimation time to 3 min.


#### Evaluate for proper acclimation time - InZoneC
```{r inzone acclim test}
data.frame(table(acclimdat$InZoneC))

 tot_acclimzone = acclimdat %>%
  filter(!is.na(acclim_window)) %>%
  filter(!is.na(InZoneC)) %>% 
  group_by(ExposureHrs, Treatment, Spp, RepID, acclim_window) %>%
  summarize(NinZone = sum(InZoneC==1), NoutZone = sum(InZoneC==0)) %>%
  mutate(PercZoneC = NinZone / (NinZone+NoutZone)) %>%
  ungroup()  %>%
  data.frame()

acclimplot.zone = ggplot(tot_acclimzone, aes(x=factor(acclim_window), y=PercZoneC)) + geom_boxplot(aes(fill = factor(acclim_window)), alpha=.4 ) + 
  scale_fill_manual(values=c("yellow", rep("white",6)))

acclimplot.zone

acclimplot.zone + facet_wrap(~Spp)

acclimplot.zone + facet_wrap(~Treatment)

acclimplot.zone + facet_wrap(~ExposureHrs)

```
### No clear indication of acclimation differences; Set acclimation time to 3 min.



#### Evaluate for proper acclimation time - activity
```{r activity acclim test}

#considered to be active when sum of distance traveled in 1/6 of a second is > .2 (I think this was a setting in the ethovision filter...should check notebook again)

 tot_acclimactiv = acclimdat %>%
  filter(!is.na(acclim_window)) %>%
  group_by(ExposureHrs, Treatment, Spp, RepID, acclim_window) %>%
  summarize(Active = sum(SumDistMoved>=0.2), Still = sum(SumDistMoved<0.2)) %>%
  mutate(PercActive = Active / (Active+Still)) %>%
  ungroup()  %>%
  data.frame()

acclimplot.zone = ggplot(tot_acclimactiv, aes(x=factor(acclim_window), y=PercActive)) + geom_boxplot(aes(fill = factor(acclim_window)), alpha=.4 ) + 
  scale_fill_manual(values=c("yellow", rep("white",6)))

acclimplot.zone

acclimplot.zone + facet_wrap(~Spp)

acclimplot.zone + facet_wrap(~Treatment)

acclimplot.zone + facet_wrap(~ExposureHrs)

```
### There is a general drop in activity for GS in the first two minutes, but no behavioaral signal after that. Set acclimation time to 3 min.

```{r remove acclim time} 

DataSum2496 = DataSum2496[DataSum2496$TrialTime>(3*60),]

```


#### write out cleaned dataframe for use in subsequent codes
```{r write out data, echo=FALSE, eval=FALSE}
getwd()
write.csv(DataSum2496, "outputData/Exposure_Outputdata/Bifenthrin_2020_Cleaned_FullData.csv", row.names=F)
```
























Old Code:

Insert ~ ln200

#### interpolate missing datapoints - testing testing fail
```{r interpolate attempt1, eval=FALSE, include=FALSE}
# about 6% of the timepoints in the reduced dataset are missing data at the MnDistMoved column (41,006 out of 669,600 total) because of removed data points in filtering
# of those the vast majority are GS (40173 of 41006) because of the poorer recording conditions

# here I remove all rows without X and Y centroids, and use my own function to calculate distance moved between the summarized centroids. I can't use this abbreviated dataset 

DataSum2496nom_dist = DataSum2496nom %>%
  group_by(uniqueID) %>%
  subset(!is.na(MnDistMoved)) %>%
  mutate(SumDistMoved.Abbrev = distmov(x1=lag(Xcent), x2=Xcent, y1=lag(Ycent), y2=Ycent) ) %>%
  ungroup() %>%
  data.frame()
           
# merge it back into the interpolated data 
DS = merge(DataSum2496nom, DataSum2496nom_dist[, c("lineID","SumDistMoved.Abbrev")], by="lineID", all.x=T)



# look at point differences when use these two methods; does it vary by species, treatment, or time?
ggplot(DS, aes(x=factor(Treatment), y=(SumDistMoved - SumDistMoved.Abbrev) ) ) + 
         geom_point() + geom_hline(yintercept=0, col="steelblue3") + 
         facet_grid(ExposureHrs~Spp) + 
         ylab("Difference in Distance Moved\nCalculated at 30fps vs 4fps centroids") + 
         theme_bw()
# removed 41,192 rows without data

# A negative number indicates that the distance calculated from 5fps centroids is greater than the distance calculated from 30fps. This makes sense because if there is a missing point between two detections, the distance between those detections isn't included in the total estimate of distance by ethovision but with my code it is included and assumed to be a straight line (underestimate). Additionall;y, with this code any erroneous points that weren't filtered out successfully (likely because they didn't cause a distance to be recorded in the ethovision track, but the points were still present), the erroneous points are included in the interpolation and additional ines are drawn from the fish tothe cross-dish reflection and back. Argh. However, sometimes the 5fps is smaller than 30 fps (positive point) because there was tortuosity in the path that was eliminated during abbreviation/summarization step going from 20-5fps. 

# it seems as though the difference is larger for GS, which makes sense if it's linked to poor detections, extra manual filtering, and both missing and erroneous points. 


# look at differences in total distance for each trial 
DS.totaldist = DS %>%
  group_by(Spp, Treatment, ExposureHrs, Replicate, Arena) %>%
  summarize(total.dist.30fps = sum(SumDistMoved, na.rm=T), 
            total.dist.5fps = sum(SumDistMoved.Abbrev, na.rm=T)) %>%
  data.frame()

ggplot(subset(DS.totaldist, Spp=="GS"), aes(x=Replicate, y=total.dist.30fps)) + 
  geom_point(pch=16, color="green3") + geom_point(aes(y=total.dist.5fps), pch=16, color="steelblue3") +
  facet_grid(ExposureHrs ~ Treatment)

ggplot(subset(DS.totaldist, Spp=="WS"), aes(x=Replicate, y=total.dist.30fps)) + 
  geom_point(pch=17, color="green3") + geom_point(aes(y=total.dist.5fps), pch=16, color="steelblue3") +
  facet_grid(ExposureHrs ~ Treatment)

# 30fps is always longer total distance than 5fps but the trends seem consistent and there doesn't seem to be an obvious visual bias by treatment

DS.distsd = DS.totaldist %>%
  group_by(Spp, Treatment, ExposureHrs) %>%
  summarize(sd.30fps = sd(total.dist.30fps, na.rm=T), 
          sd.5fps = sd(total.dist.5fps, na.rm=T)) %>%
  ungroup() %>%
  data.frame()

ggplot(DS.distsd, aes(x=factor(Treatment), y=sd.30fps)) + 
  geom_point(pch=17, color="green3") + geom_point(aes(y=sd.5fps), pch=16, color="steelblue3") +
  facet_grid(Spp ~ ExposureHrs) 
# variance among trials is simliar for GS but slightly lower at 5fps, but for WS the trend isn't as clear. At 24hrs, the variance is higher with 5fps uexcept for the 2000 exposure, and at 96hrs its all over the board, but generally the 30fps is higher (100, 1000, 2000), but sometimes lower (1000) and sometimes the same (0, 5).  

```

```{r interpolation notes only, eval=FALSE, include=FALSE}

## To summarize (8/18/2021) I've attempted to explore the usefulness of calculating distance moved from the 30fps dataset in ethovision, or calculating distance moved from the 5fps dataset after it has been condensed/sumarized. In the step for re-calculating distance after the fact, I've also used all sequential locations and assumed linear paths between them, even when there were substantial temporal gaps between detections. The results from this do not lead in a clear direction for continued analysis. The options are:   
#1) use Ethovision's estimated distance, and de-facto assume the fish is still when the track is lost (often true but not always)  
#2) use distances calculated here, at 5 fps, but this feels unsatisfying because it is clear that this does lose some tortuosity (unclear whether that is real or erronious, but if we're trusting the software and post-processing then we must assume it's largely real).  Also, upon a second review of the editing process, there were occational erroneous points left in as long as they didn't create long-distance movements. So with the ethovision distance estimate, erroneous points should not have a large effect. However, if I interpolate between all existing points then I'll be adding these long-distance erroneous movement to/from the reflection point BACK into the distance estimate. This is not correct, and likely more of a problem then the assumption that missing data = stationary fish. So this choice isn't preferable. 
#3) re-jigger this code to calculate post-hoc distance moved for 30fps but for all sequential detections. This seems the most satisfying because it won't lose the tortuosity of the track but it will allow us to estimate an distance moved when the software loses a moving fish (if it is stationary it will also account for that). However, again, there is the3 issue with the poor detection/reflection and the limited editing. I think the editing is fine for if I use the ethovision distances, but maybe problematic if I interpolate. 

#- so after all this days work, I think perhaps we go with the data we have, fill in the zeros for moving/not moving, fill in the zone ID for the last known location, and start the analysis. 
#- Analysis will include four output variables for effects of treatment and time for each species: distance = activity index; % time active = activity index; turning or meander = directionality (body control?), center zone = thigmotaxis and boldness). Two four-panel plots to show results (raw and predicted? just raw?). 
```
