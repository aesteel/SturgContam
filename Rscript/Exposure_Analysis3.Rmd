---
title: "Exposure_Analysis3 - Model Selection"
author: "Anna Steel"
date: "9/3/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(readtext) # need this because the ethovision output .txt files have unusual encoding as UTF-16
library(lme4)
library(rethinking)
library(rprojroot) # only used for find_rstudio_root_file() to set project wd as root
library(patchwork)
library(circular)

knitr::opts_knit$set(root.dir = find_rstudio_root_file()) # sets root directory to match project directory, not rmd file location
```

```{r utility functions, include=FALSE}
# calculate hypotenuse of triangle created by two xy locations

distmov = function(x1,x2,y1,y2) { dm = sqrt((x1-x2)^2 + (y1-y2)^2); return(dm)}

# calculate number steps between detections; use summarized dataset (5 pos/sec)
nstep = function(t2,t1, interv=0.2) {
  if (t2-t1 < 0) stop('time steps backwards?')
  nstep <- ( (t2-t1) / interv)
  return(nstep)
  }

```


## Read in Cleaned Data ("Exposure_Analysis1.Rmd")
```{r read in clean data}
DataSum2496.raw = read.csv("outputData/Exposure_Outputdata/Bifenthrin_2020_Cleaned_FullData.csv")
```




# Statistical Models, predictions, and other posterior queries for each metric (Total distance travelled, Mean velocity, Meander and Turn angle, Use of center zone (% time), Time Active, Full Rotations vs distance traveled) 


## Distance Models #####
```{r distance data, echo=F}

## Summarize to take total distance (sum moved in a trial) for each fish replicates
DataSum2496.dist = DataSum2496.raw %>%
  group_by(index, Trial, Arena, Replicate, ExposureHrs, Treatment, calcConc, Spp, RepID) %>%
  summarize(TotalfishDist_m = sum(SumDistMoved, na.rm=T)/(10*100)) %>%
  ungroup()  %>%
  
  mutate(lnCalcConc = log(calcConc+1)) %>%
  mutate(lnCalcConcC= scale(lnCalcConc, scale=FALSE)) %>%
  mutate(lnCalcConcC2 = lnCalcConcC^2 ) %>% 
   # order of transformations matters (log then scale then square)

  mutate(ExposureHrsC = scale(ExposureHrs, scale=FALSE)) %>%
  data.frame()

MeanDist0 = DataSum2496.dist %>%
  subset(Treatment==0) %>%
  group_by(Spp, ExposureHrs) %>%
  summarize(mean0_dist = mean(TotalfishDist_m)) %>%
  ungroup()  %>%
  # mutate(lnCalcConcC= scale(lnCalcConc, scale=FALSE)) %>%
  # mutate(lnCalcConcC2 = lnCalcConcC^2) %>%
  data.frame()

DataSumDiff.dist = merge(DataSum2496.dist, MeanDist0, all.x=T)
DataSumDiff.dist$DistDiff = DataSumDiff.dist$TotalfishDist_m - DataSumDiff.dist$mean0_dist


```


```{r distance multi-level Bayesmodels selection, echo=F, eval=F}
# try setting up the linear model in a bayesian form, same as frequentist model above

DSdist_bmoddat = DataSum2496.dist[,c("TotalfishDist_m","lnCalcConcC","lnCalcConcC2",
                                     "ExposureHrs","Spp","RepID")]
#DSdist_bmoddat$TotalfishDistcm = DSdist_bmoddat$TotalfishDist/10
DSdist_bmoddat$lnCalcConcC = as.numeric(DSdist_bmoddat$lnCalcConcC) 
DSdist_bmoddat$lnCalcConcC2 = as.numeric(DSdist_bmoddat$lnCalcConcC2) 
DSdist_bmoddat$SppDummy <- ifelse(DSdist_bmoddat$Spp=="GS", 0,1)
DSdist_bmoddat$ExposeDummy <- ifelse(DSdist_bmoddat$ExposureHrs=="24", 0,1)

# remove fish with only one timepoint of detection, because cant add random slope with one timepoint
DSdist_bmoddat = DSdist_bmoddat[!(DSdist_bmoddat$RepID %in% paste0(c(0,5,100,500,1000,2000), "-WS-4")),]
DSdist_bmoddat$RepID = as.factor(as.character(DSdist_bmoddat$RepID))

distspp.blm_int1.rise = map2stan(
  alist(
    TotalfishDist_m ~ dnorm(mu, sigma),
      mu  <- a_fish[RepID] + 
             be_fish[RepID]*ExposeDummy + 
              bs*SppDummy + 
              bt*(lnCalcConcC) + bt2*(lnCalcConcC2) + 
              bts1*(SppDummy)*(lnCalcConcC) + bts2*(SppDummy)*(lnCalcConcC2),
        # Wrong way of extending a random intercept; doesn't include correlation between slope and intercept for the same individual
        # a_fish[RepID] ~ dnorm(a,a_sig),
        #   a ~ dcauchy(0,10),
        #   a_sig ~ dcauchy(0,10),
        # be_fish[RepID] ~ dnorm(be,be_sig),
        #   be ~ dcauchy(0,10),
        #   be_sig ~ dcauchy(0,10),
        # Right way, because includes correlation by individual
           c(a_fish,be_fish)[RepID] ~ dmvnorm2(Mu=c(a,be), sigma=sigma_fish, Rho=Rho),
           a ~ dnorm(0,10),
           be ~ dnorm(0,10),
           sigma_fish ~ dcauchy(0,10),
           Rho ~ dlkjcorr(2),
             # not as flat as (1) but biases against strong correlations of intercept and slope
        bt ~ dnorm(0,10),
        bt2 ~ dnorm(0,10),
        bs ~ dnorm(0,10),
        bts1 ~ dnorm(0,10),
        bts2 ~ dnorm(0,10),
    sigma ~ dcauchy(0,10)
    ) ,
  data = DSdist_bmoddat, iter = 2000, warmup = 500, chains = 4)



distspp.blm_int2.rise = map2stan(
  alist(
    TotalfishDist_m ~ dnorm(mu, sigma),
    mu  <- a_fish[RepID] +
           be_fish[RepID]*ExposeDummy +
             bs*SppDummy +
             bt*(lnCalcConcC) + bt2*(lnCalcConcC2) +
             bse*(SppDummy)*(ExposeDummy) +
             bts1*(SppDummy)*(lnCalcConcC) + bts2*(SppDummy)*(lnCalcConcC2) +
             bte1*(ExposeDummy)*(lnCalcConcC) + bte2*(ExposeDummy)*(lnCalcConcC2),
         # does the interaction also need to have the random effect? I hope not =/
           c(a_fish,be_fish)[RepID] ~ dmvnorm2(Mu = c(a,be), sigma=sigma_fish, Rho=Rho), 
           a ~ dnorm(0,10),
           be ~ dnorm(0,10),
           sigma_fish ~ dcauchy(0,10),
           Rho ~ dlkjcorr(2),
             # not as flat as (1) but biases against strong correlations of intercept and slope
        bt ~ dnorm(0,10),
        bt2 ~ dnorm(0,10),
        bs ~ dnorm(0,10),
        bse ~ dnorm(0,10),
        bts1 ~ dnorm(0,10),
        bts2 ~ dnorm(0,10),
        bte1 ~ dnorm(0,10),
        bte2 ~ dnorm(0,10),
    sigma ~ dcauchy(0,10)
    ) ,
  data = DSdist_bmoddat, iter = 4000, warmup = 1000, chains = 4)



# same parameters as the center zone model, with bse added; more intuitive to me...lets each of the four categorical groups have a unique slope and curvature for the effect of treatment
distspp.blm_int3.rise = map2stan( # the true 'full' model as far as I can figure
  alist(
    TotalfishDist_m ~ dnorm(mu, sigma),
    mu  <- a_fish[RepID] +
           be_fish[RepID]*ExposeDummy +
             bs*SppDummy +
             bt*(lnCalcConcC) + 
             bse*(SppDummy)*(ExposeDummy) +
             bte*(lnCalcConcC)*(ExposeDummy) +
             bts*(lnCalcConcC)*(SppDummy) + 
             bt2*(lnCalcConcC2) +
             bt2e*(lnCalcConcC2)*(ExposeDummy)+
             bt2s*(lnCalcConcC2)*(SppDummy),

           c(a_fish,be_fish)[RepID] ~ dmvnorm2(c(a, be),sigma_fish, Rho),# 
           a ~ dnorm(4,10), # approximate mean of base case (GS-24hr)
           be ~ dnorm(0,10),
           sigma_fish ~ dcauchy(0,2),
           Rho ~ dlkjcorr(2),
    
        bs ~ dnorm(0,10),
        bt ~ dnorm(0,10),
        bte ~ dnorm(0,10),
        bse ~ dnorm(0,10),
        bts ~ dnorm(0,10),
        bt2 ~ dnorm(0,10),
        bt2e ~ dnorm(0,10),
        bt2s ~ dnorm(0,10),
    sigma ~ dcauchy(0,10)
    ) ,
  data = DSdist_bmoddat, iter = 4000, warmup = 1000, chains = 4)
## trace plots look fine. Not great, but definitely fine. Rhat are fine, and n_eff are fine (again, not great). large error bars on a and be (with random effects) so taht seems reasonable, and narrow errors for all the other parametes. bte, bt2e, and bt2s are near zero, bs and bt2 are large effects (relative) and bt2s is also not zero. bt and bt2 are likely no zero but small. All in all, this seems like a good model, and it runs well...still should use WAIC to compare to other options here. 

distspp.blm_int5.rise.2 = map2stan( # same as int3.rise except for the two interactions between treatmen/treatment^2 and exposure
  alist(
    TotalfishDist_m ~ dnorm(mu, sigma),
    mu  <- a_fish[RepID] + 
           be_fish[RepID]*ExposeDummy + 
             bs*SppDummy + 
             bt*(lnCalcConcC) + bt2*(lnCalcConcC2) + 
             bse*(SppDummy)*(ExposeDummy) +
             bts1*(SppDummy)*(lnCalcConcC) + bts2*(SppDummy)*(lnCalcConcC2),
           c(a_fish,be_fish)[RepID] ~ dmvnorm2(c(a, be),sigma_fish, Rho),# 
           a ~ dnorm(4,10), # approximate mean of base case (GS-24hr)
           be ~ dnorm(0,10),
           sigma_fish ~ dcauchy(0,2),
           Rho ~ dlkjcorr(2),
             # not as flat as (1) but biases against strong correlations of intercept and slope
        bt ~ dnorm(0,10),
        bt2 ~ dnorm(0,10),
        bs ~ dnorm(0,10),
        bse ~ dnorm(0,10),
        bts1 ~ dnorm(0,10),
        bts2 ~ dnorm(0,10),
    sigma ~ dcauchy(0,2)
    ) ,
  data = DSdist_bmoddat, iter = 4000, warmup = 1000, chains = 4)
# see notes below for thoughts on traceplots etc. take home = it's fine

plot(compare(distspp.blm_int5.rise.2, distspp.blm_int3.rise))
# the less complex model (without interaction between exposure time and concentration) is better; dWAIC = 9.2, weight for model int5.rise.2 is 99%. 


distspp.blm_int5.rise.2.offset = map2stan(
  alist(
    TotalfishDist_m ~ dnorm(mu, sigma),
    mu  <- a + a_fish[RepID] +
           be + be_fish[RepID]*ExposeDummy +
             bs*SppDummy +
             bt*(lnCalcConcC) + bt2*(lnCalcConcC2) +
             bse*(SppDummy)*(ExposeDummy) +
             bts1*(SppDummy)*(lnCalcConcC) + bts2*(SppDummy)*(lnCalcConcC2),
           c(a_fish,be_fish)[RepID] ~ dmvnorm2(0,sigma=sigma_fish, Rho=Rho),#
           a ~ dnorm(4,5), # approximate mean of base case (GS-24hr)
           be ~ dnorm(0,5),
           sigma_fish ~ dcauchy(0,2),
           Rho ~ dlkjcorr(2),
             # not as flat as (1) but biases against strong correlations of intercept and slope
        bt ~ dnorm(0,10),
        bt2 ~ dnorm(0,10),
        bs ~ dnorm(0,10),
        bse ~ dnorm(0,10),
        bts1 ~ dnorm(0,10),
        bts2 ~ dnorm(0,10),
    sigma ~ dcauchy(0,2)
    ) ,
  data = DSdist_bmoddat, iter = 4000, warmup = 1000, chains = 4, cores=2)



# distspp.blm_int5.rise.2.lkj3 = map2stan(
#   alist(
#     TotalfishDist_m ~ dnorm(mu, sigma),
#     mu  <- a_fish[RepID] + 
#            be_fish[RepID]*ExposeDummy + 
#            bs*SppDummy + 
#            bt*(lnCalcConcC) + bt2*(lnCalcConcC2) + 
#            bse*(SppDummy)*(ExposeDummy) +
#            bts1*(SppDummy)*(lnCalcConcC) + bts2*(SppDummy)*(lnCalcConcC2),
#         c(a_fish,be_fish)[RepID] ~ dmvnorm2(Mu=c(a,be),sigma=sigma_fish, Rho=Rho),# 
#              a ~ dnorm(4,10), # approximate mean of base case (GS-24hr)
#              be ~ dnorm(0,10),
#              sigma_fish ~ dcauchy(0,2),
#              Rho ~ dlkjcorr(3),
#         
#         bt ~ dnorm(0,10),
#         bt2 ~ dnorm(0,10),
#         bs ~ dnorm(0,10),
#         bse ~ dnorm(0,10),
#         bts1 ~ dnorm(0,10),
#         bts2 ~ dnorm(0,10),
#     sigma ~ dcauchy(0,2)
#     ) ,
#   data = DSdist_bmoddat, iter = 4000, warmup = 1000, chains = 4, cores=2)
#  
# 
# 
# distspp.blm_int5.rise.2.lkj1 = map2stan(
#   alist(
#     TotalfishDist_m ~ dnorm(mu, sigma),
#     mu  <- a_fish[RepID] + 
#            be_fish[RepID]*ExposeDummy + 
#            bs*SppDummy + 
#            bt*(lnCalcConcC) + bt2*(lnCalcConcC2) + 
#            bse*(SppDummy)*(ExposeDummy) +
#            bts1*(SppDummy)*(lnCalcConcC) + bts2*(SppDummy)*(lnCalcConcC2),
#     
#         c(a_fish,be_fish)[RepID] ~ dmvnorm2(Mu=c(a,be),sigma=sigma_fish, Rho=Rho),# 
#                  a ~ dnorm(4,10), # approximate mean of base case (GS-24hr)
#                  be ~ dnorm(0,10),
#                  sigma_fish ~ dcauchy(0,2),
#                  Rho ~ dlkjcorr(1),
#     
#         bs ~ dnorm(0,10),
#         bt ~ dnorm(0,10),
#         bt2 ~ dnorm(0,10),
#         bse ~ dnorm(0,10),
#         bts1 ~ dnorm(0,10),
#         bts2 ~ dnorm(0,10),
#     sigma ~ dcauchy(0,2)
#     ) ,
#   data = DSdist_bmoddat, iter = 4000, warmup = 1000, chains = 4, cores=2)
#  
# distspp.blm_int5.rise.NC = map2stan(
#   alist(
#     TotalfishDist_m ~ dnorm(mu, sigma),
#     mu  <- a_fish[RepID] +
#            be_fish[RepID]*ExposeDummy +
#              bs*SppDummy +
#              bse*(SppDummy)*(ExposeDummy) +
#              bt*(lnCalcConcC) + bt2*(lnCalcConcC2) +
#              bts1*(SppDummy)*(lnCalcConcC) + bts2*(SppDummy)*(lnCalcConcC2),
#          # does the interaction also need to have the random effect? I hope not =/
#            c(a_fish,be_fish)[RepID] ~ dmvnormNC(sigma=sigma_fish, Rho=Rho),#
#            #a ~ dnorm(0,10),
#            #be ~ dnorm(0,10),
#            sigma_fish ~ dcauchy(0,10),
#            Rho ~ dlkjcorr(2),
#              # not as flat as (1) but biases against strong correlations of intercept and slope
#         bt ~ dnorm(0,10),
#         bt2 ~ dnorm(0,10),
#         bs ~ dnorm(0,10),
#         bse ~ dnorm(0,10),
#         bts1 ~ dnorm(0,10),
#         bts2 ~ dnorm(0,10),
#     sigma ~ dcauchy(0,10)
#     ) ,
#   data = DSdist_bmoddat, iter = 2000, warmup = 500, chains = 4)

distspp.blm_int5.ri = map2stan(
  alist(
    TotalfishDist_m ~ dnorm(mu, sigma),
    mu  <- a_fish[RepID] + 
           bt*(lnCalcConcC) + bt2*(lnCalcConcC2) + 
           be*ExposeDummy + 
           bs*SppDummy + 
           bse*(SppDummy)*(ExposeDummy) +
           bts1*(SppDummy)*(lnCalcConcC) + bts2*(SppDummy)*(lnCalcConcC2),
             a_fish[RepID] ~ dnorm(a,a_sig),
             a ~ dcauchy(0,10),
             a_sig ~ dcauchy(0,10),
        bt ~ dnorm(0,10),
        bt2 ~ dnorm(0,10),
        be ~ dnorm(0,10),
        bs ~ dnorm(0,10),
        bse ~ dnorm(0,10),
        bts1 ~ dnorm(0,10),
        bts2 ~ dnorm(0,10),
    sigma ~ dcauchy(0,10)
    ) ,
  data = DSdist_bmoddat, iter = 2000, warmup = 500, chains = 4)


 plot(distspp.blm_int1.rise)
 plot(distspp.blm_int2.rise)
 plot(distspp.blm_int5.rise.2)
 #plot(distspp.blm_int5.rise.NC)
 plot(distspp.blm_int5.ri)
 
 precis(distspp.blm_int1.rise, prob = .95, digits=3)
 precis(distspp.blm_int2.rise, prob = .95, digits=3)
 precis(distspp.blm_int5.rise.2, prob = .95, digits=3)
 #precis(distspp.blm_int5.rise.NC, prob = .95, digits=3)
 precis(distspp.blm_int5.ri, prob = .95, digits=3)
  # compare these later two to see how removing the random slope changes the effect of Be and Bs  
  # turns out it doesn't change it much! So...

 plot(precis(distspp.blm_int1.rise, prob = .95))
 plot(precis(distspp.blm_int2.rise, prob = .95))
 plot(precis(distspp.blm_int5.rise.2, prob = .95, depth=2))
 plot(precis(distspp.blm_int5.ri, prob = .95, depth=2))

compare(distspp.blm_int1.rise, #distspp.blm_int2.rise,
        distspp.blm_int5.rise.2, distspp.blm_int5.ri)

plot(compare(distspp.blm_int1.rise, #distspp.blm_int2.rise,
             distspp.blm_int5.rise.2, distspp.blm_int5.ri))

```
### I'm guess I'm happy with model int5.rise.2, that accounts for the repeated measures of an individual across time ('distspp.blm_int5.rise.2'). The trace plots have better mixing for int5.2 than int5.NC and Zack says that there's more to parameterizing the NC approach than is covered in the rethinking book chapter. The trace plots aren't great but it seems relatively stable as I change small things, so Zack says it's probably good enough. If I really cared I could go tweek parameters more and document the changes to the estimated parameters. I tried estimating the overall interept and slope seperately, with offsets for the individual IDs, but the variance for the overall parameters was huge and largely dependant on the prior. I'm going to move on and assume the model is good enough. 


```{r distance multi-level Bayesmodels final, echo=F}

DSdist_bmoddat = DataSum2496.dist[,c("TotalfishDist_m","lnCalcConcC","lnCalcConcC2",
                                     "ExposureHrs","Spp","RepID")]
#DSdist_bmoddat$TotalfishDistcm = DSdist_bmoddat$TotalfishDist/10
DSdist_bmoddat$lnCalcConcC = as.numeric(DSdist_bmoddat$lnCalcConcC) 
DSdist_bmoddat$lnCalcConcC2 = as.numeric(DSdist_bmoddat$lnCalcConcC2) 
DSdist_bmoddat$SppDummy <- ifelse(DSdist_bmoddat$Spp=="GS", 0,1)
DSdist_bmoddat$ExposeDummy <- ifelse(DSdist_bmoddat$ExposureHrs=="24", 0,1)

# remove fish with only one timepoint of detection, because cant add random slope with one timepoint
DSdist_bmoddat = DSdist_bmoddat[!(DSdist_bmoddat$RepID %in% paste0(c(0,5,100,500,1000,2000), "-WS-4")),]
DSdist_bmoddat$RepID = as.factor(as.character(DSdist_bmoddat$RepID))

set.seed(1983)
distspp.blm_int5.rise.2 = map2stan(
  alist(
    TotalfishDist_m ~ dnorm(mu, sigma),
    mu  <- a_fish[RepID] + 
           be_fish[RepID]*ExposeDummy + 
             bs*SppDummy + 
             bt*(lnCalcConcC) + bt2*(lnCalcConcC2) + 
             bse*(SppDummy)*(ExposeDummy) +
             bts1*(SppDummy)*(lnCalcConcC) + bts2*(SppDummy)*(lnCalcConcC2),
    
           c(a_fish,be_fish)[RepID] ~ dmvnorm2(c(a, be),sigma_fish, Rho),# 
           a ~ dnorm(4,10), # approximate mean of base case (GS-24hr)
           be ~ dnorm(0,10),
           sigma_fish ~ dcauchy(0,2),
           Rho ~ dlkjcorr(2), # not as flat as (1) but biases against strong correlations of intercept and slope
        bt ~ dnorm(0,10),
        bt2 ~ dnorm(0,10),
        bs ~ dnorm(0,10),
        bse ~ dnorm(0,10),
        bts1 ~ dnorm(0,10),
        bts2 ~ dnorm(0,10),
    sigma ~ dcauchy(0,2)
    ) ,
  data = DSdist_bmoddat, iter = 4000, warmup = 1000, chains = 4)


# check model
 precis(distspp.blm_int5.rise.2, prob = .95, digits=3)
 plot(precis(distspp.blm_int5.rise.2, prob = .95))
 plot(precis(distspp.blm_int5.rise.2, prob = .95, depth=2))

 plot(distspp.blm_int5.rise.2)

```


```{r distance multi-level Bayesmodels predict, echo=F, eval=F}

# pull posterior from model:
set.seed(42)
post = extract.samples(distspp.blm_int5.rise.2)

# set up dataframe to plot posterior predictions
preddat = list(CalcConc=rep(seq(0, 2250, 2), 4), 
               lnCalcConc=log(rep(seq(0, 2250, 2),4)+1), 
               lnCalcConcC=(log(rep(seq(0, 2250, 2),4)+1)) - 
                 mean(DataSum2496.dist$lnCalcConc) ,
               lnCalcConcC2=((log(rep(seq(0, 2250, 2),4)+1)) - 
                 mean(DataSum2496.dist$lnCalcConc))^2 ,               
               ExposeDummy = rep(c(0,1), each=1126*2), 
               SppDummy = rep(rep(c(0,1),each=1126),2), 
               RepID = rep(2,4504))

# make zeros for individual random effects to predict to mean only -> model doesn't have any 'a' this way
a_fish_zeros = matrix(0,12000,90)
be_fish_zeros = matrix(0,12000,90)

# use estimated posteriors for population of individuals to simulate new fish; shapes of distributions between model posteriors and predicted posteriors are nearly identical, not what I want...but it does predict uncertainty across individuals, but might as well just take predictions for individual fish are put them in as the data...not quote grasping this
a_fish_sim = matrix(rnorm(12000*90, mean(post$a_fish), mean(post$sigma_fish[,1])),12000,90)
be_fish_sim = matrix(rnorm(12000*90, mean(post$be_fish), mean(post$sigma_fish[,2])),12000,90)

# replace individual fish estimates with global estimate; this should predict to the average individual in a population...so since I want to get at the population level response this seems more appropriate.
a_global = matrix(post$a,12000,90)
be_global = matrix(post$be,12000,90)

# use link to predict to mean only
link.int5.rise.2 <- link(distspp.blm_int5.rise.2, n=1000, data= preddat, 
                         replace = list(a_fish = a_global, 
                                        be_fish = be_global) )
#                         replace = list(a_fish = a_fish_sim, 
#                                        be_fish = be_fish_sim) )

preddat.df <- data.frame(sapply(preddat,c)) # thanks stack overflow! https://stackoverflow.com/questions/4227223/convert-a-list-to-a-data-frame

preddat.df$link_mu_mn <- apply(link.int5.rise.2, 2, mean) 
preddat.df$link_PI05 = apply(link.int5.rise.2, 2, PI, .95)[1,] 
preddat.df$link_PI95 = apply(link.int5.rise.2, 2, PI, .95)[2,] 


# # predict from posteriors (on transformed scale)
#   link_pred <- link(distspp.blm_int2.rise, data = preddat, n=1000) 
#   preddat$link_mu_mn <- apply(link_pred, 2, mean)
#   preddat$link_PI05 = apply(link_pred, 2, PI, .95)[1,]
#   preddat$link_PI95 = apply(link_pred, 2, PI, .95)[2,]
#   
#  # predict with sim; it's my understanding that this integrates the error estimates too?
#   sim_pred <- sim(distspp.blm_int2.rise, data = preddat, n=1000) 
#   preddat$sim_mu_mn <- apply(sim_pred, 2, mean)
#   preddat$sim_PI05 = apply(sim_pred, 2, PI, .95)[1,]
#   preddat$sim_PI95 = apply(sim_pred, 2, PI, .95)[2,]
#  
  # plot back-transformed data
  preddat.df$Spp <- ifelse(preddat.df$SppDummy==0,"GS","WS")
  preddat.df$ExposureHrs <- ifelse(preddat.df$ExposeDummy==0,"24","96")


DistPred_transf_plot2 = ggplot() + 
  geom_point(data=DataSum2496.dist,
             aes(x=(lnCalcConcC),                          
                 y=TotalfishDist_m, 
                 color=factor(Spp))) + 
  geom_ribbon(data = preddat.df, aes(x=(lnCalcConcC), 
              ymin=link_PI05, ymax=link_PI95), 
              alpha=.4, col="grey70")+
  geom_line(data = preddat.df, aes(x=(lnCalcConcC), y=link_mu_mn), lwd=.2)+
    facet_grid(Spp~ExposureHrs, scales="free", labeller = labeller(
      ExposureHrs = c("24"="24 Hours Exposure","96"="96 Hours Exposure"),
      Spp = c("GS" = "Green Sturgeon", "WS" = "White Sturgeon")))+
    scale_color_manual(values=c("green3", "steelblue3"), guide=FALSE)+
    ylab("Total Distance Traveled (m)") + 
    scale_x_continuous(name="Bifenthrin Concentration (ng/L)") + #, breaks = seq(-7.5,5, 2.5), labels=(seq(-7.5,5, 2.5)+3.73) ) +
    theme_bw()


DistPred_orig_plot2 = ggplot() + 
  geom_point(data=DataSum2496.dist,
             aes(x=(calcConc),                          
                 y=TotalfishDist_m, 
                 color=factor(Spp))) + 
  geom_ribbon(data = preddat.df, aes(x=(CalcConc), 
              ymin=link_PI05, ymax=link_PI95), 
              alpha=.4, col="grey70")+
  geom_line(data = preddat.df, aes(x=(CalcConc), y=link_mu_mn), lwd=.2)+
  facet_grid(Spp~ExposureHrs, scales="free", labeller = labeller(
    ExposureHrs = c("24"="24 Hours Exposure","96"="96 Hours Exposure"),
    Spp = c("GS" = "Green Sturgeon", "WS" = "White Sturgeon")))+
  scale_color_manual(values=c("green3", "steelblue3"), guide=FALSE)+
  ylab("Total Distance Traveled (cm)") + 
  scale_x_continuous(name="Bifenthrin Concentration (ng/L)") + #, breaks = seq(-7.5,5, 2.5), labels=(seq(-7.5,5, 2.5)+3.73) ) +
  theme_bw()

DistPred_transf_plot2
DistPred_orig_plot2 

```
 
 
### Distance Contrasts

### Study questions: 

###  1) is there an effect (all treatment vs control), and which metrics show an effect

###  2) does that effect change with time [96 treat vs 96 control and 24 treat vs 24 control OR individual change from 24 to 96 (all treatments) as compared to individual change for control between 24 and 96]

###  3) Does the magnitude of the effect vary between species

```{r distance multi-level model density plots, echo=F}
set.seed(1983) 
postdist = extract.samples(distspp.blm_int5.rise.2)  # maybe change to distspp.blm_int3.rise, and if so, change the model prediction parts in the following chunk and the next. Argh. 


# reference table to convert from treatment to centered, log-transformed measured concentrations
TreatCalcTable = unique(DataSum2496.dist[order(DataSum2496.dist$Treatment)
                                             ,c("Spp", "Treatment","lnCalcConc", "lnCalcConcC")])
TreatCalcTable$lnCalcConcC2 = TreatCalcTable$lnCalcConcC ^ 2



# calculate differences between control and treatment at each time point for each species (20 contrasts)
GS0bif24 = postdist$a +
  postdist$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==0)$lnCalcConcC) +
  postdist$bt2*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==0)$lnCalcConcC2)
GS5bif24 = postdist$a + 
  postdist$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==5)$lnCalcConcC) +
  postdist$bt2*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==5)$lnCalcConcC2)
GS100bif24 = postdist$a + 
  postdist$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==100)$lnCalcConcC) +
  postdist$bt2*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==100)$lnCalcConcC2)
GS500bif24 = postdist$a + 
  postdist$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==500)$lnCalcConcC) +
  postdist$bt2*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==500)$lnCalcConcC2)
GS1000bif24 = postdist$a +
  postdist$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==1000)$lnCalcConcC) + 
  postdist$bt2* as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==1000)$lnCalcConcC2)
GS2000bif24 = postdist$a + 
  postdist$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==2000)$lnCalcConcC) + 
  postdist$bt2*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==2000)$lnCalcConcC2)

mean(GS0bif24)
mean(GS5bif24)
 cont.GS_0.5bif_24 = (sum(GS0bif24<GS5bif24) / length(GS0bif24)) 
 cont.GS_0.5bif_24 #72.0% prob that 5 is more than 0
mean(GS100bif24)
 cont.GS_0.100bif_24 = (sum(GS0bif24<GS100bif24) / length(GS0bif24)) 
 cont.GS_0.100bif_24 #62.4% prob that 100 is more than 0
mean(GS500bif24)
 cont.GS_0.500bif_24 = (sum(GS0bif24<GS500bif24) / length(GS0bif24)) 
 cont.GS_0.500bif_24 #40.7% prob that 500 is more than 0
mean(GS1000bif24)
 cont.GS_0.1000bif_24 = (sum(GS0bif24<GS1000bif24) / length(GS0bif24)) 
 cont.GS_0.1000bif_24 #32.8% prob that 1000 is more than 0
mean(GS2000bif24)
 cont.GS_0.2000bif_24 = (sum(GS0bif24<GS2000bif24) / length(GS0bif24)) 
 cont.GS_0.2000bif_24 #13.7% prob that 2000 is more than 0 (86.3% chance that 2000 is less than 0)

GS24.plot = ggplot() + geom_density(aes(x=GS0bif24, color="black")) + 
  geom_density(aes(x=GS5bif24, color="green3")) + 
  geom_density(aes(x=GS100bif24, color="goldenrod")) + 
  geom_density(aes(x=GS500bif24, color="red3")) + 
  geom_density(aes(x=GS1000bif24, color="pink")) + 
  geom_density(aes(x=GS2000bif24, color="steelblue3")) + 
  scale_color_manual(name="Nominal Bifenthrin\nConcentration", 
                     values=c("black"="black", "green3"="green3", "goldenrod"="goldenrod",
                              "red3"="red3", "pink"="pink","steelblue3"="steelblue3"), 
                     labels=c("0 ng/L", "5 ng/L", "100ng/L", 
                              "500ng/L", "1000ng/L", "2000 ng/L") ) + 
  xlab("Distance moved (GS @ 24hr)")+
  theme_bw()


# repeat for green sturgeon, 96hr

GS0bif96 = postdist$a + postdist$be +
  postdist$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==0)$lnCalcConcC) +
  postdist$bt2*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==0)$lnCalcConcC2)
GS5bif96 = postdist$a + postdist$be + 
  postdist$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==5)$lnCalcConcC) +
  postdist$bt2*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==5)$lnCalcConcC2)
GS100bif96 = postdist$a + postdist$be + 
  postdist$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==100)$lnCalcConcC) +
  postdist$bt2*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==100)$lnCalcConcC2)
GS500bif96 = postdist$a + postdist$be + 
  postdist$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==500)$lnCalcConcC) +
  postdist$bt2*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==500)$lnCalcConcC2)
GS1000bif96 = postdist$a + postdist$be +
  postdist$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==1000)$lnCalcConcC) + 
  postdist$bt2* as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==1000)$lnCalcConcC2)
GS2000bif96 = postdist$a + postdist$be + 
  postdist$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==2000)$lnCalcConcC) + 
  postdist$bt2*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==2000)$lnCalcConcC2)

mean(GS0bif96)
mean(GS5bif96)
 cont.GS_0.5bif_96 = (sum(GS0bif96<GS5bif96) / length(GS0bif96)) 
 cont.GS_0.5bif_96 #72.0% prob that 5 is more than 0
mean(GS100bif96)
mean(GS500bif96)
mean(GS1000bif96)
mean(GS2000bif96)

GS96.plot = ggplot() + geom_density(aes(x=GS0bif96), color="black") + 
  geom_density(aes(x=GS5bif96), color="green3") + 
  geom_density(aes(x=GS100bif96), color="goldenrod") + 
  geom_density(aes(x=GS500bif96), color="red3") + 
  geom_density(aes(x=GS1000bif96), color="pink") + 
  geom_density(aes(x=GS2000bif96), color="steelblue3") + 
  scale_color_manual(name="Nominal Bifenthrin\nConcentration", 
                     values=c("black"="black", "green3"="green3", "goldenrod"="goldenrod",
                              "red3"="red3", "pink"="pink","steelblue3"="steelblue3"), 
                     labels=c("0 ng/L", "5 ng/L", "100ng/L", 
                              "500ng/L", "1000ng/L", "2000 ng/L") ) + 
  xlab("Distance moved (GS @ 96hr)")+
  theme_bw()


# repeat for white sturgeon, 24hr

WS0bif24 = postdist$a + postdist$bs +
  postdist$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==0)$lnCalcConcC) +
  postdist$bt2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==0)$lnCalcConcC2) +
  postdist$bts1*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==0)$lnCalcConcC) +
  postdist$bts2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==0)$lnCalcConcC2)
WS5bif24 = postdist$a + postdist$bs + 
  postdist$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==5)$lnCalcConcC) +
  postdist$bt2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==5)$lnCalcConcC2)+
  postdist$bts1*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==5)$lnCalcConcC) +
  postdist$bts2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==5)$lnCalcConcC2)
WS100bif24 = postdist$a + postdist$bs + 
  postdist$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==100)$lnCalcConcC) +
  postdist$bt2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==100)$lnCalcConcC2)+
  postdist$bts1*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==100)$lnCalcConcC) +
  postdist$bts2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==100)$lnCalcConcC2)
WS500bif24 = postdist$a + postdist$bs + 
  postdist$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==500)$lnCalcConcC) +
  postdist$bt2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==500)$lnCalcConcC2)+
  postdist$bts1*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==500)$lnCalcConcC) +
  postdist$bts2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==500)$lnCalcConcC2)
WS1000bif24 = postdist$a + postdist$bs +
  postdist$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==1000)$lnCalcConcC) + 
  postdist$bt2* as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==1000)$lnCalcConcC2)+
  postdist$bts1*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==1000)$lnCalcConcC) + 
  postdist$bts2* as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==1000)$lnCalcConcC2)
WS2000bif24 = postdist$a + postdist$bs + 
  postdist$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==2000)$lnCalcConcC) + 
  postdist$bt2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==2000)$lnCalcConcC2)+
  postdist$bts1*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==2000)$lnCalcConcC) + 
  postdist$bts2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==2000)$lnCalcConcC2)

mean(WS0bif24)
mean(WS5bif24)
 cont.WS_0.5bif_24 = (sum(WS0bif24<WS5bif24) / length(WS0bif24)) 
 cont.WS_0.5bif_24 #100% prob that 5 is more than 0
mean(WS100bif24)
 cont.WS_0.100bif_24 = (sum(WS0bif24<WS100bif24) / length(WS0bif24)) 
 cont.WS_0.100bif_24 #100% prob that 100 is more than 0
mean(WS500bif24)
 cont.WS_0.500bif_24 = (sum(WS0bif24<WS500bif24) / length(WS0bif24)) 
 cont.WS_0.500bif_24 #55% prob that 500 is more than 0
mean(WS1000bif24)
 cont.WS_0.1000bif_24 = (sum(WS0bif24<WS1000bif24) / length(WS0bif24)) 
 cont.WS_0.1000bif_24 #0% prob that 1000 is more than 0 (i.e. 100% prob that 1000 is less than 0)
mean(WS2000bif24)
 cont.WS_0.2000bif_24 = (sum(WS0bif24<WS2000bif24) / length(WS0bif24)) 
 cont.WS_0.2000bif_24 #0% prob that 2000 is more than 0 (i.e. 100% prob that 1000 is less than 0)
 
WS24.plot = ggplot() + geom_density(aes(x=WS0bif24), color="black") + 
  geom_density(aes(x=WS5bif24), color="green3") + 
  geom_density(aes(x=WS100bif24), color="goldenrod") + 
  geom_density(aes(x=WS500bif24), color="red3") + 
  geom_density(aes(x=WS1000bif24), color="pink") + 
  geom_density(aes(x=WS2000bif24), color="steelblue3") + 
  scale_color_manual(name="Nominal Bifenthrin\nConcentration", 
                     values=c("black"="black", "green3"="green3", "goldenrod"="goldenrod",
                              "red3"="red3", "pink"="pink","steelblue3"="steelblue3"), 
                     labels=c("0 ng/L", "5 ng/L", "100ng/L", 
                              "500ng/L", "1000ng/L", "2000 ng/L") ) + 
  xlab("Distance moved (WS @ 24hr)")+
  theme_bw()


# repeat for white sturgeon, 96hr


WS0bif96 = postdist$a + postdist$bs + postdist$be + post$bse + 
  postdist$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==0)$lnCalcConcC) +
  postdist$bt2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==0)$lnCalcConcC2) +
  postdist$bts1*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==0)$lnCalcConcC) +
  postdist$bts2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==0)$lnCalcConcC2)
WS5bif96 = postdist$a + postdist$bs + postdist$be + post$bse + 
  postdist$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==5)$lnCalcConcC) +
  postdist$bt2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==5)$lnCalcConcC2) +
  postdist$bts1*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==5)$lnCalcConcC) +
  postdist$bts2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==5)$lnCalcConcC2)
WS100bif96 = postdist$a + postdist$bs + postdist$be + post$bse + 
  postdist$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==100)$lnCalcConcC) +
  postdist$bt2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==100)$lnCalcConcC2) +
  postdist$bts1*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==100)$lnCalcConcC) +
  postdist$bts2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==100)$lnCalcConcC2)
WS500bif96 = postdist$a + postdist$bs + postdist$be + post$bse + 
  postdist$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==500)$lnCalcConcC) +
  postdist$bt2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==500)$lnCalcConcC2) +
  postdist$bts1*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==500)$lnCalcConcC) +
  postdist$bts2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==500)$lnCalcConcC2)
WS1000bif96 = postdist$a + postdist$bs + postdist$be + post$bse + 
  postdist$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==1000)$lnCalcConcC) + 
  postdist$bt2* as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==1000)$lnCalcConcC2) +
  postdist$bts1*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==1000)$lnCalcConcC) + 
  postdist$bts2* as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==1000)$lnCalcConcC2)
WS2000bif96 = postdist$a + postdist$bs + postdist$be + post$bse + 
  postdist$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==2000)$lnCalcConcC) + 
  postdist$bt2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==2000)$lnCalcConcC2) +
  postdist$bts1*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==2000)$lnCalcConcC) + 
  postdist$bts2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==2000)$lnCalcConcC2)

mean(WS0bif96)
mean(WS5bif96)
 cont.WS_0.5bif_96 = (sum(WS0bif96<WS5bif96) / length(WS0bif96)) 
 cont.WS_0.5bif_96 #100% prob that 5 is more than 0
mean(WS100bif96)
 cont.WS_0.100bif_96 = (sum(WS0bif96<WS100bif96) / length(WS0bif96)) 
 cont.WS_0.100bif_96 #100% prob that 100 is more than 0
mean(WS500bif96)
 cont.WS_0.500bif_96 = (sum(WS0bif96<WS500bif96) / length(WS0bif96)) 
 cont.WS_0.500bif_96 #55.0% prob that 500 is more than 0
mean(WS1000bif96)
 cont.WS_0.1000bif_96 = (sum(WS0bif96<WS1000bif96) / length(WS0bif96)) 
 cont.WS_0.1000bif_96 #0% prob that 1000 is more than 0 (i.e. 100% prob that 1000 is less than 0)
mean(WS2000bif96)
 cont.WS_0.2000bif_96 = (sum(WS0bif96<WS2000bif96) / length(WS0bif96)) 
 cont.WS_0.2000bif_96 #0% prob that 2000 is more than 0 (i.e. 100% prob that 2000 is less than 0)

WS96.plot = ggplot() + geom_density(aes(x=WS0bif96), color="black") + 
  geom_density(aes(x=WS5bif96), color="green3") + 
  geom_density(aes(x=WS100bif96), color="goldenrod") + 
  geom_density(aes(x=WS500bif96), color="red3") + 
  geom_density(aes(x=WS1000bif96), color="pink") + 
  geom_density(aes(x=WS2000bif96), color="steelblue3") + 
  scale_color_manual(name="Nominal Bifenthrin\nConcentration", 
                     values=c("black"="black", "green3"="green3", "goldenrod"="goldenrod",
                              "red3"="red3", "pink"="pink","steelblue3"="steelblue3"), 
                     labels=c("0 ng/L", "5 ng/L", "100ng/L", 
                              "500ng/L", "1000ng/L", "2000 ng/L") ) + 
  xlab("Distance moved (WS @ 96hr)")+
  theme_bw()

GS24.plot + GS96.plot + WS24.plot + WS96.plot

predgroups = list(GS0bif24, GS5bif24,GS100bif24,GS500bif24,GS1000bif24,GS2000bif24,
                  GS0bif96, GS5bif96,GS100bif96,GS500bif96,GS1000bif96,GS2000bif96,
                  WS0bif24, WS5bif24,WS100bif24,WS500bif24,WS1000bif24,WS2000bif24,
                  WS0bif96, WS5bif96,WS100bif96,WS500bif96,WS1000bif96,WS2000bif96)
PredGroupNames =  as.character(expression(GS0bif24,GS5bif24,GS100bif24,GS500bif24,
                                          GS1000bif24,GS2000bif24,
                   GS0bif96, GS5bif96,GS100bif96,GS500bif96,GS1000bif96,GS2000bif96,
                   WS0bif24, WS5bif24,WS100bif24,WS500bif24,WS1000bif24,WS2000bif24,
                   WS0bif96, WS5bif96,WS100bif96,WS500bif96,WS1000bif96,WS2000bif96))
posterior.preds = data.frame(PredGroupNames = PredGroupNames, 
                             PredMeans = sapply(predgroups, mean),
                             Pred95CIl = sapply(predgroups, quantile, 0.05),
                             Pred95CIu = sapply(predgroups, quantile, 0.95))
```
#### if use this in a paper, recolor to a more intuitive gradient and add legend
 
 
```{r distance multi-level model time and spp contrasts, echo=F}
# this uses the predicted posteriors for distance moved, calculated above

# GS vs WS
cont.GS.WS_0bif_24 = sum(GS0bif24<WS0bif24) / length(GS0bif24)
 cont.GS.WS_0bif_24 # 100% probability that GS will move less than WS

 cont.GS.WS_0bif_96 = sum(GS0bif96<WS0bif96) / length(GS0bif96)
 cont.GS.WS_0bif_96 # 100% probability that GS will move less than WS
cont.GS.WS_2000bif_96 = sum(GS2000bif96<WS2000bif96) / length(GS2000bif96)
 cont.GS.WS_2000bif_96 # 99.89% probability that GS will move less than WS


# Green Sturgeon, Exposure Hr
cont.GS0bif_96.24 = (sum(GS0bif96<GS0bif24) / length(GS0bif96)) 
# cont.GS5bif_96.24 = (sum(GS5bif96<GS5bif24) / length(GS5bif96))
# cont.GS100bif_96.24 = (sum(GS100bif96<GS100bif24) / length(GS100bif96))
# cont.GS500bif_96.24 = (sum(GS500bif96<GS500bif24) / length(GS500bif96))
# cont.GS1000bif_96.24 = (sum(GS1000bif96<GS1000bif24) / length(GS1000bif96))
# cont.GS2000bif_96.24 = (sum(GS2000bif96<GS2000bif24) / length(GS2000bif96))

cont.GS0bif_96.24
# ; cont.GS5bif_96.24; cont.GS100bif_96.24; cont.GS500bif_96.24; cont.GS1000bif_96.24; cont.GS2000bif_96.24

# ha! they're all the same, because there's no interaction of exposure time and treatment. 
 # 4.8% of the samples from the posterior showed less distance moved at 96 than 24; so most likely that movement is greater at 96 than 24 (95.2%)

GS0bif_96.24.plot = ggplot() + geom_density(aes(x=GS0bif96), color="steelblue3") + 
  geom_density(aes(x=GS0bif24), color="green3") + 
  xlab("Distance moved - GS @ 0 ng/L bifenthrin\n24 vs 96 hrs)") +
  theme_bw()
# GS5bif_96.24.plot = ggplot() + geom_density(aes(x=GS5bif96), color="steelblue3") + 
#   geom_density(aes(x=GS5bif24), color="green3") + 
#   xlab("Distance moved - GS @ 5 ng/L bifenthrin\n24 vs 96 hrs)") +
#   theme_bw()
# GS100bif_96.24.plot = ggplot() + geom_density(aes(x=GS100bif96), color="steelblue3") + 
#   geom_density(aes(x=GS100bif24), color="green3") + 
#   xlab("Distance moved - GS @ 100 ng/L bifenthrin\n24 vs 96 hrs)") +
#   theme_bw()
# GS500bif_96.24.plot = ggplot() + geom_density(aes(x=GS500bif96), color="steelblue3") + 
#   geom_density(aes(x=GS500bif24), color="green3") + 
#   xlab("Distance moved - GS @ 500 ng/L bifenthrin\n24 vs 96 hrs)") +
#   theme_bw()
# GS1000bif_96.24.plot = ggplot() + geom_density(aes(x=GS1000bif96), color="steelblue3") + 
#   geom_density(aes(x=GS1000bif24), color="green3") + 
#   xlab("Distance moved - GS @ 1000 ng/L bifenthrin\n24 vs 96 hrs)") +
#   theme_bw()
# GS2000bif_96.24.plot = ggplot() + geom_density(aes(x=GS2000bif96), color="steelblue3") + 
#   geom_density(aes(x=GS2000bif24), color="green3") + 
#   xlab("Distance moved - GS @ 2000 ng/L bifenthrin\n24 vs 96 hrs)") +
#   theme_bw()

# use patchwork grammar to plot multiple plots
GS0bif_96.24.plot
#(GS0bif_96.24.plot|GS5bif_96.24.plot|GS100bif_96.24.plot)/(GS500bif_96.24.plot|GS1000bif_96.plot|GS2000bif_96.plot)

cont.GS0bif_96.24 # 4.8% chance that GS move less at 96hrs than 24hrs (ie: move more with age)
# cont.GS5bif_96.24
# cont.GS100bif_96.24
# cont.GS500bif_96.24
# cont.GS1000bif_96.24
# cont.GS2000bif_96.24



# White Sturgeon: probability of a difference between 24 and 96 hours, at each treatment level
cont.WS0bif_96.24 = (sum(WS0bif96<WS0bif24) / length(WS0bif96)) 
cont.WS0bif_96.24
# 4.8% of the samples from the posterior showed less distance moved at 96 than 24; so most likely that movement is greater at 96 than 24 (95.2%)

WS0bif_96.24.plot = ggplot() + geom_density(aes(x=WS0bif96), color="steelblue3") + 
  geom_density(aes(x=WS0bif24), color="green3") + 
  xlab("Distance moved - WS @ 0 ng/L bifenthrin\n24 vs 96 hrs)") +
  theme_bw()
WS0bif_96.24.plot


```

#### well, these plots all look about the same, as they should since there's no interaction for concentration * exposure time; which fits the contrast value - it is 95.2% likely (for all comparisons of concentation, because there isn't an interaction) that for Green Sturgeon the distance moved at 96hrs (7ph) is greater than the distance moved at 24hrs (4 dph). But for white sturgeon, it's a 100% chance that there is less movement at 96hrs than at 24hrs exposure. 






 
     

## Velocity Models - abandoned b/c very similar pattern to distance #####
### Velocity 
```{r velocity plots, echo=F}

## Summarize movement velocity
 DataSum9696.vel = DataSum2496.raw %>%
  group_by(index, Trial, Arena, Replicate, ExposureHrs, Treatment, calcConc, Spp, RepID) %>%
  summarize(MnVel = mean(MnVel, na.rm=T), npos = n()) %>%
  ungroup()  %>%
  data.frame()
```



```{r velocity models, echo=F}
vel.lm = lm(MnVel ~ factor(Spp)+ factor(Treatment)*factor(ExposureHrs) , data = DataSum2496.vel)
velspp.lm = lm(MnVel ~ factor(Spp)*factor(Treatment)*factor(ExposureHrs) , data = DataSum2496.vel)

velspp.lmm = lmer(MnVel ~ factor(Spp)*factor(Treatment)*factor(ExposureHrs)+ (1| RepID), data = DataSum2496.vel)

 plot(velspp.lmm)
 qqnorm(resid(velspp.lmm)); qqline(resid(velspp.lmm))
 # plots look okay; the tree-way interaction makes for a better distn of residuals
 
 summary(velspp.lm) # everything is significant except for expsure hrs when modeled with log(conc)
   # effect of species is vastly stronger than anything else
   
   TukeyHSD(aov(velspp.lm))[[4]]
    # for WS, 2000 vs all other treatments are sig diff, and only one other (1000-100)
    # for GS, no GS-GS concentrations were significantly different in this model
   
   TukeyHSD(aov(velspp.lm))[[5]]
    # Ws-GS different at 24 and 69 hours, and WS-WS / GS-GS different at 24 & 96 hours; should do custom contrasts to publish because this is making all possible contrasts. Acutally, should fit in baysian model to publish and compare poterior predicted distribitions to compare. 
  
   TukeyHSD(aov(velspp.lm))[[6]]
    ## if use the three-way interaction model, identify custom contrasts of interest. Thus applies to frequentist of bayesian analysis

```





## Meander Models  #####
```{r meander data, echo=F}
## Add transformations of concentrations, exposure hours, and meander
 
DataSum2496 <- DataSum2496.raw %>%
  mutate(MeanderCircLog = log(abs(MeanderCirc)+1)) %>%
  mutate(lnCalcConc = log(calcConc+1)) %>%
  mutate(lnCalcConcC= as.numeric(scale(lnCalcConc, scale=FALSE))) %>%
  mutate(lnCalcConcC2 = lnCalcConcC ^ 2 ) %>% 
   # order of transformations matters (log then scale then square)
  data.frame()

## Summarize meander and turn angle

## Summarize meander and turn angle
DataSum2496.meand = DataSum2496 %>%
  group_by(index, Trial, Arena, Replicate, ExposureHrs, Treatment, 
           calcConc, lnCalcConc, lnCalcConcC, lnCalcConcC2, Spp, RepID) %>%
  summarize(MnTurnAngle = deg(circ.mean.na(rad(TurnAngleCirc))), 
            VarTurnAngle = deg(circ.disp.na(rad(TurnAngleCirc))$var), # circular variance
            MnMeander = mean(MeanderCirc, na.rm=T),
            SDMeander = sd(MeanderCirc, na.rm=T))  %>%
  ungroup()  %>%
  data.frame()

#keep raw data but remove missing points
#DataSum2496.mraw = DataSum2496[!is.na(DataSum2496$TurnAngle_deg),]
# MeanMeand0 = DataSum2496.meand %>%
#   subset(Treatment==0) %>%
#   group_by(Spp, ExposureHrs) %>%
#   summarize(mean0_meand = mean(MnMeander)) %>%
#   ungroup()  %>%
#   data.frame()
# 
# DataSumDiff.meand = merge(DataSum2496.meand, MeanMeand0, all.x=T)
# DataSumDiff.meand$DistDiff = DataSumDiff.meand$MnMeander - DataSumDiff.meand$mean0_meand


```


```{r meander single-level Bayesmodels selection, echo=F, eval=F}
# try setting up the linear model in a bayesian form, same as frequentist model above
# use all meander data points, not summarized data
DSmeand_bmoddat = DataSum2496.meand[,c("SDMeander","calcConc","lnCalcConcC","lnCalcConcC2","ExposureHrs","Spp","RepID")]
DSmeand_bmoddat = DSmeand_bmoddat[!is.na(DSmeand_bmoddat$SDMeander),] # drops 26.1% of the data points when using full dataset; none if using summarized dataset 

DSmeand_bmoddat$lnCalcConcC = as.numeric(DSmeand_bmoddat$lnCalcConcC) 
DSmeand_bmoddat$lnCalcConcC2 = as.numeric(DSmeand_bmoddat$lnCalcConcC2) 
DSmeand_bmoddat$SppDummy <- as.numeric(ifelse(DSmeand_bmoddat$Spp=="GS", 0,1))
DSmeand_bmoddat$ExposeDummy <- as.numeric(ifelse(DSmeand_bmoddat$ExposureHrs=="24", 0,1))
#DSmeand_bmoddat$MeanderCircLog = as.numeric(DSmeand_bmoddat$MeanderCircLog) 

# remove fish with only one timepoint of detection, because cant add random slope with one timepoint
DSmeand_bmoddat = DSmeand_bmoddat[!(DSmeand_bmoddat$RepID %in% paste0(c(0,5,100,500,1000,2000), "-WS-4")),]
DSmeand_bmoddat$RepID = as.factor(as.character(DSmeand_bmoddat$RepID))

# let treatment effect and curve vary by species and exposure, and let exposure effect vary by species (all interactions, no multilevel)
set.seed(1983)
meandspp.blm_1 = map2stan(
  alist(
    SDMeander ~ dnorm(mu, sigma), 
      mu  <-  a + 
              be*ExposeDummy + 
              bs*SppDummy + 
              bse*(SppDummy)*(ExposeDummy) +
              bt*(lnCalcConcC) +
              bte*(ExposeDummy)*(lnCalcConcC) +
              bts*(SppDummy)*(lnCalcConcC) +
              bt2*(lnCalcConcC2) +
              bt2e*(ExposeDummy)*(lnCalcConcC2) +
              bt2s*(SppDummy)*(lnCalcConcC2) ,
        a ~ dnorm(0,10),
        be ~ dnorm(0,10),
        bs ~ dnorm(0,10),
        bse ~ dnorm(0,10),
        bt ~ dnorm(0,10),
        bte ~ dnorm(0,10),
        bts ~ dnorm(0,10),
        bt2 ~ dnorm(0,10),
        bt2e ~ dnorm(0,10),
        bt2s ~ dnorm(0,10),
    sigma ~ dcauchy(0,10)
    ) ,
  data = DSmeand_bmoddat, iter = 1000, warmup = 300, chains = 4)

saveRDS(meandspp.blm_1, "meandspp.blm_1.Rds")


# drop s*e
set.seed(1983)
meandspp.blm_2 = map2stan(
  alist(
    SDMeander ~ dnorm(mu, sigma), 
      mu  <-  a + 
              be*ExposeDummy + 
              bs*SppDummy + 
              bt*(lnCalcConcC) +
              bte*(ExposeDummy)*(lnCalcConcC) +
              bts*(SppDummy)*(lnCalcConcC) +
              bt2*(lnCalcConcC2) +
              bt2e*(ExposeDummy)*(lnCalcConcC2) +
              bt2s*(SppDummy)*(lnCalcConcC2) ,
        a ~ dnorm(0,10),
        be ~ dnorm(0,10),
        bs ~ dnorm(0,10),
        bt ~ dnorm(0,10),
        bte ~ dnorm(0,10),
        bts ~ dnorm(0,10),
        bt2 ~ dnorm(0,10),
        bt2e ~ dnorm(0,10),
        bt2s ~ dnorm(0,10),
      sigma ~ dcauchy(0,10)
    ) ,
  data = DSmeand_bmoddat, iter = 1000, warmup = 300, chains = 4)

saveRDS(meandspp.blm_2, "meandspp.blm_2.Rds")
## removing s*e improved model by 5.8 AIC points. Will keep it out



# drop all t interactions
set.seed(1983)
meandspp.blm_2b = map2stan(
  alist(
    SDMeander ~ dnorm(mu, sigma), 
      mu  <-  a + 
              be*ExposeDummy + 
              bs*SppDummy + 
              bt*(lnCalcConcC) +
              bt2*(lnCalcConcC2),
        a ~ dnorm(0,10),
        be ~ dnorm(0,10),
        bs ~ dnorm(0,10),
        bt ~ dnorm(0,10),
        bt2 ~ dnorm(0,10),
      sigma ~ dcauchy(0,10)
    ) ,
  data = DSmeand_bmoddat, iter = 1000, warmup = 300, chains = 4)


# add back in interaction with spp and treatment - below as blm_4

# remove exposure interaction with treatment effect (keep with quadratic)
set.seed(1983)
meandspp.blm_3 = map2stan(
  alist(
    SDMeander ~ dnorm(mu, sigma), 
      mu  <-  a + 
              be*ExposeDummy + 
              bs*SppDummy + 
              bt*(lnCalcConcC) +
              bts*(SppDummy)*(lnCalcConcC) +
              bt2*(lnCalcConcC2) +
              bt2e*(ExposeDummy)*(lnCalcConcC2) +
              bt2s*(SppDummy)*(lnCalcConcC2) ,
        a ~ dnorm(0,10),
        be ~ dnorm(0,10),
        bs ~ dnorm(0,10),
        bt ~ dnorm(0,10),
        bts ~ dnorm(0,10),
        bt2 ~ dnorm(0,10),
        bt2e ~ dnorm(0,10),
        bt2s ~ dnorm(0,10),
      sigma ~ dcauchy(0,10)
    ) ,
  data = DSmeand_bmoddat, iter = 1000, warmup = 300, chains = 4)

saveRDS(meandspp.blm_3, "meandspp.blm_3.Rds")



# remove exposure interaction with both straight and squadratic treatment effect 
set.seed(1983)
meandspp.blm_4 = map2stan(
  alist(
    SDMeander ~ dnorm(mu, sigma), 
      mu  <-  a + 
              be*ExposeDummy + 
              bs*SppDummy + 
              bt*(lnCalcConcC) +
              bts*(SppDummy)*(lnCalcConcC) +
              bt2*(lnCalcConcC2) +
              bt2s*(SppDummy)*(lnCalcConcC2) ,
        a ~ dnorm(0,10),
        be ~ dnorm(0,10),
        bs ~ dnorm(0,10),
        bt ~ dnorm(0,10),
        bts ~ dnorm(0,10),
        bt2 ~ dnorm(0,10),
        bt2s ~ dnorm(0,10),
      sigma ~ dcauchy(0,10)
    ) ,
  data = DSmeand_bmoddat, iter = 1000, warmup = 300, chains = 4)

saveRDS(meandspp.blm_4, "meandspp.blm_4.Rds")

# remove exposure interaction with both straight and squadratic treatment effect but add bace s*e (match distance model)
set.seed(1983)
meandspp.blm_5 = map2stan(
  alist(
    SDMeander ~ dnorm(mu, sigma), 
      mu  <-  a + 
              be*ExposeDummy + 
              bs*SppDummy + 
              bse*SppDummy*ExposeDummy + 
              bt*(lnCalcConcC) +
              bts*(SppDummy)*(lnCalcConcC) +
              bt2*(lnCalcConcC2) +
              bt2s*(SppDummy)*(lnCalcConcC2) ,
        a ~ dnorm(0,10),
        be ~ dnorm(0,10),
        bs ~ dnorm(0,10),
        bse ~ dnorm(0,10),
        bt ~ dnorm(0,10),
        bts ~ dnorm(0,10),
        bt2 ~ dnorm(0,10),
        bt2s ~ dnorm(0,10),
      sigma ~ dcauchy(0,10)
    ) ,
  data = DSmeand_bmoddat, iter = 1000, warmup = 300, chains = 4)

saveRDS(meandspp.blm_5, "meandspp.blm_5.Rds")
# model without s*e is still better, even when there isn't an interaction between exposure and the treatment and quadratic of treatment. 


# remove species interaction with straight treatment effect 
set.seed(1983)
meandspp.blm_6 = map2stan(
  alist(
    SDMeander ~ dnorm(mu, sigma), 
      mu  <-  a + 
              be*ExposeDummy + 
              bs*SppDummy + 
              bt*(lnCalcConcC) +
              bt2*(lnCalcConcC2) +
              bt2s*(SppDummy)*(lnCalcConcC2) ,
        a ~ dnorm(0,10),
        be ~ dnorm(0,10),
        bs ~ dnorm(0,10),
        bt ~ dnorm(0,10),
        bt2 ~ dnorm(0,10),
        bt2s ~ dnorm(0,10),
      sigma ~ dcauchy(0,10)
    ) ,
  data = DSmeand_bmoddat, iter = 1000, warmup = 300, chains = 4)

saveRDS(meandspp.blm_6, "meandspp.blm_6.Rds")


compare(meandspp.blm_2,meandspp.blm_3,meandspp.blm_4,meandspp.blm_5,meandspp.blm_6)
```

```{r meander multi-level Baysemodels selection, echo=F, eval=F}

# use all meander data points, not summarized data
DSmeand_bmoddat = DataSum2496.meand[,c("SDMeander","lnCalcConcC","lnCalcConcC2",
                                     "ExposureHrs","Spp","RepID")]
DSmeand_bmoddat = DSmeand_bmoddat[!is.na(DSmeand_bmoddat$SDMeander),] # drops 26.1% of the data points when using full dataset; none if using summarized dataset 

DSmeand_bmoddat$lnCalcConcC = as.numeric(DSmeand_bmoddat$lnCalcConcC) 
DSmeand_bmoddat$lnCalcConcC2 = as.numeric(DSmeand_bmoddat$lnCalcConcC2) 
DSmeand_bmoddat$SppDummy <- as.numeric(ifelse(DSmeand_bmoddat$Spp=="GS", 0,1))
DSmeand_bmoddat$ExposeDummy <- as.numeric(ifelse(DSmeand_bmoddat$ExposureHrs=="24", 0,1))
#DSmeand_bmoddat$MeanderCircLog = as.numeric(DSmeand_bmoddat$MeanderCircLog) 

# remove fish with only one timepoint of detection, because cant add random slope with one timepoint
DSmeand_bmoddat = DSmeand_bmoddat[!(DSmeand_bmoddat$RepID %in% paste0(c(0,5,100,500,1000,2000), "-WS-4")),]
DSmeand_bmoddat$RepID = as.factor(as.character(DSmeand_bmoddat$RepID))

DSmeand_bmoddat = DSmeand_bmoddat[order(DSmeand_bmoddat$RepID),]

# let treatment effect and curve vary by species and exposure (all interactions except for s*e) and include random intercept for each individual, and let effect of exposure time vary by individual
set.seed(2016)
meandspp.blm_2.rise = map2stan(
  alist(
    SDMeander ~ dnorm(mu, sigma), 
      mu  <-  a_fish[RepID] + 
              be_fish[RepID]*ExposeDummy + 
              bs*SppDummy + 
              bt*(lnCalcConcC) +
              bte*(ExposeDummy)*(lnCalcConcC) +
              bts*(SppDummy)*(lnCalcConcC) +
              bt2*(lnCalcConcC2) +
              bt2e*(ExposeDummy)*(lnCalcConcC2) +
              bt2s*(SppDummy)*(lnCalcConcC2) ,
           c(a_fish,be_fish)[RepID] ~ dmvnorm2(Mu=c(a,be), sigma=sigma_fish, Rho=Rho), 
                   a ~ dnorm(0,10),
                   be ~ dnorm(0,10),
                   sigma_fish ~ dcauchy(0,10),
                   Rho ~ dlkjcorr(2),
        bs ~ dnorm(0,10),
        bt ~ dnorm(0,10),
        bte ~ dnorm(0,10),
        bts ~ dnorm(0,10),
        bt2 ~ dnorm(0,10),
        bt2e ~ dnorm(0,10),
        bt2s ~ dnorm(0,10),
    sigma ~ dcauchy(0,10)
    ) ,
  data = DSmeand_bmoddat, iter = 2000, warmup = 700, chains = 4)
 
#saveRDS(meandspp.blm_2.rise, "meandspp.blm_2.rise.Rds")

# check model
 precis(meandspp.blm_2.rise, prob = .95, digits=3)
 plot(precis(meandspp.blm_2.rise, prob = .95))
 plot(precis(meandspp.blm_2.rise, prob = .95, depth=2))

 plot(meandspp.blm_2.rise)
# this model's checks looked fine but it's fitting TERRIBLY. could be a plotting thing, but I think it's that the estimtd for the curvature of GS are way too high. Same with the basic blm_2 model above, but less so.  

 
```
### _2.rise is a fine model, and pretty well matches the other models, and lets us test the questions we're interested in. But the neff for sigma is pretty low. Trield various levels of dcauchy(0,X) and estimates didn't change too dramatically: with dcauchy(0,20) neff=26. With dcauchy(0,50) neff=4. with dcauchy(0,5) neff=30. with dcauchy(0,10) neff=25. Rhat ~1.1 - 1.2 for most also. Traceplots look okay but not perfect. Some sections where one or two of the chains don't mix (ie: are pretty thin lines). And sigma trace plots don't look great. But likely an okay model to use anyway. 
 
### Comparing the models with and wihtout random effects, we see that when random effects are added the estimates all move closer to zero (shrinkage?) and the variance gets arger for alle stimates that do not include any effect of exposure time (since that is the random slope). Those which do include exposure time show reduced sd values because some of the variation assocaited with exposure time is accounted for by the individual clustering. 


```{r meander multi-level Bayesmodels predict, echo=F, eval=F}

# pull posterior from model:
set.seed(42)
post = extract.samples(meandspp.blm_2.rise)

# set up dataframe to plot posterior predictions
preddat = list(CalcConc=rep(seq(0, 2250, 2), 4), 
               lnCalcConc=log(rep(seq(0, 2250, 2),4)+1), 
               lnCalcConcC=   (log(rep(seq(0, 2250, 2),4)+1)) - 
                 mean(DataSum2496.dist$lnCalcConc) ,
               lnCalcConcC2=( (log(rep(seq(0, 2250, 2),4)+1)) - 
                 mean(DataSum2496.dist$lnCalcConc) ) ^ 2 ,               
               ExposeDummy = rep(c(0,1), each=1126*2), 
               SppDummy = rep(rep(c(0,1),each=1126),2), 
               RepID = rep(16,4504))


# replace individual fish estimates with global estimate; this should predict to the average individual in a population...so since I want to get at the population level response this seems most appropriate.
a_global = matrix(post$a,5200,90) # 5200 = 1300 samples per chain x 4 chains
be_global = matrix(post$be,5200,90)

# use link to predict to mean only
link.2.rise <- link(meandspp.blm_2.rise, n=1000, data= preddat, 
                        replace = list(a_fish = a_global, 
                                        be_fish = be_global) )

preddat.df <- data.frame(sapply(preddat,c)) # thanks stack overflow! https://stackoverflow.com/questions/4227223/convert-a-list-to-a-data-frame

preddat.df$link_mu_mn <- apply(link.2.rise, 2, mean) 
preddat.df$link_PI05 = apply(link.2.rise, 2, PI, .95)[1,] 
preddat.df$link_PI95 = apply(link.2.rise, 2, PI, .95)[2,] 


  # plot back-transformed data
  preddat.df$Spp <- ifelse(preddat.df$SppDummy==0,"GS","WS")
  preddat.df$ExposureHrs <- ifelse(preddat.df$ExposeDummy==0,"24","96")


MeandPred_transf_plot = ggplot() + 
  geom_point(data=DataSum2496.meand,
             aes(x=(lnCalcConcC),                          
                 y=SDMeander, 
                 color=factor(Spp))) + 
  geom_ribbon(data = preddat.df, aes(x=(lnCalcConcC), 
              ymin=link_PI05, ymax=link_PI95), 
              alpha=.4, col="grey70")+
  geom_line(data = preddat.df, aes(x=(lnCalcConcC), y=link_mu_mn), lwd=.2)+
    facet_grid(Spp~ExposureHrs, scales="free", labeller = labeller(
      ExposureHrs = c("24"="24 Hours Exposure","96"="96 Hours Exposure"),
      Spp = c("GS" = "Green Sturgeon", "WS" = "White Sturgeon")))+
    scale_color_manual(values=c("green3", "steelblue3"), guide=FALSE)+
    ylab("SD of Track Meander (deg/mm)") + 
    scale_x_continuous(name="Log-centered Bifenthrin Concentration (ng/L)") + #, breaks = seq(-7.5,5, 2.5), labels=(seq(-7.5,5, 2.5)+3.73) ) +
    theme_bw()


MeandPred_orig_plot = ggplot() + 
  geom_point(data=DataSum2496.meand,
             aes(x=exp(lnCalcConc),                          
                 y=SDMeander, 
                 color=factor(Spp))) + 
  geom_ribbon(data = preddat.df, aes(x=(CalcConc), 
              ymin=link_PI05, ymax=link_PI95), 
              alpha=.4, col="grey70")+
  geom_line(data = preddat.df, aes(x=(CalcConc), y=link_mu_mn), lwd=.2)+
  facet_grid(Spp~ExposureHrs, scales="free", labeller = labeller(
    ExposureHrs = c("24"="24 Hours Exposure","96"="96 Hours Exposure"),
    Spp = c("GS" = "Green Sturgeon", "WS" = "White Sturgeon")))+
  scale_color_manual(values=c("green3", "steelblue3"), guide=FALSE)+
  ylab("SD of Track Meander (deg/mm)") + 
  scale_x_continuous(name="Bifenthrin Concentration (ng/L)") + #, breaks = seq(-7.5,5, 2.5), labels=(seq(-7.5,5, 2.5)+3.73) ) +
  theme_bw()

MeandPred_transf_plot
MeandPred_orig_plot 

```
 
 
### MeanderSD Contrasts

### Study questions: 

###  1) is there an effect (all treatment vs control), and which metrics show an effect

###  2) does that effect change with time [96 treat vs 96 control and 24 treat vs 24 control OR individual change from 24 to 96 (all treatments) as compared to individual change for control between 24 and 96]

###  3) Does the magnitude of the effect vary between species

```{r meander multi-level model density plots, echo=F}
set.seed(1983) 
postmeand = extract.samples(meandspp.blm_2.rise)  

# reference table to convert from treatment to centered, log-transformed measured concentrations
TreatCalcTable = unique(DataSum2496.meand[order(DataSum2496.meand$Treatment)
                                             ,c("Spp", "Treatment","lnCalcConc", "lnCalcConcC")])
TreatCalcTable$lnCalcConcC2 = TreatCalcTable$lnCalcConcC ^ 2



# calculate differences between control and treatment at each time point for each species (20 contrasts)
GS0bif24m = postmeand$a +
  postmeand$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==0)$lnCalcConcC) +
  postmeand$bt2*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==0)$lnCalcConcC2)
GS5bif24m = postmeand$a + 
  postmeand$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==5)$lnCalcConcC) +
  postmeand$bt2*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==5)$lnCalcConcC2)
GS100bif24m = postmeand$a + 
  postmeand$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==100)$lnCalcConcC) +
  postmeand$bt2*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==100)$lnCalcConcC2)
GS500bif24m = postmeand$a + 
  postmeand$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==500)$lnCalcConcC) +
  postmeand$bt2*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==500)$lnCalcConcC2)
GS1000bif24m = postmeand$a +
  postmeand$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==1000)$lnCalcConcC) + 
  postmeand$bt2* as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==1000)$lnCalcConcC2)
GS2000bif24m = postmeand$a + 
  postmeand$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==2000)$lnCalcConcC) + 
  postmeand$bt2*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==2000)$lnCalcConcC2)

mean(GS0bif24m)
mean(GS5bif24m)
 cont.GS_0.5bif_24m = (sum(GS0bif24m<GS5bif24m) / length(GS0bif24m)) 
 cont.GS_0.5bif_24m #72.0% prob that 5 is more than 0
mean(GS100bif24m)
 cont.GS_0.100bif_24m = (sum(GS0bif24m<GS100bif24m) / length(GS0bif24m)) 
 cont.GS_0.100bif_24m #62.4% prob that 100 is more than 0
mean(GS500bif24m)
 cont.GS_0.500bif_24m = (sum(GS0bif24m<GS500bif24m) / length(GS0bif24m)) 
 cont.GS_0.500bif_24m #40.7% prob that 500 is more than 0
mean(GS1000bif24m)
 cont.GS_0.1000bif_24m = (sum(GS0bif24m<GS1000bif24m) / length(GS0bif24m)) 
 cont.GS_0.1000bif_24m #32.8% prob that 1000 is more than 0
mean(GS2000bif24m)
 cont.GS_0.2000bif_24m = (sum(GS0bif24m<GS2000bif24m) / length(GS0bif24m)) 
 cont.GS_0.2000bif_24m #13.7% prob that 2000 is more than 0 (86.3% chance that 2000 is less than 0)

GS24m.plot = ggplot() + geom_density(aes(x=GS0bif24m, color="black")) + 
  geom_density(aes(x=GS5bif24m, color="green3")) + 
  geom_density(aes(x=GS100bif24m, color="goldenrod")) + 
  geom_density(aes(x=GS500bif24m, color="red3")) + 
  geom_density(aes(x=GS1000bif24m, color="pink")) + 
  geom_density(aes(x=GS2000bif24m, color="steelblue3")) + 
  scale_color_manual(name="Nominal Bifenthrin\nConcentration", 
                     values=c("black"="black", "green3"="green3", "goldenrod"="goldenrod",
                              "red3"="red3", "pink"="pink","steelblue3"="steelblue3"), 
                     labels=c("0 ng/L", "5 ng/L", "100ng/L", 
                              "500ng/L", "1000ng/L", "2000 ng/L") ) + 
  xlab("SD Track Meander (GS @ 24hr)")+
  theme_bw()


# repeat for green sturgeon, 96hr

GS0bif96m = postmeand$a + postmeand$be +
  postmeand$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==0)$lnCalcConcC) +
  postmeand$bt2*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==0)$lnCalcConcC2)
GS5bif96m = postmeand$a + postmeand$be + 
  postmeand$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==5)$lnCalcConcC) +
  postmeand$bt2*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==5)$lnCalcConcC2)
GS100bif96m = postmeand$a + postmeand$be + 
  postmeand$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==100)$lnCalcConcC) +
  postmeand$bt2*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==100)$lnCalcConcC2)
GS500bif96m = postmeand$a + postmeand$be + 
  postmeand$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==500)$lnCalcConcC) +
  postmeand$bt2*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==500)$lnCalcConcC2)
GS1000bif96m = postmeand$a + postmeand$be +
  postmeand$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==1000)$lnCalcConcC) + 
  postmeand$bt2* as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==1000)$lnCalcConcC2)
GS2000bif96m = postmeand$a + postmeand$be + 
  postmeand$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==2000)$lnCalcConcC) + 
  postmeand$bt2*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==2000)$lnCalcConcC2)

mean(GS0bif96m)
mean(GS5bif96m)
 cont.GS_0.5bif_96m = (sum(GS0bif96m<GS5bif96m) / length(GS0bif96m)) 
 cont.GS_0.5bif_96m #72.0% prob that 5 is more than 0
mean(GS100bif96m)
mean(GS500bif96m)
mean(GS1000bif96m)
mean(GS2000bif96m)

GS96m.plot = ggplot() + geom_density(aes(x=GS0bif96m), color="black") + 
  geom_density(aes(x=GS5bif96m), color="green3") + 
  geom_density(aes(x=GS100bif96m), color="goldenrod") + 
  geom_density(aes(x=GS500bif96m), color="red3") + 
  geom_density(aes(x=GS1000bif96m), color="pink") + 
  geom_density(aes(x=GS2000bif96m), color="steelblue3") + 
  scale_color_manual(name="Nominal Bifenthrin\nConcentration", 
                     values=c("black"="black", "green3"="green3", "goldenrod"="goldenrod",
                              "red3"="red3", "pink"="pink","steelblue3"="steelblue3"), 
                     labels=c("0 ng/L", "5 ng/L", "100ng/L", 
                              "500ng/L", "1000ng/L", "2000 ng/L") ) + 
  xlab("SD Track Meander (GS @ 96hr)")+
  theme_bw()


# repeat for white sturgeon, 24hr

WS0bif24m = postmeand$a + postmeand$bs +
  postmeand$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==0)$lnCalcConcC) +
  postmeand$bt2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==0)$lnCalcConcC2) +
  postmeand$bts1*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==0)$lnCalcConcC) +
  postmeand$bts2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==0)$lnCalcConcC2)
WS5bif24m = postmeand$a + postmeand$bs + 
  postmeand$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==5)$lnCalcConcC) +
  postmeand$bt2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==5)$lnCalcConcC2)+
  postmeand$bts1*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==5)$lnCalcConcC) +
  postmeand$bts2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==5)$lnCalcConcC2)
WS100bif24m = postmeand$a + postmeand$bs + 
  postmeand$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==100)$lnCalcConcC) +
  postmeand$bt2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==100)$lnCalcConcC2)+
  postmeand$bts1*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==100)$lnCalcConcC) +
  postmeand$bts2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==100)$lnCalcConcC2)
WS500bif24m = postmeand$a + postmeand$bs + 
  postmeand$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==500)$lnCalcConcC) +
  postmeand$bt2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==500)$lnCalcConcC2)+
  postmeand$bts1*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==500)$lnCalcConcC) +
  postmeand$bts2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==500)$lnCalcConcC2)
WS1000bif24m = postmeand$a + postmeand$bs +
  postmeand$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==1000)$lnCalcConcC) + 
  postmeand$bt2* as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==1000)$lnCalcConcC2)+
  postmeand$bts1*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==1000)$lnCalcConcC) + 
  postmeand$bts2* as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==1000)$lnCalcConcC2)
WS2000bif24m = postmeand$a + postmeand$bs + 
  postmeand$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==2000)$lnCalcConcC) + 
  postmeand$bt2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==2000)$lnCalcConcC2)+
  postmeand$bts1*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==2000)$lnCalcConcC) + 
  postmeand$bts2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==2000)$lnCalcConcC2)

mean(WS0bif24m)
mean(WS5bif24m)
 cont.WS_0.5bif_24m = (sum(WS0bif24m<WS5bif24m) / length(WS0bif24m)) 
 cont.WS_0.5bif_24m #100% prob that 5 is more than 0
mean(WS100bif24m)
 cont.WS_0.100bif_24m = (sum(WS0bif24m<WS100bif24m) / length(WS0bif24m)) 
 cont.WS_0.100bif_24m #100% prob that 100 is more than 0
mean(WS500bif24m)
 cont.WS_0.500bif_24m = (sum(WS0bif24m<WS500bif24m) / length(WS0bif24m)) 
 cont.WS_0.500bif_24m #55% prob that 500 is more than 0
mean(WS1000bif24m)
 cont.WS_0.1000bif_24m = (sum(WS0bif24m<WS1000bif24m) / length(WS0bif24m)) 
 cont.WS_0.1000bif_24m #0% prob that 1000 is more than 0 (i.e. 100% prob that 1000 is less than 0)
mean(WS2000bif24m)
 cont.WS_0.2000bif_24m = (sum(WS0bif24m<WS2000bif24m) / length(WS0bif24m)) 
 cont.WS_0.2000bif_24m #0% prob that 2000 is more than 0 (i.e. 100% prob that 1000 is less than 0)
 
WS24m.plot = ggplot() + geom_density(aes(x=WS0bif24m), color="black") + 
  geom_density(aes(x=WS5bif24m), color="green3") + 
  geom_density(aes(x=WS100bif24m), color="goldenrod") + 
  geom_density(aes(x=WS500bif24m), color="red3") + 
  geom_density(aes(x=WS1000bif24m), color="pink") + 
  geom_density(aes(x=WS2000bif24m), color="steelblue3") + 
  scale_color_manual(name="Nominal Bifenthrin\nConcentration", 
                     values=c("black"="black", "green3"="green3", "goldenrod"="goldenrod",
                              "red3"="red3", "pink"="pink","steelblue3"="steelblue3"), 
                     labels=c("0 ng/L", "5 ng/L", "100ng/L", 
                              "500ng/L", "1000ng/L", "2000 ng/L") ) + 
  xlab("SD Track Meander (WS @ 24hr)")+
  theme_bw()


# repeat for white sturgeon, 96hr


WS0bif96m = postmeand$a + postmeand$bs + postmeand$be + 
  postmeand$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==0)$lnCalcConcC) +
  postmeand$bt2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==0)$lnCalcConcC2) +
  postmeand$bts1*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==0)$lnCalcConcC) +
  postmeand$bts2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==0)$lnCalcConcC2)
WS5bif96m = postmeand$a + postmeand$bs + postmeand$be + 
  postmeand$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==5)$lnCalcConcC) +
  postmeand$bt2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==5)$lnCalcConcC2) +
  postmeand$bts1*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==5)$lnCalcConcC) +
  postmeand$bts2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==5)$lnCalcConcC2)
WS100bif96m = postmeand$a + postmeand$bs + postmeand$be + 
  postmeand$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==100)$lnCalcConcC) +
  postmeand$bt2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==100)$lnCalcConcC2) +
  postmeand$bts1*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==100)$lnCalcConcC) +
  postmeand$bts2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==100)$lnCalcConcC2)
WS500bif96m = postmeand$a + postmeand$bs + postmeand$be + 
  postmeand$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==500)$lnCalcConcC) +
  postmeand$bt2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==500)$lnCalcConcC2) +
  postmeand$bts1*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==500)$lnCalcConcC) +
  postmeand$bts2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==500)$lnCalcConcC2)
WS1000bif96m = postmeand$a + postmeand$bs + postmeand$be +  
  postmeand$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==1000)$lnCalcConcC) + 
  postmeand$bt2* as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==1000)$lnCalcConcC2) +
  postmeand$bts1*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==1000)$lnCalcConcC) + 
  postmeand$bts2* as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==1000)$lnCalcConcC2)
WS2000bif96m = postmeand$a + postmeand$bs + postmeand$be + 
  postmeand$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==2000)$lnCalcConcC) + 
  postmeand$bt2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==2000)$lnCalcConcC2) +
  postmeand$bts1*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==2000)$lnCalcConcC) + 
  postmeand$bts2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==2000)$lnCalcConcC2)

mean(WS0bif96m)
mean(WS5bif96m)
 cont.WS_0.5bif_96m = (sum(WS0bif96m<WS5bif96m) / length(WS0bif96m)) 
 cont.WS_0.5bif_96m #100% prob that 5 is more than 0
mean(WS100bif96m)
 cont.WS_0.100bif_96m = (sum(WS0bif96m<WS100bif96m) / length(WS0bif96m)) 
 cont.WS_0.100bif_96m #100% prob that 100 is more than 0
mean(WS500bif96m)
 cont.WS_0.500bif_96m = (sum(WS0bif96m<WS500bif96m) / length(WS0bif96m)) 
 cont.WS_0.500bif_96m #55.0% prob that 500 is more than 0
mean(WS1000bif96m)
 cont.WS_0.1000bif_96m = (sum(WS0bif96m<WS1000bif96m) / length(WS0bif96m)) 
 cont.WS_0.1000bif_96m #0% prob that 1000 is more than 0 (i.e. 100% prob that 1000 is less than 0)
mean(WS2000bif96m)
 cont.WS_0.2000bif_96m = (sum(WS0bif96m<WS2000bif96m) / length(WS0bif96m)) 
 cont.WS_0.2000bif_96m #0% prob that 2000 is more than 0 (i.e. 100% prob that 2000 is less than 0)

WS96m.plot = ggplot() + geom_density(aes(x=WS0bif96m), color="black") + 
  geom_density(aes(x=WS5bif96m), color="green3") + 
  geom_density(aes(x=WS100bif96m), color="goldenrod") + 
  geom_density(aes(x=WS500bif96m), color="red3") + 
  geom_density(aes(x=WS1000bif96m), color="pink") + 
  geom_density(aes(x=WS2000bif96m), color="steelblue3") + 
  scale_color_manual(name="Nominal Bifenthrin\nConcentration", 
                     values=c("black"="black", "green3"="green3", "goldenrod"="goldenrod",
                              "red3"="red3", "pink"="pink","steelblue3"="steelblue3"), 
                     labels=c("0 ng/L", "5 ng/L", "100ng/L", 
                              "500ng/L", "1000ng/L", "2000 ng/L") ) + 
  xlab("SD Track Meander (WS @ 96hr)")+
  theme_bw()

GS24m.plot + GS96m.plot + WS24m.plot + WS96m.plot

predgroups = list(GS0bif24m, GS5bif24m,GS100bif24m,GS500bif24m,GS1000bif24m,GS2000bif24m,
                  GS0bif96m, GS5bif96m,GS100bif96m,GS500bif96m,GS1000bif96m,GS2000bif96m,
                  WS0bif24m, WS5bif24m,WS100bif24m,WS500bif24m,WS1000bif24m,WS2000bif24m,
                  WS0bif96m, WS5bif96m,WS100bif96m,WS500bif96m,WS1000bif96m,WS2000bif96m)
PredGroupNames =  as.character(expression(GS0bif24m,GS5bif24m,GS100bif24m,GS500bif24m,
                                          GS1000bif24m,GS2000bif24m,
                   GS0bif96m, GS5bif96m,GS100bif96m,GS500bif96m,GS1000bif96m,GS2000bif96m,
                   WS0bif24m, WS5bif24m,WS100bif24m,WS500bif24m,WS1000bif24m,WS2000bif24m,
                   WS0bif96m, WS5bif96m,WS100bif96m,WS500bif96m,WS1000bif96m,WS2000bif96m))
posterior.preds = data.frame(PredGroupNames = PredGroupNames, 
                             PredMeans = sapply(predgroups, mean),
                             Pred95CIl = sapply(predgroups, quantile, 0.05),
                             Pred95CIu = sapply(predgroups, quantile, 0.95))
```
#### if use this in a paper, recolor to a more intuitive gradient and add legend
 
 
```{r meander multi-level model time and spp contrasts, echo=F}
# this uses the predicted posteriors for distance moved, calculated above

# GS vs WS
cont.GS.WS_0bif_24m = sum(GS0bif24m<WS0bif24m) / length(GS0bif24m)
 cont.GS.WS_0bif_24m # 100% probability that GS will move less than WS

 cont.GS.WS_0bif_96m = sum(GS0bif96m<WS0bif96m) / length(GS0bif96m)
 cont.GS.WS_0bif_96m # 100% probability that GS will move less than WS
cont.GS.WS_2000bif_96m = sum(GS2000bif96m<WS2000bif96m) / length(GS2000bif96m)
 cont.GS.WS_2000bif_96m # 99.89% probability that GS will move less than WS


# Green Sturgeon, Exposure Hr
cont.GS0bif_96.24m = (sum(GS0bif96m<GS0bif24m) / length(GS0bif96m)) 
cont.GS5bif_96.24m = (sum(GS5bif96m<GS5bif24m) / length(GS5bif96m)) 
cont.GS100bif_96.24m = (sum(GS100bif96m<GS100bif24m) / length(GS100bif96m)) 
cont.GS500bif_96.24m = (sum(GS500bif96m<GS500bif24m) / length(GS500bif96m)) 
cont.GS1000bif_96.24m = (sum(GS1000bif96m<GS1000bif24m) / length(GS1000bif96m)) 
cont.GS2000bif_96.24m = (sum(GS2000bif96m<GS2000bif24m) / length(GS2000bif96m)) 

cont.GS0bif_96.24m
cont.GS5bif_96.24m
cont.GS100bif_96.24m
cont.GS500bif_96.24m
cont.GS1000bif_96.24m
cont.GS2000bif_96.24m


GS0bif_96.24m.plot = ggplot() + geom_density(aes(x=GS0bif96m), color="steelblue3") + 
  geom_density(aes(x=GS0bif24m), color="green3") + 
  xlab("SD Meander - GS @ 0 ng/L bifenthrin\n24 vs 96 hrs)") +
  theme_bw()
GS2000bif_96.24m.plot = ggplot() + geom_density(aes(x=GS2000bif96m), color="steelblue3") + 
  geom_density(aes(x=GS2000bif24m), color="green3") + 
  xlab("SD Meander - GS @ 2000 ng/L bifenthrin\n24 vs 96 hrs)") +
  theme_bw()
# can repeat these for each concentration if interesting

# use patchwork grammar to plot multiple plots together
GS0bif_96.24m.plot + GS2000bif_96.24m.plot   




# White Sturgeon: probability of a difference between 24 and 96 hours, at each treatment level
cont.WS0bif_96.24m = (sum(WS0bif96m<WS0bif24m) / length(WS0bif96m)) 
cont.WS0bif_96.24m


WS0bif_96.24m.plot = ggplot() + geom_density(aes(x=WS0bif96m), color="steelblue3") + 
  geom_density(aes(x=WS0bif24m), color="green3") + 
  xlab("SD Meander - WS @ 0 ng/L bifenthrin\n24 vs 96 hrs)") +
  theme_bw()
WS0bif_96.24m.plot


```

#### well, these plots all look about the same, as they should since there's no interaction for concentration * exposure time; which fits the contrast value - it is 95.2% likely (for all comparisons of concentation, because there isn't an interaction) that for Green Sturgeon the distance moved at 96hrs (7ph) is greater than the distance moved at 24hrs (4 dph). But for white sturgeon, it's a 100% chance that there is less movement at 96hrs than at 24hrs exposure. 




########### 
     
## Center Zone Models - good and complete! #####
```{r center zone data, echo=F, eval=F} 
DataSum2496.centC = DataSum2496.raw %>%
  filter(!is.na(InZoneC)) %>%  ### will this bias the data if I remove those points where there isn't a detection? If the fish is more likely to be in the center when it's stationary, and it's more likely to be undetected when it's stationary, this may bias these values and under-represent the effect of the bifenthrin (more stationary when strongly affected)
  # also note, this line doesn't actually change the results because summing the InZoneC column drops all NA automatically; this line above just makes that explicit
  group_by(index, Trial, Arena, Replicate, ExposureHrs, Treatment, calcConc, Spp, RepID) %>%
  summarize(InZoneC = sum(InZoneC, na.rm=T), InZoneB = sum(InZoneB, na.rm=T), npos = n()) %>%
  mutate(PercZoneC1 = InZoneC / npos) %>%
  mutate(PercZoneC2 = InZoneC / (InZoneC+InZoneB)) %>%
  # ran this comparison to see how much the NA can influence the data, and it seems to be minor
  ungroup()  %>%
  data.frame()

 DataSum2496.centC$lnCalcConc = log(DataSum2496.centC$calcConc+1)
 DataSum2496.centC$lnCalcConcC= scale(DataSum2496.centC$lnCalcConc, scale=FALSE)
 DataSum2496.centC$lnCalcConcC2 = DataSum2496.centC$lnCalcConcC^2 
    # order of transformations matters (log then scale then square)

 # add a tiny amount to the perc to keep it above zero (issues for fitting because logit(0)=Inf
 # but don't add so much that the max will be =>1
 DataSum2496.centC$PercZoneC1 = DataSum2496.centC$PercZoneC1 +.001
 DataSum2496.centC$PercZoneC2 = DataSum2496.centC$PercZoneC2 +.001
 
```

```{r center zone data 2, echo=F} 
DataSum2496.centC = DataSum2496.raw %>%
  filter(!is.na(InZoneC)) %>%  ### will this bias the data if I remove those points where there isn't a detection? If the fish is more likely to be in the center when it's stationary, and it's more likely to be undetected when it's stationary, this may bias these values and under-represent the effect of the bifenthrin (more stationary when strongly affected)
  # also note, this line doesn't actually change the results because summing the InZoneC column drops all NA automatically; this line above just makes that explicit
  group_by(index, Trial, Arena, Replicate, ExposureHrs, Treatment, calcConc, Spp, RepID) %>%
  summarize(nCent = sum(InZoneC), npos = n()) %>%
  ungroup()  %>%
  data.frame()

 DataSum2496.centC$lnCalcConc = log(DataSum2496.centC$calcConc+1)
 DataSum2496.centC$lnCalcConcC= scale(DataSum2496.centC$lnCalcConc, scale=FALSE)
 DataSum2496.centC$lnCalcConcC2 = DataSum2496.centC$lnCalcConcC^2 
    # order of transformations matters (log then scale then square)

 DataSum2496.centC$nOuter = DataSum2496.centC$npos - DataSum2496.centC$nCent
 
 
```


```{r centerzone multi-level Bayesmodels selection, echo=F, eval=F}
# try setting up the linear model in a bayesian form, same as frequentist model above
# use all meander data points, not summarized data
DScent_bmoddat = DataSum2496.centC[,c("nCent", "npos", "lnCalcConcC","lnCalcConcC2",
                                     "ExposureHrs","Spp","RepID")]
DScent_bmoddat$lnCalcConcC = as.numeric(DScent_bmoddat$lnCalcConcC) 
DScent_bmoddat$lnCalcConcC2 = as.numeric(DScent_bmoddat$lnCalcConcC2) 
DScent_bmoddat$SppDummy <- as.numeric(ifelse(DScent_bmoddat$Spp=="GS", 0,1))
DScent_bmoddat$ExposeDummy <- as.numeric(ifelse(DScent_bmoddat$ExposureHrs=="24", 0,1))

# remove fish with only one timepoint of detection, because cant add random slope with one timepoint
DScent_bmoddat = DScent_bmoddat[!(DScent_bmoddat$RepID %in% paste0(c(0,5,100,500,1000,2000), "-WS-4")),]
DScent_bmoddat$RepID = as.factor(as.character(DScent_bmoddat$RepID))


set.seed(1983)
centspp.blm_int_a = map2stan(
  alist(
    nCent ~ dbinom(npos, p), 
      logit(p)  <- a_fish[RepID] + 
              be*ExposeDummy + 
              bs*SppDummy + 
              bt*(lnCalcConcC) ,
    
           a_fish[RepID] ~ dnorm(a,sigma_fish),
           a ~ dnorm(4,10), # approximate mean of base case (GS-24hr)
           sigma_fish ~ dcauchy(0,2),
        be ~ dnorm(0,10),
        bs ~ dnorm(0,10),
        bt ~ dnorm(0,10)
    ) ,
  data = DScent_bmoddat, iter = 2000, warmup = 300, chains = 3)
# wanders around the parameter space a lot. Doens't look very good at all. Hm. 

set.seed(1983)
centspp.blm_int1 = map2stan(
  alist(
    nCent ~ dbinom(npos, p), 
      logit(p)  <- a_fish[RepID] + 
              be_fish[RepID]*ExposeDummy + 
              bs*SppDummy + 
              bt*(lnCalcConcC) ,
    
           c(a_fish,be_fish)[RepID] ~ dmvnorm2(c(a, be),sigma_fish, Rho),# 
           a ~ dnorm(4,10), # approximate mean of base case (GS-24hr)
           be ~ dnorm(0,10),
           sigma_fish ~ dcauchy(0,2),
           Rho ~ dlkjcorr(2), # not as flat as (1) but biases against strong correlations of intercept and slope
    
        bs ~ dnorm(0,10),
        bt ~ dnorm(0,10)
    ) ,
  data = DScent_bmoddat, iter = 2000, warmup = 300, chains = 3)

set.seed(1983)
centspp.blm_int2 = map2stan(
  alist(
    nCent ~ dbinom(npos, p), 
      logit(p)  <-  a_fish[RepID] + 
              be_fish[RepID]*ExposeDummy + 
              bs*SppDummy + 
              bt*(lnCalcConcC) + 
              bt2*(lnCalcConcC2), 
      
           c(a_fish,be_fish)[RepID] ~ dmvnorm2(c(a, be),sigma_fish, Rho),# 
           a ~ dnorm(4,10), # approximate mean of base case (GS-24hr)
           be ~ dnorm(0,10),
           sigma_fish ~ dcauchy(0,2),
           Rho ~ dlkjcorr(2), # not as flat as (1) but biases against strong correlations of intercept and slope
    
        bs ~ dnorm(0,10),
        bt ~ dnorm(0,10),
        bt2 ~ dnorm(0,10)
    ) ,
  data = DScent_bmoddat, iter = 2000, warmup = 300, chains = 3)

set.seed(1983)
centspp.blm_int3 = map2stan(
  alist(
      nCent ~ dbinom(npos, p), 
      logit(p)  <-  a_fish[RepID] + 
              be_fish[RepID]*ExposeDummy + 
              bs*SppDummy + 
              bt*(lnCalcConcC) + 
              bt2*(lnCalcConcC2) + 
              bt2e*(lnCalcConcC2)*(ExposeDummy), 
      
           c(a_fish,be_fish)[RepID] ~ dmvnorm2(c(a, be),sigma_fish, Rho),# 
           a ~ dnorm(4,10), # approximate mean of base case (GS-24hr)
           be ~ dnorm(0,10),
           sigma_fish ~ dcauchy(0,2),
           Rho ~ dlkjcorr(2), # not as flat as (1) but biases against strong correlations of intercept and slope
    
        bs ~ dnorm(0,10),
        bt ~ dnorm(0,10),
        bt2 ~ dnorm(0,10),
        bt2e ~ dnorm(0,10)
    ) ,
  data = DScent_bmoddat, iter = 2000, warmup = 300, chains = 3)

set.seed(1983)
centspp.blm_int4 = map2stan(
  alist(
    nCent ~ dbinom(npos, p), 
      logit(p)  <- a_fish[RepID] + 
              be_fish[RepID]*ExposeDummy + 
              bs*SppDummy + 
              bt*(lnCalcConcC) + 
              bt2*(lnCalcConcC2) + 
              bt2s*(lnCalcConcC2)*(SppDummy), 
       
           c(a_fish,be_fish)[RepID] ~ dmvnorm2(c(a, be),sigma_fish, Rho),# 
           a ~ dnorm(4,10), # approximate mean of base case (GS-24hr)
           be ~ dnorm(0,10),
           sigma_fish ~ dcauchy(0,2),
           Rho ~ dlkjcorr(2), # not as flat as (1) but biases against strong correlations of intercept and slope
    
        bs ~ dnorm(0,10),
        bt ~ dnorm(0,10),
        bt2 ~ dnorm(0,10),
        bt2s ~ dnorm(0,10)
    ) ,
  data = DScent_bmoddat, iter = 2000, warmup = 300, chains = 3)
## 2294 transitions after warmup that exceeded max treedepth; wants more sampling too

set.seed(1983)
centspp.blm_int5 = map2stan(
  alist(
    nCent ~ dbinom(npos, p),
      logit(p)  <- a_fish[RepID] +
              be_fish[RepID]*ExposeDummy +
              bs*SppDummy +
              bt*(lnCalcConcC) +
              bte*(lnCalcConcC)*(ExposeDummy)+
              bt2*(lnCalcConcC2) +
              bt2s*(lnCalcConcC2)*(SppDummy),

           c(a_fish,be_fish)[RepID] ~ dmvnorm2(c(a, be),sigma_fish, Rho),#
           a ~ dnorm(4,10), # approximate mean of base case (GS-24hr)
           be ~ dnorm(0,10),
           sigma_fish ~ dcauchy(0,2),
           Rho ~ dlkjcorr(2), # not as flat as (1) but biases against strong correlations of intercept and slope

        bs ~ dnorm(0,10),
        bt ~ dnorm(0,10),
        bte ~ dnorm(0,10),
        bt2 ~ dnorm(0,10),
        bt2s ~ dnorm(0,10)
    ) ,
  data = DScent_bmoddat, iter = 2000, warmup = 300, chains = 3)


set.seed(1983)
centspp.blm_int6 = map2stan(
  alist(
    nCent ~ dbinom(npos, p),
      logit(p)  <- a_fish[RepID] +
              be_fish[RepID]*ExposeDummy +
              bs*SppDummy +
              bt*(lnCalcConcC) +
              bte*(lnCalcConcC)*(ExposeDummy)+
              bts*(lnCalcConcC)*(SppDummy),

           c(a_fish,be_fish)[RepID] ~ dmvnorm2(c(a, be),sigma_fish, Rho),#
           a ~ dnorm(4,10), # approximate mean of base case (GS-24hr)
           be ~ dnorm(0,10),
           sigma_fish ~ dcauchy(0,2),
           Rho ~ dlkjcorr(2), # not as flat as (1) but biases against strong correlations of intercept and slope

        bs ~ dnorm(0,10),
        bt ~ dnorm(0,10),
        bte ~ dnorm(0,10),
        bts ~ dnorm(0,10)
    ) ,
  data = DScent_bmoddat, iter = 2000, warmup = 300, chains = 3)

set.seed(1983)
centspp.blm_int7 = map2stan(
  alist(
    nCent ~ dbinom(npos, p),
      logit(p)  <- a_fish[RepID] +
              be_fish[RepID]*ExposeDummy +
              bs*SppDummy +
              bt*(lnCalcConcC) +
              bse*(SppDummy)*(ExposeDummy)+
              bte*(lnCalcConcC)*(ExposeDummy)+
              bts*(lnCalcConcC)*(SppDummy)+
              bt2*(lnCalcConcC2) +
              bt2e*(lnCalcConcC2)*(ExposeDummy)+
              bt2s*(lnCalcConcC2)*(SppDummy),

           c(a_fish,be_fish)[RepID] ~ dmvnorm2(c(a, be),sigma_fish, Rho),#
           a ~ dnorm(4,10), # approximate mean of base case (GS-24hr)
           be ~ dnorm(0,10),
           sigma_fish ~ dcauchy(0,2),
           Rho ~ dlkjcorr(2), # not as flat as (1) but biases against strong correlations of intercept and slope

        bs ~ dnorm(0,10),
        bt ~ dnorm(0,10),
        bse ~ dnorm(0,10),
        bte ~ dnorm(0,10),
        bts ~ dnorm(0,10),
        bt2 ~ dnorm(0,10),
        bt2e ~ dnorm(0,10),
        bt2s ~ dnorm(0,10)
    ) ,
  data = DScent_bmoddat, iter = 2000, warmup = 300, chains = 3)

set.seed(1983)
centspp.blm_int8 = map2stan(
  alist(
    nCent ~ dbinom(npos, p),
      logit(p)  <- a_fish[RepID] +
              be_fish[RepID]*ExposeDummy +
              bs*SppDummy +
              bt*(lnCalcConcC) +
              bse*(SppDummy)*(ExposeDummy)+
              bts*(lnCalcConcC)*(SppDummy)+
              bt2*(lnCalcConcC2) +
              bt2s*(lnCalcConcC2)*(SppDummy),

           c(a_fish,be_fish)[RepID] ~ dmvnorm2(c(a, be),sigma_fish, Rho),#
           a ~ dnorm(4,10), # approximate mean of base case (GS-24hr)
           be ~ dnorm(0,10),
           sigma_fish ~ dcauchy(0,2),
           Rho ~ dlkjcorr(2), # not as flat as (1) but biases against strong correlations of intercept and slope

        bs ~ dnorm(0,10),
        bt ~ dnorm(0,10),
        bse ~ dnorm(0,10),
        bts ~ dnorm(0,10),
        bt2 ~ dnorm(0,10),
        bt2s ~ dnorm(0,10)
    ) ,
  data = DScent_bmoddat, iter = 2000, warmup = 300, chains = 3)

compare(centspp.blm_int1, centspp.blm_int2, centspp.blm_int3, centspp.blm_int4, centspp.blm_int5, centspp.blm_int6, centspp.blm_int7,centspp.blm_int8)
## models are basically all the same...8 is slightly better WAIC than 7 (1.6) suggesting there isn't a need for the interacgtion between treatment and exposure period. But 7 is the only one that is >2 different from the 'best' which are models 2 and 4

```

```{r centerzone multi-level Bayesmodels final, echo=F}
DScent_bmoddat = DataSum2496.centC[,c("nCent", "npos", "lnCalcConcC","lnCalcConcC2", "ExposureHrs","Spp","RepID")]
DScent_bmoddat$lnCalcConcC = as.numeric(DScent_bmoddat$lnCalcConcC) 
DScent_bmoddat$lnCalcConcC2 = as.numeric(DScent_bmoddat$lnCalcConcC2) 
DScent_bmoddat$SppDummy <- as.numeric(ifelse(DScent_bmoddat$Spp=="GS", 0,1))
DScent_bmoddat$ExposeDummy <- as.numeric(ifelse(DScent_bmoddat$ExposureHrs=="24", 0,1))

# remove fish with only one timepoint of detection, because cant add random slope with one timepoint
DScent_bmoddat = DScent_bmoddat[!(DScent_bmoddat$RepID %in% paste0(c(0,5,100,500,1000,2000), "-WS-4")),]
DScent_bmoddat$RepID = as.factor(as.character(DScent_bmoddat$RepID))



set.seed(1983)
centspp.blm_int8 = map2stan(
  alist(
    nCent ~ dbinom(npos, p),
      logit(p)  <- a_fish[RepID] +
              be_fish[RepID]*ExposeDummy +
              bs*SppDummy +
              bt*(lnCalcConcC) +
              bse*(SppDummy)*(ExposeDummy)+
              bts*(lnCalcConcC)*(SppDummy)+
              bt2*(lnCalcConcC2) +
              bt2s*(lnCalcConcC2)*(SppDummy),

           c(a_fish,be_fish)[RepID] ~ dmvnorm2(c(a, be),sigma_fish, Rho),#
           a ~ dnorm(4,10), # approximate mean of base case (GS-24hr)
           be ~ dnorm(0,10),
           sigma_fish ~ dcauchy(0,2),
           Rho ~ dlkjcorr(2), # not as flat as (1) but biases against strong correlations of intercept and slope

        bs ~ dnorm(0,10),
        bt ~ dnorm(0,10),
        bse ~ dnorm(0,10),
        bts ~ dnorm(0,10),
        bt2 ~ dnorm(0,10),
        bt2s ~ dnorm(0,10)
    ) ,
  data = DScent_bmoddat, iter = 2000, warmup = 300, chains = 3)


# check model
 precis(centspp.blm_int8, prob = .95, digits=3)
 plot(precis(centspp.blm_int8, prob = .95))
 plot(precis(centspp.blm_int8, prob = .95, depth=2))

 plot(centspp.blm_int8)
```

```{r center zone multi-level Bayesmodels predict, echo=F, eval=F}

# pull posterior from model:
set.seed(42)
post = extract.samples(centspp.blm_int8)

# set up dataframe to plot posterior predictions
preddat = list(CalcConc=rep(seq(0, 2250, 2), 4), 
               lnCalcConc=log(rep(seq(0, 2250, 2),4)+1), 
               lnCalcConcC=(log(rep(seq(0, 2250, 2),4)+1)) - 
                 mean(DataSum2496.centC$lnCalcConc) ,
               lnCalcConcC2=((log(rep(seq(0, 2250, 2),4)+1)) - 
                 mean(DataSum2496.centC$lnCalcConc))^2 ,               
               ExposeDummy = rep(c(0,1), each=1126*2), 
               SppDummy = rep(rep(c(0,1),each=1126),2), 
               RepID = rep(2,4504),
               npos = rep(mean(DataSum2496.centC$npos), 4504) )

# make zeros for individual random effects to predict to mean only -> model doesn't have any 'a' this way
  # a_fish_zeros = matrix(0,12000,90)
  # be_fish_zeros = matrix(0,12000,90)

# use estimated posteriors for population of individuals to simulate new fish; shapes of distributions between model posteriors and predicted posteriors are nearly identical, not what I want...but it does predict uncertainty across individuals, but might as well just take predictions for individual fish are put them in as the data...not quote grasping this
  # a_fish_sim = matrix(rnorm(12000*90, mean(post$a_fish), mean(post$sigma_fish[,1])),12000,90)
  # be_fish_sim = matrix(rnorm(12000*90, mean(post$be_fish), mean(post$sigma_fish[,2])),12000,90)

# replace individual fish estimates with global estimate; this should predict to the average individual in a population...so since I want to get at the population level response this seems more appropriate.
a_global = matrix(post$a,459000,90)
be_global = matrix(post$be,459000,90)

# use link to predict to mean only
# link.int2 <- link(centspp.blm_int2, n=1000, data= preddat, 
#                          replace = list(a_fish = a_global, 
#                                         be_fish = be_global) )
# link.int3 <- link(centspp.blm_int3, n=1000, data= preddat, 
#                          replace = list(a_fish = a_global, 
#                                         be_fish = be_global) )
# link.int4 <- link(centspp.blm_int4, n=1000, data= preddat, 
#                          replace = list(a_fish = a_global, 
#                                         be_fish = be_global) )
# link.int5 <- link(centspp.blm_int5, n=1000, data= preddat, 
#                          replace = list(a_fish = a_global, 
#                                         be_fish = be_global) )
# link.int6 <- link(centspp.blm_int6, n=1000, data= preddat, 
#                          replace = list(a_fish = a_global, 
#                                         be_fish = be_global) )
# link.int7 <- link(centspp.blm_int7, n=1000, data= preddat, 
#                          replace = list(a_fish = a_global, 
#                                         be_fish = be_global) )
link.int8 <- link(centspp.blm_int8, n=1000, data= preddat, 
                         replace = list(a_fish = a_global, 
                                        be_fish = be_global) )
preddat.df <- data.frame(sapply(preddat,c)) # thanks stack overflow! (turns the list into a dataframe) https://stackoverflow.com/questions/4227223/convert-a-list-to-a-data-frame

preddat.df$link_mu_mn <- apply(link.int8, 2, mean) 
preddat.df$link_PI05 = apply(link.int8, 2, PI, .95)[1,] 
preddat.df$link_PI95 = apply(link.int8, 2, PI, .95)[2,] 

# preddat.df$link_mu_mn <- apply(link.int5, 2, mean) 
# preddat.df$link_PI05 = apply(link.int5, 2, PI, .95)[1,] 
# preddat.df$link_PI95 = apply(link.int5, 2, PI, .95)[2,] 
 

# # predict from posteriors (on transformed scale)
#   link_pred <- link(distspp.blm_int2.rise, data = preddat, n=1000) 
#   preddat$link_mu_mn <- apply(link_pred, 2, mean)
#   preddat$link_PI05 = apply(link_pred, 2, PI, .95)[1,]
#   preddat$link_PI95 = apply(link_pred, 2, PI, .95)[2,]
#   
#  # predict with sim; it's my understanding that this integrates the error estimates too?
#   sim_pred <- sim(distspp.blm_int2.rise, data = preddat, n=1000) 
#   preddat$sim_mu_mn <- apply(sim_pred, 2, mean)
#   preddat$sim_PI05 = apply(sim_pred, 2, PI, .95)[1,]
#   preddat$sim_PI95 = apply(sim_pred, 2, PI, .95)[2,]
#  
  # plot predictions and data
  preddat.df$Spp <- ifelse(preddat.df$SppDummy==0,"GS","WS")
  preddat.df$ExposureHrs <- ifelse(preddat.df$ExposeDummy==0,"24","96")


CentPred_transf_plot2_mod8 = ggplot() + 
  geom_point(data=DataSum2496.centC,
             aes(x=(lnCalcConcC),                          
                 y=nCent/npos, 
                 color=factor(Spp))) + 
  geom_ribbon(data = preddat.df, aes(x=(lnCalcConcC), 
              ymin=link_PI05, ymax=link_PI95), 
              alpha=.4, col="grey70")+
  geom_line(data = preddat.df, aes(x=(lnCalcConcC), y=link_mu_mn), lwd=.2)+ 
    facet_grid(Spp~ExposureHrs, scales="free", labeller = labeller(
      ExposureHrs = c("24"="24 Hours Exposure","96"="96 Hours Exposure"),
      Spp = c("GS" = "Green Sturgeon", "WS" = "White Sturgeon")))+
    scale_color_manual(values=c("green3", "steelblue3"), guide=FALSE)+
    ylab("Proportion of Positions within Central Zone") + 
    scale_x_continuous(name="log(Bifenthrin Concentration) (ng/L)") + #, breaks = seq(-7.5,5, 2.5), labels=(seq(-7.5,5, 2.5)+3.73) ) +
    theme_bw()


CentPred_orig_plot2_mod8 = ggplot() + 
  geom_point(data=DataSum2496.centC,
             aes(x=(calcConc),                          
                 y=nCent/npos, 
                 color=factor(Spp))) + 
  geom_ribbon(data = preddat.df, aes(x=(CalcConc), 
              ymin=link_PI05, ymax=link_PI95), 
              alpha=.4, col="grey70")+
  geom_line(data = preddat.df, aes(x=(CalcConc), y=link_mu_mn), lwd=.2)+
  facet_grid(Spp~ExposureHrs, scales="free", labeller = labeller(
    ExposureHrs = c("24"="24 Hours Exposure","96"="96 Hours Exposure"),
    Spp = c("GS" = "Green Sturgeon", "WS" = "White Sturgeon")))+
  scale_color_manual(values=c("green3", "steelblue3"), guide=FALSE)+
  ylab("Proportion of Positions within Central Zone") + 
  scale_x_continuous(name="Bifenthrin Concentration (ng/L)") + #, breaks = seq(-7.5,5, 2.5), labels=(seq(-7.5,5, 2.5)+3.73) ) +
  theme_bw()



# CentPred_transf_plot2_mod1
# CentPred_transf_plot2_mod2
# CentPred_transf_plot2_mod3
# CentPred_transf_plot2_mod4
# CentPred_transf_plot2_mod5
# CentPred_transf_plot2_mod6
# CentPred_transf_plot2_mod7
CentPred_transf_plot2_mod8

# CentPred_orig_plot2_mod1
# CentPred_orig_plot2_mod2
# CentPred_orig_plot2_mod3
# CentPred_orig_plot2_mod4
# CentPred_orig_plot2_mod5
# CentPred_orig_plot2_mod6
# CentPred_orig_plot2_mod7
CentPred_orig_plot2_mod8

```
 ### Hm. WAIC suggests they're nearly all equal, except for 7 (barely, nearly better). From looking at the fit of the prediction lines, I think 6 is not a good model because without the quadratic it doesn't fit the curve of the data and the mechanism we expected. Model 5 allows the quadratic to vary by species (green sturgeon curve becomes flatter in the transformed plots), and the effect of concentration to vary by exposure period (24 hr curve becomes flatter). This looks pretty good, but the confidence bands are wider than those for model 4 while the trend is very smiliar. Model 3 lets the quadratic vary by exposure period (but not spp), so I built/fit Model 7 to let both the standard and quadratic effectws for treatment vary by exposure period and species (ie: seperate line for each of the four facets). This model seems to be better, or at least not worse, based on AIC, and the plots look better too. Let's go with 7 - I think it's similar to the model for distance too, which will make the paper easier to write. Oops. Model 8 matches the distance model. And it is slightly better on AIC - it removes the interactions between treatment and exposure time. 
 
 
 
### Central Zone Contrasts

### Study questions: 

###  1) is there an effect (all treatment vs control), and which metrics show an effect
- posterior for bt x control vs posteriors for bt x each level of treatment (5 comps)
- in reality, this seems better nested under the following two contrast grouping, because the early-life stange behavior of the two species is so different, and it also seems that the WS are more affected (or perhaps just more mobile and this easier to detect change?)

###  2) Does the magnitude of the effect vary between species
- posterior for bt X GS x control vs posteriors for bt x GS x each level of treatment (5 comps)
- posterior for bt x WS x control vs posteriors for bt x WS x each level of treatment (5 comps)
= 10 comparisons

###  3) does that effect change with time [96 treat vs 96 control and 24 treat vs 24 control OR individual change from 24 to 96 (all treatments) as compared to individual change for control between 24 and 96]
- posterior for bt-24control vs bt-24xtreatments (n=5) and bt-96control vs bt-96 treatments (n=5) = 10 comparisons
- OR the above comparisions by species
= 20 comparisons. 


### Esh. Appendix table? mean difference, 95%CI or probability that the difference is not zero, which is more comparable to a p-value I think. It's the confidence that there IS a difference in the direction indicated (+ or -)



```{r cent multi-level model density plots and conc contrasts, echo=F}
set.seed(1983) 
postcent = extract.samples(centspp.blm_int8)
 
    # # reference table to convert from treatment to centered, log-transformed measured concentrations
TreatCalcTable = unique(DataSum2496.centC[order(DataSum2496.centC$Treatment)
                                             ,c("Spp", "Treatment", 
                                                "lnCalcConc", "lnCalcConcC")])
TreatCalcTable$lnCalcConcC2 = TreatCalcTable$lnCalcConcC ^ 2



# calculate differences between control and treatment at each time point for each species (20 contrasts)
GS0bif24cent = postcent$a +
  postcent$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==0)$lnCalcConcC) +
  postcent$bt2*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==0)$lnCalcConcC2)
GS5bif24cent = postcent$a + 
  postcent$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==5)$lnCalcConcC) +
  postcent$bt2*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==5)$lnCalcConcC2)
GS100bif24cent = postcent$a + 
  postcent$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==100)$lnCalcConcC) +
  postcent$bt2*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==100)$lnCalcConcC2)
GS500bif24cent = postcent$a + 
  postcent$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==500)$lnCalcConcC) +
  postcent$bt2*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==500)$lnCalcConcC2)
GS1000bif24cent = postcent$a +
  postcent$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==1000)$lnCalcConcC) + 
  postcent$bt2* as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==1000)$lnCalcConcC2)
GS2000bif24cent = postcent$a + 
  postcent$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==2000)$lnCalcConcC) + 
  postcent$bt2*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==2000)$lnCalcConcC2)

# complile into a list
GS24cent.list = list(GS0bif24cent, GS5bif24cent, GS100bif24cent,
                     GS500bif24cent, GS1000bif24cent, GS2000bif24cent)

# write come output functions to reduce code length
logistic.summary.func = function(x) { mean = logistic(mean(x))
                                      Lower95CI = logistic(quantile(x,.025))
                                      Upper95CI = logistic(quantile(x,.975))
                                      return(data.frame(mean = mean,
                                                        U95CI = Upper95CI,
                                                        L95CI=Lower95CI)) }

# use functions to 
   pred.muGS24 = data.frame(nomconc = c(0,5,100,500,1000,2000), 
                            Spp = "GS",
                            ExposureHrs = 24,
                     pred.centZone = t(sapply(GS24cent.list,logistic.summary.func)),
                       diff.meancontrol = c(NA, sapply(GS24cent.list[2:6], function(x) mean(GS24cent.list[[1]]) - mean(x) )),
                     prob.greater0 = c(NA, mapply(function(x,y) sum(x<y), GS24cent.list[1], GS24cent.list[2:6]) / length(GS24cent.list[[1]]) ) )

          ## long version of the above pred.mu
          # logistic(mean(GS0bif24cent))
          # 
          # logistic(mean(GS5bif24cent))
          #  cont.GS_0.5bif_24cent = (sum(GS0bif24cent<GS5bif24cent) / length(GS0bif24cent)) 
          #  cont.GS_0.5bif_24cent #  57.2% prob that 5 is more than 0
          #  
          # logistic(mean(GS100bif24cent))
          #  cont.GS_0.100bif_24cent = (sum(GS0bif24cent<GS100bif24cent) / length(GS0bif24cent)) 
          #  cont.GS_0.100bif_24cent #  85.2% prob that 100 is more than 0
          #  
          # logistic(mean(GS500bif24cent))
          #  cont.GS_0.500bif_24cent = (sum(GS0bif24cent<GS500bif24cent) / length(GS0bif24cent)) 
          #  cont.GS_0.500bif_24cent #  99.5% prob that 500 is more than 0
          #  
          # logistic(mean(GS1000bif24cent))
          #  cont.GS_0.1000bif_24cent = (sum(GS0bif24cent<GS1000bif24cent) / length(GS0bif24cent)) 
          #  cont.GS_0.1000bif_24cent #  99.8% prob that 1000 is more than 0
          # 
          # logistic(mean(GS2000bif24cent))
          #  cont.GS_0.2000bif_24cent = (sum(GS0bif24cent<GS2000bif24cent) / length(GS0bif24cent)) 
          #  cont.GS_0.2000bif_24cent #  >99.9% prob that 2000 is more than 0 
          ##
 
 
GS24cent.plot = ggplot() + geom_density(aes(x=logistic(GS0bif24cent), color="black")) + 
  geom_density(aes(x=logistic(GS5bif24cent), color="green3")) + 
  geom_density(aes(x=logistic(GS100bif24cent), color="goldenrod")) + 
  geom_density(aes(x=logistic(GS500bif24cent), color="red3")) + 
  geom_density(aes(x=logistic(GS1000bif24cent), color="pink")) + 
  geom_density(aes(x=logistic(GS2000bif24cent), color="steelblue3")) + 
  scale_color_manual(name="Nominal Bifenthrin\nConcentration", 
                     values=c("black"="black", "green3"="green3", 
                              "goldenrod"="goldenrod","red3"="red3", 
                              "pink"="pink","steelblue3"="steelblue3"), 
                     labels=c("0 ng/L", "5 ng/L", "100ng/L", 
                              "500ng/L", "1000ng/L", "2000 ng/L") ) + 
  xlab("probability of Detection in Central Zone (GS @ 24hr)")+
  xlim(c(0,1))+
  theme_bw()







# repeat for green sturgeon, 96hr

GS0bif96cent = postcent$a + postcent$be +
  postcent$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==0)$lnCalcConcC) +
  postcent$bt2*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==0)$lnCalcConcC2) 
GS5bif96cent = postcent$a + postcent$be + 
  postcent$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==5)$lnCalcConcC) +
  postcent$bt2*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==5)$lnCalcConcC2)
GS100bif96cent = postcent$a + postcent$be + 
  postcent$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==100)$lnCalcConcC) +
  postcent$bt2*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==100)$lnCalcConcC2)
GS500bif96cent = postcent$a + postcent$be + 
  postcent$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==500)$lnCalcConcC) +
  postcent$bt2*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==500)$lnCalcConcC2)
GS1000bif96cent = postcent$a + postcent$be +
  postcent$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==1000)$lnCalcConcC) + 
  postcent$bt2* as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==1000)$lnCalcConcC2)
GS2000bif96cent = postcent$a + postcent$be + 
  postcent$bt*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==2000)$lnCalcConcC) + 
  postcent$bt2*as.numeric(subset(TreatCalcTable, Spp=="GS" & Treatment==2000)$lnCalcConcC2)

## complile into a list
GS96cent.list = list(GS0bif96cent, GS5bif96cent, GS100bif96cent,
                     GS500bif96cent, GS1000bif96cent, GS2000bif96cent)

# write come output functions to reduce code length
logistic.summary.func = function(x) { mean = logistic(mean(x))
                                      Lower95CI = logistic(quantile(x,.025))
                                      Upper95CI = logistic(quantile(x,.975))
                                      return(data.frame(mean = mean,
                                                        U95CI = Upper95CI,
                                                        L95CI=Lower95CI)) }

# use functions to 
   pred.muGS96 = data.frame(nomconc = c(0,5,100,500,1000,2000), 
                            Spp = "GS",
                            ExposureHrs = 96,
                     pred.centZone = t(sapply(GS96cent.list,logistic.summary.func)),
                     diff.meancontrol = c(NA, sapply(GS96cent.list[2:6], function(x) mean(GS96cent.list[[1]]) - mean(x) )),
                     prob.greater0 = c(NA, mapply(function(x,y) sum(x<y), GS96cent.list[1], GS96cent.list[2:6]) / length(GS96cent.list[[1]]) ) )



        # 
        # mean(GS0bif96cent)
        # mean(GS5bif96cent)
        #  cont.GS_0.5bif_96cent = (sum(GS0bif96cent<GS5bif96cent) / length(GS0bif96cent)) 
        #  cont.GS_0.5bif_96cent #72.0% prob that 5 is more than 0
        # mean(GS100bif96cent)
        # mean(GS500bif96cent)
        # mean(GS1000bif96cent)
        # mean(GS2000bif96cent)

GS96cent.plot = ggplot() + geom_density(aes(x=logistic(GS0bif96cent)), color="black") + 
  geom_density(aes(x=logistic(GS5bif96cent)), color="green3") + 
  geom_density(aes(x=logistic(GS100bif96cent)), color="goldenrod") + 
  geom_density(aes(x=logistic(GS500bif96cent)), color="red3") + 
  geom_density(aes(x=logistic(GS1000bif96cent)), color="pink") + 
  geom_density(aes(x=logistic(GS2000bif96cent)), color="steelblue3") + 
  scale_color_manual(name="Nominal Bifenthrin\nConcentration", 
                     values=c("black"="black", "green3"="green3", "goldenrod"="goldenrod",
                              "red3"="red3", "pink"="pink","steelblue3"="steelblue3"), 
                     labels=c("0 ng/L", "5 ng/L", "100ng/L", 
                              "500ng/L", "1000ng/L", "2000 ng/L") ) + 
  xlab("Proportion of Detections in Central Zone (GS @ 96hr)")+
  xlim(c(0,1))+
  theme_bw()


# repeat for white sturgeon, 24hr

WS0bif24cent = postcent$a + postcent$bs +
  postcent$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==0)$lnCalcConcC) +
  postcent$bt2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==0)$lnCalcConcC2) +
  postcent$bt2s*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==0)$lnCalcConcC2)
WS5bif24cent = postcent$a + postcent$bs + 
  postcent$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==5)$lnCalcConcC) +
  postcent$bt2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==5)$lnCalcConcC2)+
  postcent$bt2s*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==5)$lnCalcConcC2)
WS100bif24cent = postcent$a + postcent$bs + 
  postcent$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==100)$lnCalcConcC) +
  postcent$bt2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==100)$lnCalcConcC2)+
  postcent$bt2s*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==100)$lnCalcConcC2)
WS500bif24cent = postcent$a + postcent$bs + 
  postcent$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==500)$lnCalcConcC) +
  postcent$bt2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==500)$lnCalcConcC2)+
  postcent$bt2s*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==500)$lnCalcConcC2)
WS1000bif24cent = postcent$a + postcent$bs +
  postcent$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==1000)$lnCalcConcC) + 
  postcent$bt2* as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==1000)$lnCalcConcC2)+
  postcent$bt2s* as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==1000)$lnCalcConcC2)
WS2000bif24cent = postcent$a + postcent$bs + 
  postcent$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==2000)$lnCalcConcC) + 
  postcent$bt2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==2000)$lnCalcConcC2)+
  postcent$bt2s*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==2000)$lnCalcConcC2)



# complile into a list
WS24cent.list = list(WS0bif24cent, WS5bif24cent, WS100bif24cent,
                     WS500bif24cent, WS1000bif24cent, WS2000bif24cent)

# write come output functions to reduce code length
logistic.summary.func = function(x) { mean = logistic(mean(x))
                                      Lower95CI = logistic(quantile(x,.025))
                                      Upper95CI = logistic(quantile(x,.975))
                                      return(data.frame(mean = mean,
                                                        U95CI = Upper95CI,
                                                        L95CI=Lower95CI)) }

# use functions to 
   pred.muWS24 = data.frame(nomconc = c(0,5,100,500,1000,2000), 
                            Spp = "WS",
                            ExposureHrs = 24,
                     pred.centZone = t(sapply(WS24cent.list,logistic.summary.func)),
                     diff.meancontrol = c(NA, sapply(WS24cent.list[2:6], function(x) mean(WS24cent.list[[1]]) - mean(x) )),
                     prob.greater0 = c(NA, mapply(function(x,y) sum(x<y), WS24cent.list[1], WS24cent.list[2:6]) / length(WS24cent.list[[1]]) ) )

        # 
        # mean(WS0bif24cent)
        # mean(WS5bif24cent)
        #  cont.WS_0.5bif_24cent = (sum(WS0bif24cent<WS5bif24cent) / length(WS0bif24cent)) 
        #  cont.WS_0.5bif_24cent #100% prob that 5 is more than 0
        # mean(WS100bif24cent)
        #  cont.WS_0.100bif_24cent = (sum(WS0bif24cent<WS100bif24cent) / length(WS0bif24cent)) 
        #  cont.WS_0.100bif_24cent #100% prob that 100 is more than 0
        # mean(WS500bif24cent)
        #  cont.WS_0.500bif_24cent = (sum(WS0bif24cent<WS500bif24cent) / length(WS0bif24cent)) 
        #  cont.WS_0.500bif_24cent #55% prob that 500 is more than 0
        # mean(WS1000bif24cent)
        #  cont.WS_0.1000bif_24cent = (sum(WS0bif24cent<WS1000bif24cent) / length(WS0bif24cent)) 
        #  cont.WS_0.1000bif_24cent #0% prob that 1000 is more than 0 (i.e. 100% prob that 1000 is less than 0)
        # mean(WS2000bif24cent)
        #  cont.WS_0.2000bif_24cent = (sum(WS0bif24cent<WS2000bif24cent) / length(WS0bif24cent)) 
        #  cont.WS_0.2000bif_24cent #0% prob that 2000 is more than 0 (i.e. 100% prob that 1000 is less than 0)
        #  
WS24cent.plot = ggplot() + geom_density(aes(x=logistic(WS0bif24cent)), color="black") + 
  geom_density(aes(x=logistic(WS5bif24cent)), color="green3") + 
  geom_density(aes(x=logistic(WS100bif24cent)), color="goldenrod") + 
  geom_density(aes(x=logistic(WS500bif24cent)), color="red3") + 
  geom_density(aes(x=logistic(WS1000bif24cent)), color="pink") + 
  geom_density(aes(x=logistic(WS2000bif24cent)), color="steelblue3") + 
  scale_color_manual(name="Nominal Bifenthrin\nConcentration", 
                     values=c("black"="black", "green3"="green3", "goldenrod"="goldenrod",
                              "red3"="red3", "pink"="pink","steelblue3"="steelblue3"), 
                     labels=c("0 ng/L", "5 ng/L", "100ng/L", 
                              "500ng/L", "1000ng/L", "2000 ng/L") ) + 
  xlab("Proportion of Detections in Central Zone (WS @ 24hr)")+
  xlim(c(0,1))+
  theme_bw()


# repeat for white sturgeon, 96hr


WS0bif96cent = postcent$a + postcent$bs + postcent$be + postcent$bse + 
  postcent$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==0)$lnCalcConcC) +
  postcent$bt2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==0)$lnCalcConcC2) +
  postcent$bt2s*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==0)$lnCalcConcC2)

WS5bif96cent = postcent$a + postcent$bs + postcent$be + postcent$bse +
  postcent$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==5)$lnCalcConcC) +
  postcent$bt2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==5)$lnCalcConcC2) +
  postcent$bt2s*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==5)$lnCalcConcC2)

WS100bif96cent = postcent$a + postcent$bs + postcent$be + postcent$bse +
  postcent$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==100)$lnCalcConcC) +
  postcent$bt2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==100)$lnCalcConcC2) +
  postcent$bt2s*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==100)$lnCalcConcC2)

WS500bif96cent = postcent$a + postcent$bs + postcent$be + postcent$bse +
  postcent$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==500)$lnCalcConcC) +
  postcent$bt2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==500)$lnCalcConcC2) +
  postcent$bt2s*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==500)$lnCalcConcC2)

WS1000bif96cent = postcent$a + postcent$bs + postcent$be + postcent$bse +
  postcent$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==1000)$lnCalcConcC) + 
  postcent$bt2* as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==1000)$lnCalcConcC2) +
  postcent$bt2s* as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==1000)$lnCalcConcC2)

WS2000bif96cent = postcent$a + postcent$bs + postcent$be + postcent$bse +
  postcent$bt*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==2000)$lnCalcConcC) + 
  postcent$bt2*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==2000)$lnCalcConcC2) +
  postcent$bt2s*as.numeric(subset(TreatCalcTable, Spp=="WS" & Treatment==2000)$lnCalcConcC2)


## complile into a list
WS96cent.list = list(WS0bif96cent, WS5bif96cent, WS100bif96cent,
                     WS500bif96cent, WS1000bif96cent, WS2000bif96cent)

# write come output functions to reduce code length
logistic.summary.func = function(x) { mean = logistic(mean(x))
                                      Lower95CI = logistic(quantile(x,.025))
                                      Upper95CI = logistic(quantile(x,.975))
                                      return(data.frame(mean = mean,
                                                        U95CI = Upper95CI,
                                                        L95CI=Lower95CI)) }

# use functions to 
   pred.muWS96 = data.frame(nomconc = c(0,5,100,500,1000,2000), 
                            Spp = "WS",
                            ExposureHrs = 96,
                     pred.centZone = t(sapply(WS96cent.list,logistic.summary.func)),
                     diff.meancontrol = c(NA, sapply(WS96cent.list[2:6], function(x) mean(WS96cent.list[[1]]) - mean(x) )),
                     prob.greater0 = c(NA, mapply(function(x,y) sum(x<y), WS96cent.list[1], WS96cent.list[2:6]) / length(WS96cent.list[[1]]) ) )


 
# mean(WS0bif96cent)
# mean(WS5bif96cent)
#  cont.WS_0.5bif_96cent = (sum(WS0bif96cent<WS5bif96cent) / length(WS0bif96cent)) 
#  cont.WS_0.5bif_96cent #100% prob that 5 is more than 0
# mean(WS100bif96cent)
#  cont.WS_0.100bif_96cent = (sum(WS0bif96cent<WS100bif96cent) / length(WS0bif96cent)) 
#  cont.WS_0.100bif_96cent #100% prob that 100 is more than 0
# mean(WS500bif96cent)
#  cont.WS_0.500bif_96cent = (sum(WS0bif96cent<WS500bif96cent) / length(WS0bif96cent)) 
#  cont.WS_0.500bif_96cent #55.0% prob that 500 is more than 0
# mean(WS1000bif96cent)
#  cont.WS_0.1000bif_96cent = (sum(WS0bif96cent<WS1000bif96cent) / length(WS0bif96cent)) 
#  cont.WS_0.1000bif_96cent #0% prob that 1000 is more than 0 (i.e. 100% prob that 1000 is less than 0)
# mean(WS2000bif96cent)
#  cont.WS_0.2000bif_96cent = (sum(WS0bif96cent<WS2000bif96cent) / length(WS0bif96cent)) 
#  cont.WS_0.2000bif_96cent #0% prob that 2000 is more than 0 (i.e. 100% prob that 2000 is less than 0)

WS96cent.plot = ggplot() + geom_density(aes(x=logistic(WS0bif96cent)), color="black") + 
  geom_density(aes(x=logistic(WS5bif96cent)), color="green3") + 
  geom_density(aes(x=logistic(WS100bif96cent)), color="goldenrod") + 
  geom_density(aes(x=logistic(WS500bif96cent)), color="red3") + 
  geom_density(aes(x=logistic(WS1000bif96cent)), color="pink") + 
  geom_density(aes(x=logistic(WS2000bif96cent)), color="steelblue3") + 
  scale_color_manual(name="Nominal Bifenthrin\nConcentration", 
                     values=c("black"="black", "green3"="green3", "goldenrod"="goldenrod",
                              "red3"="red3", "pink"="pink","steelblue3"="steelblue3"), 
                     labels=c("0 ng/L", "5 ng/L", "100ng/L", 
                              "500ng/L", "1000ng/L", "2000 ng/L") ) + 
  xlab("Proportion of Detections in Central Zone (WS @ 96hr)")+
  xlim(c(0,1))+
  theme_bw()

GS24cent.plot + GS96cent.plot + WS24cent.plot + WS96cent.plot


# compile it for output
predgroups = list(GS0bif24cent, GS5bif24cent, GS100bif24cent,
                  GS500bif24cent, GS1000bif24cent, GS2000bif24cent,
                  GS0bif96cent, GS5bif96cent, GS100bif96cent,
                  GS500bif96cent, GS1000bif96cent, GS2000bif96cent,
                  WS0bif24cent, WS5bif24cent, WS100bif24cent,
                  WS500bif24cent, WS1000bif24cent, WS2000bif24cent,
                  WS0bif96cent, WS5bif96cent, WS100bif96cent,
                  WS500bif96cent, WS1000bif96cent, WS2000bif96cent)
PredGroupNames =  as.character(expression(GS0bif24cent, GS5bif24cent, GS100bif24cent, 
                                          GS500bif24cent, GS1000bif24cent, GS2000bif24cent, 
                                          GS0bif96cent, GS5bif96cent, GS100bif96cent, 
                                          GS500bif96cent, GS1000bif96cent, GS2000bif96cent,
                                          WS0bif24cent, WS5bif24cent, WS100bif24cent, 
                                          WS500bif24cent, WS1000bif24cent, WS2000bif24cent, 
                                          WS0bif96cent, WS5bif96cent, WS100bif96cent,
                                          WS500bif96cent, WS1000bif96cent, WS2000bif96cent))
posterior.preds = data.frame(PredGroupNames = PredGroupNames, 
                             PredMeans = sapply(predgroups, mean),
                             Pred95CIl = sapply(predgroups, quantile, 0.05),
                             Pred95CIu = sapply(predgroups, quantile, 0.95))

# try to compile again in a different way. Didn't know I'd already done this here, and did it again with each spp/exp group above. Oops. 
grouplist = list(pred.muGS24,pred.muGS96,pred.muWS24,pred.muWS96)
posterior.preds2 = do.call(rbind, grouplist)

```
#### if use this in a paper, recolor to a more intuitive gradient and add legend
 
 
```{r center zone  multi-level model time and spp contrasts, echo=F}
# this uses the predicted posteriors for time in central zone, calculated above

# GS vs WS
cont.GS.WS_0bif_24cent = sum(GS0bif24cent<WS0bif24cent) / length(GS0bif24cent)
 cont.GS.WS_0bif_24cent # 19.7% probability that GS will spend less time in center than WS, at 24hrs (ie: GS should be in the center more)

 cont.GS.WS_0bif_96cent = sum(GS0bif96cent<WS0bif96cent) / length(GS0bif96cent)
 cont.GS.WS_0bif_96cent # 42.7% probability that GS will spend less time in center than WS, at 96 hrs, which translates to a 57.2% probability that WS will spend less time in the center than GS. In otherwords, there's not  much difference in time spent in central zone at 96 hours because WS increase their use of the middle as they age
  
cont.GS.WS_5bif_24cent = sum(GS5bif24cent<WS5bif24cent) / length(GS5bif24cent)
 cont.GS.WS_5bif_24cent # 1.6% probability that GS will spend less time in center than WS, after 24 hrs exposure to 100ng/L bifenthrin (ie: GS found in center more than WS)

 cont.GS.WS_5bif_96cent = sum(GS5bif96cent<WS5bif96cent) / length(GS5bif96cent)
 cont.GS.WS_5bif_96cent # 6.2% probability that GS will spend less time in center than WS, after 96 hrs exposure to 100ng/L bifenthrin (ie: GS in center more than WS, but not quite to standard 5% probability 'significance' standard
   
cont.GS.WS_100bif_24cent = sum(GS100bif24cent<WS100bif24cent) / length(GS100bif24cent)
 cont.GS.WS_100bif_24cent # <0.001% probability that GS will spend less time in center than WS after 24hrs of exposure to 100ng/L bifenthrin. Ie: highly likely that GS spend more time in center than WS.
  
cont.GS.WS_100bif_96cent = sum(GS100bif96cent<WS100bif96cent) / length(GS100bif96cent)
 cont.GS.WS_100bif_96cent # 0.02% probability that GS will spend less time in center than WS after 24hrs of exposure to 100ng/L bifenthrin. Ie: highly likely that GS spend more time in center than WS.

 ## etc...
 
 cont.GS.WS_2000bif_96cent = sum(GS2000bif96cent<WS2000bif96cent) / length(GS2000bif96cent)
 cont.GS.WS_2000bif_96cent # 1.1% probability that GS will spend less time in center than WS at 96 hrs, when exposed to 2000ng/L bifenthrin. Ie: highly likely that GS spend more time in center than WS after 96hrs of exposure t0 2000ng/L bifenthrin
 
cont.GS.WS_2000bif_24cent = sum(GS2000bif24cent<WS2000bif24cent) / length(GS2000bif24cent)
 cont.GS.WS_2000bif_24cent # 0.2% probability that GS will spend less time in center than WS after 96hrs of exposure to 2000ng/L bifenthrin. Ie: highly likely that GS spend more time in center than WS.

 cont.GS.WS_2000bif_96cent = sum(GS2000bif96cent<WS2000bif96cent) / length(GS2000bif96cent)
 cont.GS.WS_2000bif_96cent # 0.01% probability that GS will spend less time in center than WS at 96 hrs, when exposed to 2000ng/L bifenthrin. Ie: highly likely that GS spend more time in center than WS after 96hrs of exposure t0 2000ng/L bifenthrin


# Green Sturgeon, Exposure Hr (no change at different levels since no exposure*treatment term in model
cont.GS0bif_96.24cent = (sum(GS0bif96cent<GS0bif24cent) / length(GS0bif96cent)) 
cont.GS0bif_96.24cent
 # 22.7% of the samples from the posterior showed less use of central zone by GS at 96 than 24; so most likely that central-zone use is greater at 96 than 24 (77.3%), but not 'significant' if using standard cut-off thresholds

GS0bif_96.24cent.plot = ggplot() + geom_density(aes(x=GS0bif96cent), color="steelblue3") + 
  geom_density(aes(x=GS0bif24cent), color="green3") + 
  xlab("Distance moved - GS @ 0 ng/L bifenthrin\n24 vs 96 hrs)") +
  theme_bw()

# use patchwork grammar to plot multiple plots
GS0bif_96.24cent.plot



# White Sturgeon: probability of a difference between 24 and 96 hours, at each treatment level
cont.WS0bif_96.24cent = (sum(WS0bif96cent<WS0bif24cent) / length(WS0bif96cent)) 
cont.WS0bif_96.24cent
# 2.1% of the samples from the posterior showed less use of central zone by WS at 96 than 24; so highly likely that WS use of central zone is greater at 96 than 24 (97.9%) 'significant' using standard thresholds

WS0bif_96.24cent.plot = ggplot() + geom_density(aes(x=WS0bif96cent), color="steelblue3") + 
  geom_density(aes(x=WS0bif24cent), color="green3") + 
  xlab("Distance moved - WS @ 0 ng/L bifenthrin\n24 vs 96 hrs)") +
  theme_bw()
WS0bif_96.24cent.plot


```
